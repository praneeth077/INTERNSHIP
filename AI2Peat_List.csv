Paper_Number;Paper_ID;Paper_Name;Paper_Link
0;L8T7Jue8J5MJ;Playing atari with deep reinforcement learning;https://arxiv.org/abs/1312.5602
1;T22_I6QZCH4J;Ensemble deep learning: A review ;https://www.sciencedirect.com/science/article/pii/S095219762200269X
2;KT6Ax9PwSEwJ;Offline reinforcement learning: Tutorial, review, and perspectives on open problems ;https://arxiv.org/abs/2005.01643
3;mqzKEAzb62oJ;Decision transformer: Reinforcement learning via sequence modeling ;https://proceedings.neurips.cc/paper_files/paper/2021/hash/7f489f642a0ddb10272b5c31057f0663-Abstract.html
4;pWFqdIkJp7YJ;Card: Classification and regression diffusion models ;https://proceedings.neurips.cc/paper_files/paper/2022/hash/72dad95a24fae750f8ab1cb3dab5e58d-Abstract-Conference.html
5;mjatFWLvYiwJ;Beyond the imitation game: Quantifying and extrapolating the capabilities of language models ;https://arxiv.org/abs/2206.04615
6;x50-BmXs7GEJ;Conservative q-learning for offline reinforcement learning ;https://proceedings.neurips.cc/paper/2020/hash/0d2b2061826a5df3221116a5085a6052-Abstract.html
7;W45MfR2AC3UJ;Federated learning in mobile edge networks: A comprehensive survey ;https://ieeexplore.ieee.org/abstract/document/9060868/
8;cZJ1WAYwKr4J;Dota 2 with large scale deep reinforcement learning ;https://arxiv.org/abs/1912.06680
9;8GxsiI0DibgJ;Interpretable machine learning: Fundamental principles and 10 grand challenges ;https://projecteuclid.org/journals/statistics-surveys/volume-16/issue-none/Interpretable-machine-learning-Fundamental-principles-and-10-grand-challenges/10.1214/21-SS133.short
10;ETPMR67DU7gJ;Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor ;https://proceedings.mlr.press/v80/haarnoja18b
11;s2cQAMRecF0J;Towards evaluating the robustness of neural networks ;https://ieeexplore.ieee.org/abstract/document/7958570/
12;fjfo6_k5VRYJ;Soft actor-critic algorithms and applications ;https://arxiv.org/abs/1812.05905
13;yZ_b1HimtmUJ;Efficient processing of deep neural networks: A tutorial and survey ;https://ieeexplore.ieee.org/abstract/document/8114708/
14;YW9AmGuXrcgJ;Asynchronous methods for deep reinforcement learning ;https://proceedings.mlr.press/v48/mniha16.html?ref=.
15;xQ5BC7Hj-HkJ;Towards a rigorous science of interpretable machine learning ;https://arxiv.org/abs/1702.08608
16;MHq4MMenr-gJ;Deep learning ;https://books.google.com/books?hl=en&lr=&id=omivDQAAQBAJ&oi=fnd&pg=PR5&ots=MNV5hvtHRR&sig=WObQI8hl1y3CS3FCXvOmH92MBWg
17;rA4Y04TkbQEJ;How to train your robot with deep reinforcement learning: lessons we have learned ;https://journals.sagepub.com/doi/abs/10.1177/0278364920987859
18;nIBHwrpY9e8J;Data-driven science and engineering: Machine learning, dynamical systems, and control ;https://books.google.com/books?hl=en&lr=&id=jkSIDwAAQBAJ&oi=fnd&pg=PR9&ots=VE7agn9WeP&sig=JZbTr4txhV1ebgIZYPJbxXCj3OU
19;lTNo4sNhWzkJ;Continuous control with deep reinforcement learning ;https://arxiv.org/abs/1509.02971
20;kEPrWnkwpqYJ;A state-of-the-art survey on deep learning theory and architectures ;https://www.mdpi.com/2079-9292/8/3/292?ref=https://githubhelp.com
21;xT2HM3SpPT8J;Rainbow: Combining improvements in deep reinforcement learning ;https://ojs.aaai.org/index.php/AAAI/article/view/11796
22;SyDQgF5xNjIJ;Learning robust perceptive locomotion for quadrupedal robots in the wild ;https://www.science.org/doi/abs/10.1126/scirobotics.abk2822
23;QO9y1aucgpYJ;U-net: Convolutional networks for biomedical image segmentation ;https://link.springer.com/chapter/10.1007/978-3-319-24574-4_28
24;cWWmx8639L4J;Dropout as a bayesian approximation: Representing model uncertainty in deep learning ;https://proceedings.mlr.press/v48/gal16.html?trk=public_post_comment-text
25;uiYh7C2joKwJ;Human-level control through deep reinforcement learning ;https://www.nature.com/articles/nature14236/?source=post_page---------------------------
26;q1Ph2DbnqsEJ;Applications of deep reinforcement learning in communications and networking: A survey ;https://ieeexplore.ieee.org/abstract/document/8714026/
27;lsrF0eiGnUEJ;Deep reinforcement learning that matters ;https://ojs.aaai.org/index.php/AAAI/article/view/11694
28;6bhwtG1lktIJ;Enabling massive IoT toward 6G: A comprehensive survey ;https://ieeexplore.ieee.org/abstract/document/9369324/
29;xQqjDYKSnJUJ;Prioritized experience replay ;https://arxiv.org/abs/1511.05952
30;RMVLSFgjBj0J;Threat of adversarial attacks on deep learning in computer vision: A survey ;https://ieeexplore.ieee.org/abstract/document/8294186/
31;JataRPF3gDoJ;Trust region policy optimization ;https://proceedings.mlr.press/v37/schulman15.html
32;gz8vYZVT0REJ;Optimizing federated learning on non-iid data with reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/9155494/
33;KuhEz62P2bIJ;Inverse molecular design using machine learning: Generative models for matter engineering ;https://www.science.org/doi/abs/10.1126/science.aat2663
34;dJEl2TbsHN0J;Deep learning in neural networks: An overview ;https://www.sciencedirect.com/science/article/pii/S0893608014002135
35;I_1Pnwuu6zkJ;Provably efficient reinforcement learning with linear function approximation ;http://proceedings.mlr.press/v125/jin20a.html
36;6_MJGRybhkEJ;End-to-end training of deep visuomotor policies ;https://www.jmlr.org/papers/volume17/15-522/15-522.pdf
37;YfQ9XpC6nEcJ;An end-to-end deep learning architecture for graph classification ;https://ojs.aaai.org/index.php/AAAI/article/view/11782
38;hnioaab9vwEJ;Exploration by random network distillation ;https://arxiv.org/abs/1810.12894
39;bLm5LFqKmqEJ;Unmasking Clever Hans predictors and assessing what machines really learn ;https://www.nature.com/articles/s41467-019-08987-4
40;4_qhnVSvadQJ;Deep learning for IoT big data and streaming analytics: A survey ;https://ieeexplore.ieee.org/abstract/document/8373692/
41;YIPAMJB6sMwJ;Multi-game decision transformers ;https://proceedings.neurips.cc/paper_files/paper/2022/hash/b2cac94f82928a85055987d9fd44753f-Abstract-Conference.html
42;PfaOE8GmGbwJ;Adversarial attacks and defenses in images, graphs and text: A review ;https://link.springer.com/article/10.1007/s11633-019-1211-x
43;cgdmX8MMfRgJ;BoTorch: A framework for efficient Monte-Carlo Bayesian optimization ;https://proceedings.neurips.cc/paper/2020/hash/f5b1b89d98b7286673128a5fb112cb9a-Abstract.html
44;qS7UVldJKZwJ;Outracing champion Gran Turismo drivers with deep reinforcement learning ;https://www.nature.com/articles/s41586-021-04357-7
45;UVUMFZ6rUj0J;The history began from alexnet: A comprehensive survey on deep learning approaches ;https://arxiv.org/abs/1803.01164
46;nTDUrJthLnUJ;Class-incremental learning: survey and performance evaluation on image classification ;https://ieeexplore.ieee.org/abstract/document/9915459/
47;1mE90xusmroJ;Deep learning: methods and applications ;https://www.nowpublishers.com/article/Details/SIG-039
48;NO5hmY-9QGAJ;Learning combinatorial optimization algorithms over graphs ;https://proceedings.neurips.cc/paper/2017/hash/d9896106ca98d3d05b8cbdf4fd8b13a1-Abstract.html
49;msYFIAx2SMoJ;Badnets: Identifying vulnerabilities in the machine learning model supply chain ;https://arxiv.org/abs/1708.06733
50;-ND7OqA87iYJ;Behavior regularized offline reinforcement learning ;https://arxiv.org/abs/1911.11361
51;7xoWrSS5VEQJ;Artificial intelligence: A powerful paradigm for scientific research ;https://www.cell.com/article/S2666-6758(21)00104-1/fulltext
52;4frQBQQyo5UJ;Hamiltonian neural networks ;https://proceedings.neurips.cc/paper/2019/hash/26cd8ecadce0d4efd6cc8a8725cbd1f8-Abstract.html
53;hTN05sa1LkMJ;Model-based reinforcement learning for atari ;https://arxiv.org/abs/1903.00374
54;uJtoRwX77IwJ;Unity: A general platform for intelligent agents ;https://arxiv.org/abs/1809.02627
55;ipYD5ds1h6kJ;Transfer learning in deep reinforcement learning: A survey ;https://ieeexplore.ieee.org/abstract/document/10172347/
56;HP_1h8WYtNQJ;Recurrent world models facilitate policy evolution ;https://proceedings.neurips.cc/paper/2018/hash/2de5d16682c3c35007e4e92982f1a2ba-Abstract.html
57;25IZ-mh7cOgJ;Deep models under the GAN: information leakage from collaborative deep learning ;https://dl.acm.org/doi/abs/10.1145/3133956.3134012
58;C1CWxhdprssJ;Neural network dynamics for model-based deep reinforcement learning with model-free fine-tuning ;https://ieeexplore.ieee.org/abstract/document/8463189/
59;b5u6U1HTwwIJ;An optimistic perspective on offline reinforcement learning ;https://proceedings.mlr.press/v119/agarwal20c.html
60;bwiIHOZA74IJ;Artificial intelligence and machine learning approaches to energy demand-side response: A systematic review ;https://www.sciencedirect.com/science/article/pii/S136403212030191X
61;Rx5zFmjYmRAJ;Deep reinforcement learning for dialogue generation ;https://arxiv.org/abs/1606.01541
62;DK-maeBJZqoJ;Is Q-learning provably efficient? ;https://proceedings.neurips.cc/paper_files/paper/2018/hash/d3b1fb02964aa64e257f9f26a31f72cf-Abstract.html
63;tj5uz7Opn84J;Reinforcement learning with unsupervised auxiliary tasks ;https://arxiv.org/abs/1611.05397
64;GaYmVdtcYI0J;Reinforcement learning with deep energy-based policies ;http://proceedings.mlr.press/v70/haarnoja17a.html?ref=https://githubhelp.com
65;4MYcew7r8BcJ;An intriguing failing of convolutional neural networks and the coordconv solution ;https://proceedings.neurips.cc/paper_files/paper/2018/hash/60106888f8977b71e1f15db7bc9a88d1-Abstract.html
66;Os6LylDv0acJ;Bridging offline reinforcement learning and imitation learning: A tale of pessimism ;https://proceedings.neurips.cc/paper/2021/hash/60ce36723c17bbac504f2ef4c8a46995-Abstract.html
67;xiSgz1L8SucJ;Deep reinforcement learning from human preferences ;https://proceedings.neurips.cc/paper_files/paper/2017/hash/d5e2c0adad503c91f91df240d0cd4e49-Abstract.html
68;NhHOeZM0CasJ;Diversity is all you need: Learning skills without a reward function ;https://arxiv.org/abs/1802.06070
69;0LIOn4AvkfoJ;Adversarial attacks and defenses in deep learning ;https://www.sciencedirect.com/science/article/pii/S209580991930503X
70;jy7YvGRzv_gJ;Badnets: Evaluating backdooring attacks on deep neural networks ;https://ieeexplore.ieee.org/abstract/document/8685687/
71;7FXT1XWI668J;Resource management with deep reinforcement learning ;https://dl.acm.org/doi/abs/10.1145/3005745.3005750
72;rJuPkpNwY-gJ;Deep reinforcement learning framework for autonomous driving ;https://arxiv.org/abs/1704.02532
73;HtRq04qLJjcJ;A survey of deep meta-learning ;https://link.springer.com/article/10.1007/s10462-021-10004-4
74;pdwnNEmJkQgJ;A review on reinforcement learning: Introduction and applications in industrial process control ;https://www.sciencedirect.com/science/article/pii/S0098135420300557
75;FOsFRxFS4lgJ;Reinforcement learning based recommender systems: A survey ;https://dl.acm.org/doi/abs/10.1145/3543846
76;_rfzmf-LxUEJ;Bilinear classes: A structural framework for provable generalization in rl ;https://proceedings.mlr.press/v139/du21a.html
77;Sy5TYUo8TTAJ;Combustion machine learning: Principles, progress and prospects ;https://www.sciencedirect.com/science/article/pii/S0360128522000193
78;g4bEYyp3TAUJ;Reinforcement learning, fast and slow ;https://www.cell.com/trends/cognitie-sciences/fulltext/S1364-6613(19)30061-0
79;6Ul9KOmv-YgJ;Quantifying generalization in reinforcement learning ;https://proceedings.mlr.press/v97/cobbe19a.html
80;ymxirL3IxokJ;Big-data science in porous materials: materials genomics and machine learning ;https://pubs.acs.org/doi/abs/10.1021/acs.chemrev.0c00004
81;TZ18VQe782oJ;Inductive biases for deep learning of higher-level cognition ;https://royalsocietypublishing.org/doi/abs/10.1098/rspa.2021.0068
82;ZufycJA53CAJ;A survey of optimization methods from a machine learning perspective ;https://ieeexplore.ieee.org/abstract/document/8903465/
83;KXpz-f_-XM8J;Deep reinforcement learning based resource allocation for V2V communications ;https://ieeexplore.ieee.org/abstract/document/8633948/
84;s5ypH2KWkb8J;Intuitive physics learning in a deep-learning model inspired by developmental psychology ;https://www.nature.com/articles/s41562-022-01394-8
85;e1Os5ICON8UJ;Gradient based sample selection for online continual learning ;https://proceedings.neurips.cc/paper_files/paper/2019/hash/e562cd9c0768d5464b64cf61da7fc6bb-Abstract.html
86;gQ6MdtNSaQUJ;Progress & compress: A scalable framework for continual learning ;http://proceedings.mlr.press/v80/schwarz18a.html?ref=https://githubhelp.com
87;BuVp0ubmAi0J;Review on deep learning applications in frequency analysis and control of modern power system ;https://www.sciencedirect.com/science/article/pii/S0142061521009686
88;FHgTMkCoo-IJ;Model-based reinforcement learning with value-targeted regression ;http://proceedings.mlr.press/v119/ayoub20a.html
89;GSgPwrCC1XQJ;Applications of reinforcement learning in energy systems ;https://www.sciencedirect.com/science/article/pii/S1364032120309023
90;eqOvNHokpT4J;Towards the systematic reporting of the energy and carbon footprints of machine learning ;https://dl.acm.org/doi/abs/10.5555/3455716.3455964
91;MEcUcdcTcd4J;A survey and critique of multiagent deep reinforcement learning ;https://link.springer.com/article/10.1007/s10458-019-09421-1
92;vFiXGil-lbEJ;Bellman eluder dimension: New rich classes of rl problems, and sample-efficient algorithms ;https://proceedings.neurips.cc/paper_files/paper/2021/hash/6f5e4e86a87220e5d361ad82f1ebc335-Abstract.html
93;hJDIJnpyIgoJ;Towards accountability for machine learning datasets: Practices from software engineering and infrastructure ;https://dl.acm.org/doi/abs/10.1145/3442188.3445918
94;9Cy3-gIfGiAJ;Chainer: a next-generation open source framework for deep learning ;http://learningsys.org/papers/LearningSys_2015_paper_33.pdf
95;_7_eu82KfgEJ;The option-critic architecture ;https://ojs.aaai.org/index.php/AAAI/article/view/10916
96;BCHVk0993YgJ;Model compression via distillation and quantization ;https://arxiv.org/abs/1802.05668
97;fE-FRD0htVEJ;Reinforcement learning and its applications in modern power and energy systems: A review ;https://ieeexplore.ieee.org/abstract/document/9275593/
98;KSut8Hmk1BkJ;A comprehensive review of deep learning applications in hydrology and water resources ;https://iwaponline.com/wst/article-abstract/82/12/2635/75838
99;RlE1Chh9FRoJ;Adversarial attacks on neural network policies ;https://arxiv.org/abs/1702.02284
100;d5mrNvNcRGoJ;Deep reinforcement learning based mobile robot navigation: A review ;https://ieeexplore.ieee.org/abstract/document/9409758/
101;VFhahKR_hzIJ;Maven: Multi-agent variational exploration ;https://proceedings.neurips.cc/paper/2019/hash/f816dc0acface7498e10496222e9db10-Abstract.html
102;UDxLVwfeLGMJ;Wireless network intelligence at the edge ;https://ieeexplore.ieee.org/abstract/document/8865093,
103;90YnUo-Qqq8J;Thirty years of machine learning: The road to Pareto-optimal wireless networks ;https://ieeexplore.ieee.org/abstract/document/8957702/
104;zCWnwF7qn4MJ;Stochastic latent actor-critic: Deep reinforcement learning with a latent variable model ;https://proceedings.neurips.cc/paper/2020/hash/08058bf500242562c0d031ff830ad094-Abstract.html
105;ljqVj9Pm070J;Deeppath: A reinforcement learning method for knowledge graph reasoning ;https://arxiv.org/abs/1707.06690
106;kNpTul0u9AsJ;Universal value function approximators ;https://proceedings.mlr.press/v37/schaul15.html
107;Wl6vf1HjHLIJ;Advances and challenges in conversational recommender systems: A survey ;https://www.sciencedirect.com/science/article/pii/S2666651021000164
108;VK7xPyl_ZR0J;Deep learning ;https://books.google.com/books?hl=en&lr=&id=b06qDwAAQBAJ&oi=fnd&pg=PP9&ots=_oIZWRp_YL&sig=IT-QMCDiTooqRefvRRFWAU5iYzM
109;yT4IbWh7cHgJ;A review of reinforcement learning based energy management systems for electrified powertrains: Progress, challenge, and potential solution ;https://www.sciencedirect.com/science/article/pii/S136403212101100X
110;_BHyBBWfiIIJ;Explainability in deep reinforcement learning ;https://www.sciencedirect.com/science/article/pii/S0950705120308145
111;IYI1f_IObT0J;Survey of deep reinforcement learning for motion planning of autonomous vehicles ;https://ieeexplore.ieee.org/abstract/document/9210154/
112;6KvjVDtAPP4J;Deep learning enabled inverse design in nanophotonics ;https://www.degruyter.com/document/doi/10.1515/nanoph-2019-0474/html
113;CAqdzR0vmGsJ;Action-conditional video prediction using deep networks in atari games ;https://proceedings.neurips.cc/paper/2015/hash/6ba3af5d7b2790e73f0de32e5c8c1798-Abstract.html
114;ZHXw-x3IgAoJ;Reinforcement Learning-based control using Q-learning and gravitational search algorithm with experimental validation on a nonlinear servo system ;https://www.sciencedirect.com/science/article/pii/S002002552101094X
115;pVESDLgWvN8J;Edge learning for B5G networks with distributed signal processing: Semantic communication, edge computing, and wireless sensing ;https://ieeexplore.ieee.org/abstract/document/10024766/
116;JYVTtjInECMJ;On large-batch training for deep learning: Generalization gap and sharp minima ;https://arxiv.org/abs/1609.04836
117;kJKBrRGuQfMJ;Dynamics-aware unsupervised discovery of skills ;https://arxiv.org/abs/1907.01657
118;jgNec221jUMJ;A genetic programming approach to designing convolutional neural network architectures ;https://dl.acm.org/doi/abs/10.1145/3071178.3071229
119;vevTpR1UH4wJ;Autonomous experimentation systems for materials development: A community perspective ;https://www.cell.com/matter/pdf/S2590-2385(21)00306-4.pdf
120;1yFCQPXztKQJ;Multiagent cooperation and competition with deep reinforcement learning ;https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0172395
121;Q6rYIKJ7nuYJ;Mlperf training benchmark ;https://proceedings.mlsys.org/paper_files/paper/2020/hash/411e39b117e885341f25efb8912945f7-Abstract.html
122;6V_FqZcWCEAJ;Implicit generation and modeling with energy based models ;https://proceedings.neurips.cc/paper/2019/hash/378a063b8fdb1db941e34f4bde584c7d-Abstract.html
123;N_-FVS2e2hIJ;Measuring catastrophic forgetting in neural networks ;https://ojs.aaai.org/index.php/AAAI/article/view/11651
124;NYbX_3MR8FUJ;The application of two-level attention models in deep convolutional neural network for fine-grained image classification ;http://openaccess.thecvf.com/content_cvpr_2015/html/Xiao_The_Application_of_2015_CVPR_paper.html
125;VIbuEcuom7oJ;Lifelong machine learning ;https://link.springer.com/book/10.1007/978-3-031-01581-6
126;yL_oyofmQiMJ;Action-decision networks for visual tracking with deep reinforcement learning ;http://openaccess.thecvf.com/content_cvpr_2017/html/Yun_Action-Decision_Networks_for_CVPR_2017_paper.html
127;27D-KjlM_tYJ;Q-learning algorithms: A comprehensive classification and applications ;https://ieeexplore.ieee.org/abstract/document/8836506/
128;0jTnEVnntKEJ;A systematic review on overfitting control in shallow and deep neural networks ;https://link.springer.com/article/10.1007/s10462-021-09975-1
129;d5QS_41OZ7EJ;Real-time intermediate flow estimation for video frame interpolation ;https://link.springer.com/chapter/10.1007/978-3-031-19781-9_36
130;3pPKDwnVh0gJ;Benchmarking model-based reinforcement learning ;https://arxiv.org/abs/1907.02057
131;OMqyWBrRvWoJ;The role of ai, machine learning, and big data in digital twinning: A systematic literature review, challenges, and opportunities ;https://ieeexplore.ieee.org/abstract/document/9359733/
132;rR3_9LPYjjIJ;Top-k off-policy correction for a REINFORCE recommender system ;https://dl.acm.org/doi/abs/10.1145/3289600.3290999
133;o4w0HmIuPfkJ;Single and multi-agent deep reinforcement learning for AI-enabled wireless networks: A tutorial ;https://ieeexplore.ieee.org/abstract/document/9372298/
134;xgyi1fOnr4gJ;Responsive safety in reinforcement learning by pid lagrangian methods ;https://proceedings.mlr.press/v119/stooke20a.html
135;BhvvskYihiMJ;Integrated networking, caching, and computing for connected vehicles: A deep reinforcement learning approach ;https://ieeexplore.ieee.org/abstract/document/8061008/
136;tHAjjAXikJUJ;Deep learning for intelligent transportation systems: A survey of emerging trends ;https://ieeexplore.ieee.org/abstract/document/8771378/
137;6w-Te_8mBv4J;Comprehensive survey on machine learning in vehicular network: Technology, applications and challenges ;https://ieeexplore.ieee.org/abstract/document/9463461/
138;ygniRjWJMLcJ;Artificial intelligence, machine learning, deep learning, and cognitive computing: what do these terms mean and how will they impact health care? ;https://www.sciencedirect.com/science/article/pii/S0883540318302158
139;B2u62TU5hDAJ;Compute trends across three eras of machine learning ;https://ieeexplore.ieee.org/abstract/document/9891914/
140;QIDm35qtNAgJ;Artificial intelligence and machine learning as business tools: A framework for diagnosing value destruction potential ;https://www.sciencedirect.com/science/article/pii/S0007681319301570
141;lrj3qq_-hCkJ;Multi-UAV-enabled load-balance mobile-edge computing for IoT networks ;https://ieeexplore.ieee.org/abstract/document/8981986/
142;c1EZzgfgrZoJ;Dynamic scheduling for flexible job shop with new job insertions by deep reinforcement learning ;https://www.sciencedirect.com/science/article/pii/S1568494620301484
143;HJSb9-sZZZ8J;Playing FPS games with deep reinforcement learning ;https://ojs.aaai.org/index.php/AAAI/article/view/10827
144;qaW0bB1tKU0J;Learning to track: Online multi-object tracking by decision making ;https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Xiang_Learning_to_Track_ICCV_2015_paper.html
145;eDODKECKtZwJ;A lyapunov-based approach to safe reinforcement learning ;https://proceedings.neurips.cc/paper/8032-a-lyapunov-based-approach-to-safe-reinforcement-learning
146;cGLrlHTLX5YJ;Advances in adversarial attacks and defenses in computer vision: A survey ;https://ieeexplore.ieee.org/abstract/document/9614158/
147;SziFyAa2Di4J;Pre-trained language models for interactive decision-making ;https://proceedings.neurips.cc/paper_files/paper/2022/hash/ca3b1f24fc0238edf5ed1ad226b9d655-Abstract-Conference.html
148;jAiH3WTPeQgJ;A review of cooperative multi-agent deep reinforcement learning ;https://link.springer.com/article/10.1007/s10489-022-04105-y
149;OPTs80NDmMkJ;Application of deep reinforcement learning to intrusion detection for supervised problems ;https://www.sciencedirect.com/science/article/pii/S0957417419306815
150;22HkodFgZPoJ;On tiny episodic memories in continual learning ;https://arxiv.org/abs/1902.10486
151;_tLVaJlwuGQJ;Policy distillation ;https://arxiv.org/abs/1511.06295
152;2PHPY-8t1PAJ;A systematic dnn weight pruning framework using alternating direction method of multipliers ;http://openaccess.thecvf.com/content_ECCV_2018/html/Tianyun_Zhang_A_Systematic_DNN_ECCV_2018_paper.html
153;R7abFc2aXWMJ;Visual foresight: Model-based deep reinforcement learning for vision-based robotic control ;https://arxiv.org/abs/1812.00568
154;oWRu-NkMBAkJ;Conversational recommender system ;https://dl.acm.org/doi/abs/10.1145/3209978.3210002
155;RNcOCuJuEh4J;Improving sample efficiency in model-free reinforcement learning from images ;https://ojs.aaai.org/index.php/AAAI/article/view/17276
156;Tq8lWeI2j2kJ;Graph neural network and reinforcement learning for multi‐agent cooperative control of connected autonomous vehicles ;https://onlinelibrary.wiley.com/doi/abs/10.1111/mice.12702
157;hKYj8hhyrsIJ;Way off-policy batch deep reinforcement learning of implicit human preferences in dialog ;https://arxiv.org/abs/1907.00456
158;NiFkzzG6R4MJ;Jump-start reinforcement learning ;https://proceedings.mlr.press/v202/uchendu23a.html
159;uQa26F4xvg8J;Deep neural networks for bot detection ;https://www.sciencedirect.com/science/article/pii/S0020025518306248
160;djYEPgdgj0sJ;Federated learning in edge computing: a systematic survey ;https://www.mdpi.com/1424-8220/22/2/450
161;v2DGB246UQYJ;A new approach for arrhythmia classification using deep coded features and LSTM networks ;https://www.sciencedirect.com/science/article/pii/S0169260718314329
162;R4QYyTJGAqEJ;Multi-hop knowledge graph reasoning with reward shaping ;https://arxiv.org/abs/1808.10568
163;U2A3sR9U2YIJ;A study on overfitting in deep reinforcement learning ;https://arxiv.org/abs/1804.06893
164;6lVVO7RFP-8J;Rule-interposing deep reinforcement learning based energy management strategy for power-split hybrid electric vehicle ;https://www.sciencedirect.com/science/article/pii/S0360544220304047
165;uU6dV0lmcpAJ;Exponential expressivity in deep neural networks through transient chaos ;https://proceedings.neurips.cc/paper/2016/hash/148510031349642de5ca0c544f31b2ef-Abstract.html
166;a4_U-4xhmsUJ;An efficient graph convolutional network technique for the travelling salesman problem ;https://arxiv.org/abs/1906.01227
167;tx9iK-GS_s0J;Differentiable mpc for end-to-end planning and control ;https://proceedings.neurips.cc/paper/2018/hash/ba6d843eb4251a4526ce65d1807a9309-Abstract.html
168;9ozHrIOt_ygJ;Deep reinforcement learning for cyber security ;https://ieeexplore.ieee.org/abstract/document/9596578/
169;zR_6-yWXJbUJ;Deep reinforcement learning and its neuroscientific implications ;https://www.cell.com/neuron/pdf/S0896-6273(20)30468-2.pdf
170;G_tXQcNVu8EJ;Imagination-augmented agents for deep reinforcement learning ;https://proceedings.neurips.cc/paper/2017/hash/9e82757e9a1c12cb710ad680db11f6f1-Abstract.html
171;NEXwjomUDFgJ;Deep reinforcement learning for unsupervised video summarization with diversity-representativeness reward ;https://ojs.aaai.org/index.php/AAAI/article/view/12255
172;4nBV94AELqgJ;Implementation matters in deep policy gradients: A case study on ppo and trpo ;https://arxiv.org/abs/2005.12729
173;J7PUtsE8nDQJ;Deep spatial autoencoders for visuomotor learning ;https://ieeexplore.ieee.org/abstract/document/7487173/
174;ON7qh9ujiWkJ;Jointly dampening traffic oscillations and improving energy consumption with electric, connected and automated vehicles: a reinforcement learning based … ;https://www.sciencedirect.com/science/article/pii/S0306261919317179
175;BEGEVN7FA3AJ;Cooperative exploration for multi-agent deep reinforcement learning ;http://proceedings.mlr.press/v139/liu21j.html
176;779LPEcZfGkJ;Deep reinforcement learning for task offloading in mobile edge computing systems ;https://ieeexplore.ieee.org/abstract/document/9253665/
177;q35wP0HmVrAJ;Massively parallel methods for deep reinforcement learning ;https://arxiv.org/abs/1507.04296
178;1rfpkbrsSl4J;Stabilizing deep q-learning with convnets and vision transformers under data augmentation ;https://proceedings.neurips.cc/paper_files/paper/2021/hash/1e0f65eb20acbfb27ee05ddc000b50ec-Abstract.html
179;lbcyQK59A6gJ;Sample-efficient reinforcement learning with stochastic ensemble value expansion ;https://proceedings.neurips.cc/paper/2018/hash/f02208a057804ee16ac72ff4d3cec53b-Abstract.html
180;l2He5gbY6PIJ;Reinforcement learning for UAV attitude control ;https://dl.acm.org/doi/abs/10.1145/3301273
181;aQAiXwb-8QcJ;Contrastive learning as goal-conditioned reinforcement learning ;https://proceedings.neurips.cc/paper_files/paper/2022/hash/e7663e974c4ee7a2b475a4775201ce1f-Abstract-Conference.html
182;R0ZnYXIbpxwJ;Resilient machine learning for networked cyber physical systems: A survey for machine learning security to securing machine learning for CPS ;https://ieeexplore.ieee.org/abstract/document/9252851/
183;pex28U1GfjIJ;Artificial intelligence techniques for stability analysis and control in smart grids: Methodologies, applications, challenges and future directions ;https://www.sciencedirect.com/science/article/pii/S0306261920312228
184;nSTfBzorh1UJ;A review of the application of machine learning and data mining approaches in continuum materials mechanics ;https://www.frontiersin.org/articles/10.3389/fmats.2019.00110/full
185;mldcnQxHoicJ;Deep reinforcement learning for dynamic computation offloading and resource allocation in cache-assisted mobile edge computing systems ;https://ieeexplore.ieee.org/abstract/document/9310745/
186;jO5l16QUoJoJ;3D UAV trajectory design and frequency band allocation for energy-efficient and fair communication: A deep reinforcement learning approach ;https://ieeexplore.ieee.org/abstract/document/9171468/
187;z5mviSIXKjQJ;Blockchain-enabled data collection and sharing for industrial IoT with deep reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/8594641/
188;mXO6i8N2jCgJ;Coordinated load frequency control of multi-area integrated energy system using multi-agent deep reinforcement learning ;https://www.sciencedirect.com/science/article/pii/S0306261921012137
189;Sic2kq68rD0J;Uncertainty weighted actor-critic for offline reinforcement learning ;https://arxiv.org/abs/2105.08140
190;oxCRH-hpzLQJ;Artificial neural networks trained through deep reinforcement learning discover control strategies for active flow control ;https://www.cambridge.org/core/journals/journal-of-fluid-mechanics/article/artificial-neural-networks-trained-through-deep-reinforcement-learning-discover-control-strategies-for-active-flow-control/D5B80D809DFFD73760989A07F5E11039
191;7j-Wpkzee-4J;An end-to-end automatic cloud database tuning system using deep reinforcement learning ;https://dl.acm.org/doi/abs/10.1145/3299869.3300085
192;9LYcXsDTbkkJ;Evolving curricula with regret-based environment design ;https://proceedings.mlr.press/v162/parker-holder22a.html
193;qm7Spv7Mf3kJ;Reinforcement learning in feature space: Matrix bandit, kernels, and regret bound ;https://proceedings.mlr.press/v119/yang20h.html
194;_rUb20Mvnu4J;A dynamic pricing demand response algorithm for smart grid: Reinforcement learning approach ;https://www.sciencedirect.com/science/article/pii/S0306261918304112
195;5EXfh_hcqVYJ;Dualdice: Behavior-agnostic estimation of discounted stationary distribution corrections ;https://proceedings.neurips.cc/paper_files/paper/2019/file/cf9a242b70f45317ffd281241fa66502-Paper.pdf
196;k-VdTwcs0VQJ;Model-free deep reinforcement learning for urban autonomous driving ;https://ieeexplore.ieee.org/abstract/document/8917306/
197;DXzCp_KQvp0J;Lidarsim: Realistic lidar simulation by leveraging the real world ;http://openaccess.thecvf.com/content_CVPR_2020/html/Manivasagam_LiDARsim_Realistic_LiDAR_Simulation_by_Leveraging_the_Real_World_CVPR_2020_paper.html
198;F39iIOPF03YJ;Learning to schedule job-shop problems: representation and policy learning using graph neural network and reinforcement learning ;https://www.tandfonline.com/doi/abs/10.1080/00207543.2020.1870013
199;22FixEiffJMJ;Bridging the gap between value and policy based reinforcement learning ;https://proceedings.neurips.cc/paper_files/paper/2017/hash/facf9f743b083008a894eee7baa16469-Abstract.html
200;JLiZawlVdwsJ;The modern mathematics of deep learning ;https://www.cambridge.org/core/services/aop-cambridge-core/content/view/7C3874F83A5D934E5FDC984B8457D553/stamped-9781316516782c1_1-111.pdf/modern_mathematics_of_deep_learning.pdf
201;wxCDOExFvlIJ;Offline rl policies should be trained to be adaptive ;https://proceedings.mlr.press/v162/ghosh22a.html
202;ge1z3XZEMewJ;Deep reinforcement learning for dynamic multichannel access in wireless networks ;https://ieeexplore.ieee.org/abstract/document/8303773/
203;dvb2jo5pl24J;Selective experience replay for lifelong learning ;https://ojs.aaai.org/index.php/AAAI/article/view/11595
204;HcUDDuAEa9cJ;Application of deep learning to cybersecurity: A survey ;https://www.sciencedirect.com/science/article/pii/S0925231219302954
205;And_2z1rBrUJ;Input convex neural networks ;http://proceedings.mlr.press/v70/amos17b.html?ref=https://githubhelp.com
206;ynArPEHK9AIJ;Semisupervised deep reinforcement learning in support of IoT and smart city services ;https://ieeexplore.ieee.org/abstract/document/7945258/
207;FWrxvGGuEMUJ;Multi-DQN: An ensemble of Deep Q-learning agents for stock market forecasting ;https://www.sciencedirect.com/science/article/pii/S0957417420306321
208;R2_4bY4tDxAJ;Whole building energy model for HVAC optimal control: A practical framework based on deep reinforcement learning ;https://www.sciencedirect.com/science/article/pii/S0378778818330858
209;PQSLNSatVvUJ;Auto: Scaling deep reinforcement learning for datacenter-scale automatic traffic optimization ;https://dl.acm.org/doi/abs/10.1145/3230543.3230551
210;Kkr7bmfmNwQJ;Learning for a robot: Deep reinforcement learning, imitation learning, transfer learning ;https://www.mdpi.com/1424-8220/21/4/1278
211;k_u7_-XCLIcJ;Machine learning: Overview of the recent progresses and implications for the process systems engineering field ;https://www.sciencedirect.com/science/article/pii/S0098135417303538
212;7ox8R6ECZVkJ;Unsupervised state representation learning in atari ;https://proceedings.neurips.cc/paper_files/paper/2019/hash/6fb52e71b837628ac16539c1ff911667-Abstract.html
213;NmA3iQY6v04J;Deep learning for NLP and speech recognition ;https://link.springer.com/content/pdf/10.1007/978-3-030-14596-5.pdf
214;GWqsLIFhtiYJ;Deep learning empowered task offloading for mobile edge computing in urban informatics ;https://ieeexplore.ieee.org/abstract/document/8660505/
215;7ORbsoPMqqMJ;Artificial intelligence for games ;https://books.google.com/books?hl=en&lr=&id=4CLOBgAAQBAJ&oi=fnd&pg=PP1&ots=6b1IDP-SI0&sig=WP0akRz6mD0ccIic_ExsfbG3kkU
216;owpY5Gj687wJ;Deep reinforcement learning for strategic bidding in electricity markets ;https://ieeexplore.ieee.org/abstract/document/8805177/
217;s9JDTiK26iYJ;What matters in on-policy reinforcement learning? a large-scale empirical study ;https://arxiv.org/abs/2006.05990
218;tUPSg2ddHJAJ;Classic meets modern: A pragmatic learning-based congestion control for the internet ;https://dl.acm.org/doi/abs/10.1145/3387514.3405892
219;Lshwcghzf1wJ;Deep reinforcement learning: an overview ;https://link.springer.com/chapter/10.1007/978-3-319-56991-8_32
220;m7uk_5K0AegJ;Algaedice: Policy gradient from arbitrary experience ;https://arxiv.org/abs/1912.02074
221;EyGPHzj3VC8J;Learning deep control policies for autonomous aerial vehicles with mpc-guided policy search ;https://ieeexplore.ieee.org/abstract/document/7487175/
222;ypDUJmzcTG8J;World models ;https://arxiv.org/abs/1803.10122
223;tRqsatOpasAJ;A survey of embodied ai: From simulators to research tasks ;https://ieeexplore.ieee.org/abstract/document/9687596/
224;GxKE5dv61MAJ;Deep reinforcement learning for resource protection and real-time detection in IoT environment ;https://ieeexplore.ieee.org/abstract/document/9000524/
225;1pvRP2fYejAJ;Deep multi-user reinforcement learning for distributed dynamic spectrum access ;https://ieeexplore.ieee.org/abstract/document/8532121/
226;CbaphB75wiIJ;A large-scale study of representation learning with the visual task adaptation benchmark ;https://arxiv.org/abs/1910.04867
227;2SnN0U3pRGUJ;Causal confusion in imitation learning ;https://proceedings.neurips.cc/paper_files/paper/2019/hash/947018640bf36a2bb609d3557a285329-Abstract.html
228;R74PhYT1TGMJ;Recommendations with negative feedback via pairwise deep reinforcement learning ;https://dl.acm.org/doi/abs/10.1145/3219819.3219886
229;YELrNSuJV9AJ;Recent advances and challenges in task-oriented dialog systems ;https://link.springer.com/article/10.1007/s11431-020-1692-3
230;Omsj9FdA3IgJ;Deep learning the electromagnetic properties of metamaterials—a comprehensive review ;https://onlinelibrary.wiley.com/doi/abs/10.1002/adfm.202101748
231;K6AnK4cOZbMJ;Deep reinforcement learning for trading ;https://jfds.pm-research.com/content/early/2020/03/16/jfds.2020.1.030.abstract
232;6lJfC0KmtvYJ;Search on the replay buffer: Bridging planning and reinforcement learning ;https://proceedings.neurips.cc/paper/2019/hash/5c48ff18e0a47baaf81d8b8ea51eec92-Abstract.html
233;5Dy6t-_j5q0J;Continuous reinforcement learning of energy management with deep Q network for a power split hybrid electric bus ;https://www.sciencedirect.com/science/article/pii/S0306261918304422
234;sDbsrRTdhHQJ;Interpretable end-to-end urban autonomous driving with latent deep reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/9346000/
235;Fo1_Tsp55rIJ;Navigating occluded intersections with autonomous vehicles using deep reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/8461233/
236;66qBPmwB1z4J;Evaluation of deep learning models for multi-step ahead time series prediction ;https://ieeexplore.ieee.org/abstract/document/9444453/
237;2u8dpcFadu8J;Space: Unsupervised object-oriented scene representation via spatial attention and decomposition ;https://arxiv.org/abs/2001.02407
238;sQlN8IzuOmEJ;Self-supervised deep reinforcement learning with generalized computation graphs for robot navigation ;https://ieeexplore.ieee.org/abstract/document/8460655/
239;d1wLPmZKPlcJ;A review of deep learning methods and applications for unmanned aerial vehicles ;https://www.hindawi.com/journals/js/2017/3296874/abs/
240;_aq9yRkxGhEJ;Meta-gradient reinforcement learning ;https://proceedings.neurips.cc/paper/2018/hash/2715518c875999308842e3455eda2fe3-Abstract.html
241;FHNimWC0BRAJ;Deep reinforcement learning in medical imaging: A literature review ;https://www.sciencedirect.com/science/article/pii/S1361841521002395
242;6pveRFfsMUsJ;Implicit generation and generalization in energy-based models ;https://arxiv.org/abs/1903.08689
243;r_8msqHCsk4J;Randomised controlled trial of WISENSE, a real-time quality improving system for monitoring blind spots during esophagogastroduodenoscopy ;https://gut.bmj.com/content/68/12/2161.abstract
244;WfQGdnG5VxEJ;Smarts: Scalable multi-agent reinforcement learning training school for autonomous driving ;https://arxiv.org/abs/2010.09776
245;W9TB43SDqkQJ;Artificial intelligence in the creative industries: a review ;https://link.springer.com/article/10.1007/s10462-021-10039-7
246;4JSvGGrWJe0J;Multi-objective workflow scheduling with deep-Q-network-based multi-agent reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/8676306/
247;pGD-3uAZWTwJ;Reinforcement learning in sustainable energy and electric systems: A survey ;https://www.sciencedirect.com/science/article/pii/S1367578820300079
248;PQzMXHE-jSkJ;Review of the state of the art of deep learning for plant diseases: A broad analysis and discussion ;https://www.mdpi.com/2223-7747/9/10/1302
249;g7toW1jRKXMJ;Deep reinforcement learning based volt-var optimization in smart distribution systems ;https://ieeexplore.ieee.org/abstract/document/9143169/
250;cWTCTO4xt2sJ;Sentiment analysis using deep learning approaches: an overview ;https://link.springer.com/article/10.1007/s11432-018-9941-6
251;VMYRRFYC4WsJ;Machine learning for wireless communications in the Internet of Things: A comprehensive survey ;https://www.sciencedirect.com/science/article/pii/S1570870519300812
252;6pTwBR6QtwQJ;Towards real-time path planning through deep reinforcement learning for a UAV in dynamic environments ;https://link.springer.com/article/10.1007/s10846-019-01073-3
253;tPpDYIoDTdMJ;FP-BNN: Binarized neural network on FPGA ;https://www.sciencedirect.com/science/article/pii/S0925231217315655
254;763e88_5PI4J;Machine learning in the air ;https://ieeexplore.ieee.org/abstract/document/8839651/
255;q_eGpbMeDP8J;Learning modular neural network policies for multi-task and multi-robot transfer ;https://ieeexplore.ieee.org/abstract/document/7989250/
256;TP06bWS-mN4J;Deep reinforcement learning for 5G networks: Joint beamforming, power control, and interference coordination ;https://ieeexplore.ieee.org/abstract/document/8938771/
257;MXUdIoS90uIJ;A scheduling scheme in the cloud computing environment using deep Q-learning ;https://www.sciencedirect.com/science/article/pii/S0020025519309971
258;PUGQHIDngw8J;Learning combinatorial optimization on graphs: A survey with applications to networking ;https://ieeexplore.ieee.org/abstract/document/9125934/
259;7IenItVxhWkJ;Split computing and early exiting for deep learning applications: Survey and research challenges ;https://dl.acm.org/doi/abs/10.1145/3527155
260;LWZlPN-rnAYJ;Reward learning from human preferences and demonstrations in atari ;https://proceedings.neurips.cc/paper_files/paper/2018/hash/8cbe9ce23f42628c98f80fa0fac8b19a-Abstract.html
261;4nunaZ8kwc8J;Randomized ensembled double q-learning: Learning fast without a model ;https://arxiv.org/abs/2101.05982
262;yaPhRQBItgMJ;Iq-learn: Inverse soft-q learning for imitation ;https://proceedings.neurips.cc/paper/2021/hash/210f760a89db30aa72ca258a3483cc7f-Abstract.html
263;Y2bChH9ay34J;Next-generation deep learning based on simulators and synthetic data ;https://www.cell.com/trends/cognitive-sciences/fulltext/S1364-6613(21)00293-X
264;NpE6XT44LtgJ;Traffic light control using deep policy‐gradient and value‐function‐based reinforcement learning ;https://ietresearch.onlinelibrary.wiley.com/doi/abs/10.1049/iet-its.2017.0153
265;nup4eWmWJZ0J;Relational neural expectation maximization: Unsupervised discovery of objects and their interactions ;https://arxiv.org/abs/1802.10353
266;R_umPfE6uhwJ;Multi-task reinforcement learning with soft modularization ;https://proceedings.neurips.cc/paper_files/paper/2020/hash/32cfdce9631d8c7906e8e9d6e68b514b-Abstract.html
267;WRP9F9DyWW4J;Hyperbolic deep neural networks: A survey ;https://ieeexplore.ieee.org/abstract/document/9658224/
268;bAqmnP5xSI0J;Continual learning with tiny episodic memories ;https://ora.ox.ac.uk/objects/uuid:6e7580c4-85c9-4874-a52d-e4184046935c
269;8Wjjn0U4Wh4J;Deep learning for electronic health records: A comparative review of multiple deep neural architectures ;https://www.sciencedirect.com/science/article/pii/S1532046419302564
270;t8QRlPn-NucJ;Replay in deep learning: Current approaches and missing biological elements ;https://direct.mit.edu/neco/article-abstract/33/11/2908/107071
271;6r9B1Yxc58kJ;Learning to optimize join queries with deep reinforcement learning ;https://arxiv.org/abs/1808.03196
272;3RM9PN73_hkJ;Cooperative multiagent deep reinforcement learning for reliable surveillance via autonomous multi-UAV control ;https://ieeexplore.ieee.org/abstract/document/9682599/
273;8ufop_OSYkQJ;Advanced planning for autonomous vehicles using reinforcement learning and deep inverse reinforcement learning ;https://www.sciencedirect.com/science/article/pii/S0921889018302021
274;m8Sks_DRSGgJ;Fiber laser development enabled by machine learning: review and prospect ;https://link.springer.com/article/10.1186/s43074-022-00055-3
275;9YvxGW3tRtUJ;Robust active flow control over a range of Reynolds numbers using an artificial neural network trained through deep reinforcement learning ;https://pubs.aip.org/aip/pof/article/32/5/053605/1033993
276;ssVUoUPhZLcJ;Reinforced model predictive control (RL-MPC) for building energy management ;https://www.sciencedirect.com/science/article/pii/S0306261921015932
277;QKR5FE1vJJ8J;Greedynas: Towards fast one-shot nas with greedy supernet ;http://openaccess.thecvf.com/content_CVPR_2020/html/You_GreedyNAS_Towards_Fast_One-Shot_NAS_With_Greedy_Supernet_CVPR_2020_paper.html
278;PGoRkoTsVIYJ;Deep reinforcement learning: a survey ;https://link.springer.com/article/10.1631/FITEE.1900533
279;_dT-J1Dd_YIJ;A gentle introduction to reinforcement learning and its application in different fields ;https://ieeexplore.ieee.org/abstract/document/9261348/
280;sHF3twEqrP8J;Deep reinforcement learning in production systems: a systematic literature review ;https://www.tandfonline.com/doi/abs/10.1080/00207543.2021.1973138
281;TrKS1suAX5sJ;Deep-reinforcement-learning-based images segmentation for quantitative analysis of gold immunochromatographic strip ;https://www.sciencedirect.com/science/article/pii/S0925231220305385
282;XmMmAgwf0-kJ;DMRO: A deep meta reinforcement learning-based task offloading framework for edge-cloud computing ;https://ieeexplore.ieee.org/abstract/document/9448034/
283;lviehWy197sJ;A deep reinforcement learning chatbot ;https://arxiv.org/abs/1709.02349
284;DaHPL7Y1pA4J;Deep reinforcement learning and the deadly triad ;https://arxiv.org/abs/1812.02648
285;1anqsjoTHSkJ;Policy learning with constraints in model-free reinforcement learning: A survey ;https://par.nsf.gov/biblio/10313521
286;-Ylq2JhZZToJ;Generalization in reinforcement learning with selective noise injection and information bottleneck ;https://proceedings.neurips.cc/paper_files/paper/2019/hash/e2ccf95a7f2e1878fcafc8376649b6e8-Abstract.html
287;m-3JxptFs44J;Projection-based constrained policy optimization ;https://arxiv.org/abs/2010.03152
288;-sc7xxECuQ4J;Learning to be safe: Deep rl with a safety critic ;https://arxiv.org/abs/2010.14603
289;x9GVVUTud2wJ;Lyapunov-based safe policy optimization for continuous control ;https://arxiv.org/abs/1901.10031
290;tX3FFAWoXJUJ;Temporal difference learning for model predictive control ;https://arxiv.org/abs/2203.04955
291;E8lmeet4szwJ;Deep reinforcement learning for high precision assembly tasks ;https://ieeexplore.ieee.org/abstract/document/8202244/
292;wLc5z3Ew5dQJ;Reinforcement learning with general value function approximation: Provably efficient approach via bounded eluder dimension ;https://proceedings.neurips.cc/paper/2020/hash/440924c5948e05070663f88e69e8242b-Abstract.html
293;mf0uYjKzQakJ;An autonomous path planning model for unmanned ships based on deep reinforcement learning ;https://www.mdpi.com/1424-8220/20/2/426
294;okG0YNJDHU0J;Deep reinforcement learning for page-wise recommendations ;https://dl.acm.org/doi/abs/10.1145/3240323.3240374
295;R_H5Vuq7eUIJ;Maximum entropy deep inverse reinforcement learning ;https://arxiv.org/abs/1507.04888
296;P6pdg2rLzOIJ;Deep learning for video game playing ;https://ieeexplore.ieee.org/abstract/document/8632747/
297;-7E5_vxK9K8J;Passgan: A deep learning approach for password guessing ;https://link.springer.com/chapter/10.1007/978-3-030-21568-2_11
298;hX8qZjdkP10J;Smart manufacturing scheduling with edge computing using multiclass deep Q network ;https://ieeexplore.ieee.org/abstract/document/8676376/
299;-JsfHRXVC9cJ;Conservative offline distributional reinforcement learning ;https://proceedings.neurips.cc/paper/2021/hash/a05d886123a54de3ca4b0985b718fb9b-Abstract.html
300;jA-2bV0frroJ;Double Deep -Learning-Based Distributed Operation of Battery Energy Storage System Considering Uncertainties ;https://ieeexplore.ieee.org/abstract/document/8742669/
301;6AMp0JiJlNkJ;A review on deep reinforcement learning for fluid mechanics ;https://www.sciencedirect.com/science/article/pii/S0045793021001407
302;Ltsac3DEbQ8J;Human-in-the-loop artificial intelligence ;http://www.jair.org/index.php/jair/article/view/11345
303;OtQMguzZd7wJ;Effective diversity in population based reinforcement learning ;https://proceedings.neurips.cc/paper/2020/hash/d1dc3a8270a6f9394f88847d7f0050cf-Abstract.html
304;J-M8-vsF_gMJ;Deep learning for real-time Atari game play using offline Monte-Carlo tree search planning ;https://proceedings.neurips.cc/paper_files/paper/2014/hash/8bb88f80d334b1869781beb89f7b73be-Abstract.html
305;B5qLBX0vGKYJ;The serverless computing survey: A technical primer for design architecture ;https://dl.acm.org/doi/abs/10.1145/3508360
306;saDx7WKAODAJ;Machine learning for biochemical engineering: A review ;https://www.sciencedirect.com/science/article/pii/S1369703X21001303
307;xIhFxjQgap0J;What matters for on-policy deep actor-critic methods? a large-scale study ;https://openreview.net/forum?id=nIAxjsniDzg&
308;AiO4cyJrP-cJ;When to use parametric models in reinforcement learning? ;https://proceedings.neurips.cc/paper/2019/hash/1b742ae215adf18b75449c6e272fd92d-Abstract.html
309;neVX5cC3lNsJ;A hierarchical framework of cloud resource allocation and power management using deep reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/7979983/
310;1ZD6qNHgiIQJ;Distributed computation offloading method based on deep reinforcement learning in ICV ;https://www.sciencedirect.com/science/article/pii/S1568494621000314
311;jQLI0ctlRNoJ;Leveraging machine learning in the global fight against money laundering and terrorism financing: An affordances perspective ;https://www.sciencedirect.com/science/article/pii/S0148296320306640
312;XcDan_Ypt9YJ;Designing an adaptive production control system using reinforcement learning ;https://link.springer.com/article/10.1007/s10845-020-01612-y
313;AUO7JfBtwvMJ;Neuroevolution in deep neural networks: Current trends and future challenges ;https://ieeexplore.ieee.org/abstract/document/9383028/
314;0u-wNjEbDfMJ;Chainer: A deep learning framework for accelerating the research cycle ;https://dl.acm.org/doi/abs/10.1145/3292500.3330756
315;zRMzidpfnSYJ;Averaged-dqn: Variance reduction and stabilization for deep reinforcement learning ;http://proceedings.mlr.press/v70/anschel17a.html
316;8gxmewWJzb0J;Exposure: A white-box photo post-processing framework ;https://dl.acm.org/doi/abs/10.1145/3181974
317;PfBT8Q0UdzUJ;Review of deep reinforcement learning for robot manipulation ;https://ieeexplore.ieee.org/abstract/document/8675643/
318;f-sEoesTufIJ;Controlling overestimation bias with truncated mixture of continuous distributional quantile critics ;http://proceedings.mlr.press/v119/kuznetsov20a.html
319;qygqiEQnpbkJ;CATER: A diagnostic dataset for Compositional Actions and TEmporal Reasoning ;https://arxiv.org/abs/1910.04744
320;CgnUvXisys4J;A survey of multi-task deep reinforcement learning ;https://www.mdpi.com/2079-9292/9/9/1363
321;goNMHpiy79AJ;Dynamic multi-objective scheduling for flexible job shop by deep reinforcement learning ;https://www.sciencedirect.com/science/article/pii/S0360835221003934
322;XGUMd2R_ZwkJ;Adversarial attacks and defenses on graphs ;https://dl.acm.org/doi/abs/10.1145/3447556.3447566
323;xsY9zgEWiiAJ;Claws: Clustering assisted weakly supervised learning with normalcy suppression for anomalous event detection ;https://link.springer.com/chapter/10.1007/978-3-030-58542-6_22
324;w0bcInf3r6QJ;Battery-constrained federated edge learning in UAV-enabled IoT for B5G/6G networks ;https://www.sciencedirect.com/science/article/pii/S187449072100118X
325;4v0b_7c2cMQJ;Maximum resilience of artificial neural networks ;https://link.springer.com/chapter/10.1007/978-3-319-68167-2_18
326;icIhYMrxrJ8J;An application of deep reinforcement learning to algorithmic trading ;https://www.sciencedirect.com/science/article/pii/S0957417421000737
327;_f9mzhLf978J;Causalworld: A robotic manipulation benchmark for causal structure and transfer learning ;https://arxiv.org/abs/2010.04296
328;F1M5s6hha3gJ;Robust distant supervision relation extraction via deep reinforcement learning ;https://arxiv.org/abs/1805.09927
329;zb9b6JoVZEgJ;Deep reinforcement learning for the control of robotic manipulation: a focussed mini-review ;https://www.mdpi.com/2218-6581/10/1/22
330;jq6uqVOnp7YJ;Deep variation-structured reinforcement learning for visual relationship and attribute detection ;http://openaccess.thecvf.com/content_cvpr_2017/html/Liang_Deep_Variation-Structured_Reinforcement_CVPR_2017_paper.html
331;SuTy6hYLpN8J;Distributed energy-efficient multi-UAV navigation for long-term communication coverage by deep reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/8676325/
332;--JVwd_AzFMJ;Network planning with deep reinforcement learning ;https://dl.acm.org/doi/abs/10.1145/3452296.3472902
333;ODveOpgKgUoJ;Deep generalized Schrödinger bridge ;https://proceedings.neurips.cc/paper_files/paper/2022/hash/3d17b7f7d52c83ab6e97e2dc0bda2e71-Abstract-Conference.html
334;5S3oTf9W7dUJ;Gendice: Generalized offline estimation of stationary values ;https://arxiv.org/abs/2002.09072
335;XqSdUMm_TeQJ;Generalization in reinforcement learning by soft data augmentation ;https://ieeexplore.ieee.org/abstract/document/9561103/
336;U7dazFq1HkIJ;Learning to route ;https://dl.acm.org/doi/abs/10.1145/3152434.3152441
337;o1tGM_7BDO0J;A novel asynchronous deep reinforcement learning model with adaptive early forecasting method and reward incentive mechanism for short-term load … ;https://www.sciencedirect.com/science/article/pii/S0360544221017400
338;7cQO05-fjjMJ;Reinforcement learning for optimization of variational quantum circuit architectures ;https://proceedings.neurips.cc/paper/2021/hash/9724412729185d53a2e3e7f889d9f057-Abstract.html
339;bazjDmXfdbEJ;Path planning method with improved artificial potential field—a reinforcement learning perspective ;https://ieeexplore.ieee.org/abstract/document/9146273/
340;yyBmYfiUkgQJ;Curious: intrinsically motivated modular multi-goal reinforcement learning ;https://proceedings.mlr.press/v97/colas19a.html
341;dpnDFEa-k_8J;Generative adversarial user model for reinforcement learning based recommendation system ;http://proceedings.mlr.press/v97/chen19f.html
342;9hid_hpgSs0J;Deep reinforcement learning method for demand response management of interruptible load ;https://ieeexplore.ieee.org/abstract/document/8976248/
343;O5u7niXi_d8J;Toward an automated auction framework for wireless federated learning services market ;https://ieeexplore.ieee.org/abstract/document/9094030/
344;0Aj0ZPTeRIwJ;Self-supervised policy adaptation during deployment ;https://arxiv.org/abs/2007.04309
345;gfnhShu4MTkJ;Towards vision-based deep reinforcement learning for robotic motion control ;https://arxiv.org/abs/1511.03791
346;bV_AydyzEZkJ;Cellular network traffic scheduling with deep reinforcement learning ;https://ojs.aaai.org/index.php/AAAI/article/view/11339
347;u-BxglJmaagJ;Causal machine learning: A survey and open problems ;https://arxiv.org/abs/2206.15475
348;MglcYpd3BCgJ;A state-of-the-art review on mobile robotics tasks using artificial intelligence and visual data ;https://www.sciencedirect.com/science/article/pii/S095741742030926X
349;4Qud5gz5cn4J;Scheduling of decentralized robot services in cloud manufacturing with deep reinforcement learning ;https://www.sciencedirect.com/science/article/pii/S0736584522001363
350;2x40zorPhvYJ;Deep reinforcement learning for vision-based robotic grasping: A simulated comparative evaluation of off-policy methods ;https://ieeexplore.ieee.org/abstract/document/8461039/
351;OiqGoFRoeP4J;Chainerrl: A deep reinforcement learning library ;https://dl.acm.org/doi/abs/10.5555/3546258.3546335
352;Tr48L4dZDrgJ;Deep reinforcement learning for sequence-to-sequence models ;https://ieeexplore.ieee.org/abstract/document/8801910/
353;o1CbWGC6DCgJ;Cooperative management for PV/ESS-enabled electric vehicle charging stations: A multiagent deep reinforcement learning approach ;https://ieeexplore.ieee.org/abstract/document/8851270/
354;igQxU0bIlGcJ;A review of deep learning models for time series prediction ;https://ieeexplore.ieee.org/abstract/document/8742529/
355;IWcaaLt5uAgJ;Control systems and reinforcement learning ;https://books.google.com/books?hl=en&lr=&id=UZNsEAAAQBAJ&oi=fnd&pg=PR11&ots=ab9KyW0iZI&sig=fx13bGer65JJEqGM_3dsZz9xPPA
356;cvX-2Z-09kAJ;Robust reinforcement learning: A review of foundations and recent advances ;https://www.mdpi.com/2504-4990/4/1/13
357;uM5U5WixUJIJ;Reinforcement learning to optimize long-term user engagement in recommender systems ;https://dl.acm.org/doi/abs/10.1145/3292500.3330668
358;xhLyWWfb8dwJ;The free energy principle for perception and action: A deep learning perspective ;https://www.mdpi.com/1099-4300/24/2/301
359;Z3RQoONdLAoJ;Logistics-involved QoS-aware service composition in cloud manufacturing with deep reinforcement learning ;https://www.sciencedirect.com/science/article/pii/S0736584520302027
360;8b6Hp6jNbh4J;Exploratory data analysis with MATLAB ;https://books.google.com/books?hl=en&lr=&id=PD0PEAAAQBAJ&oi=fnd&pg=PP1&ots=oXlloBtzl0&sig=X0KiW6uJ6ZXkhscpkUseMNcBFsE
361;UycRP3AYkJMJ;Reinforcement learning with combinatorial actions: An application to vehicle routing ;https://proceedings.neurips.cc/paper/2020/hash/06a9d51e04213572ef0720dd27a84792-Abstract.html
362;EGxC4TrrQXgJ;Model-free quantum control with reinforcement learning ;https://journals.aps.org/prx/abstract/10.1103/PhysRevX.12.011059
363;ubhcftgxq5kJ;Transfer learning in demand response: A review of algorithms for data-efficient modelling and control ;https://www.sciencedirect.com/science/article/pii/S2666546821000732
364;on57kvrdKWsJ;Consistency models ;https://openreview.net/forum?id=FmqFfMTNnv
365;-Ir1DPU3EkcJ;Combining reinforcement learning and constraint programming for combinatorial optimization ;https://ojs.aaai.org/index.php/AAAI/article/view/16484
366;fe68SEe2SwUJ;Help, anna! visual navigation with natural multimodal assistance via retrospective curiosity-encouraging imitation learning ;https://arxiv.org/abs/1909.01871
367;MS342rArKOYJ;Ablation studies in artificial neural networks ;https://arxiv.org/abs/1901.08644
368;qZsIVfAs1oEJ;Reinforcement learning for clinical decision support in critical care: comprehensive review ;https://www.jmir.org/2020/7/e18477/
369;i8EaOLDL-E8J;Dreamshard: Generalizable embedding table placement for recommender systems ;https://proceedings.neurips.cc/paper_files/paper/2022/hash/62302a24b04589f9f9cdd5b02c344b6c-Abstract-Conference.html
370;vVcmcj1ASywJ;Curator:{Self-Managing} Storage for Enterprise Clusters ;https://www.usenix.org/conference/nsdi17/technical-sessions/presentation/cano
371;P27v47uicgQJ;Adaptive Traffic Signal Control for large-scale scenario with Cooperative Group-based Multi-agent reinforcement learning ;https://www.sciencedirect.com/science/article/pii/S0968090X21000760
372;MV0hlfOK9TgJ;Deep dynamic neural networks for multimodal gesture segmentation and recognition ;https://ieeexplore.ieee.org/abstract/document/7423804/
373;G-hSE9S4wYYJ;Operational optimization for off-grid renewable building energy system using deep reinforcement learning ;https://www.sciencedirect.com/science/article/pii/S0306261922010625
374;pB0Q8dSc8JcJ;Learning to solve np-complete problems: A graph neural network for decision tsp ;https://ojs.aaai.org/index.php/AAAI/article/view/4399
375;wUaffXKtTdEJ;RL/DRL meets vehicular task offloading using edge and vehicular cloudlet: A survey ;https://ieeexplore.ieee.org/abstract/document/9723463/
376;jsCRdUYj5AwJ;Urban traffic control in software defined internet of things via a multi-agent deep reinforcement learning approach ;https://ieeexplore.ieee.org/abstract/document/9210820/
377;RuV7ZOZVg4gJ;On-demand deep model compression for mobile devices: A usage-driven model selection framework ;https://dl.acm.org/doi/abs/10.1145/3210240.3210337
378;CRyagBGGoE0J;Automatic collision avoidance of multiple ships based on deep Q-learning ;https://www.sciencedirect.com/science/article/pii/S0141118718302293
379;Psmqvpn4L_4J;Action branching architectures for deep reinforcement learning ;https://ojs.aaai.org/index.php/AAAI/article/view/11798
380;38lWwl675C4J;Neural interactive collaborative filtering ;https://dl.acm.org/doi/abs/10.1145/3397271.3401181
381;BIPu_uzDEzQJ;Breast cancer detection using deep learning: Datasets, methods, and challenges ahead ;https://www.sciencedirect.com/science/article/pii/S0010482522007818
382;_9lASuvb-4EJ;Weakly-supervised disentangling with recurrent transformations for 3d view synthesis ;https://proceedings.neurips.cc/paper_files/paper/2015/hash/109a0ca3bc27f3e96597370d5c8cf03d-Abstract.html
383;WEPoQByCAJgJ;The causal-neural connection: Expressiveness, learnability, and inference ;https://proceedings.neurips.cc/paper_files/paper/2021/hash/5989add1703e4b0480f75e2390739f34-Abstract.html
384;lX54c0dhJ5kJ;Maximum entropy gain exploration for long horizon multi-goal reinforcement learning ;https://proceedings.mlr.press/v119/pitis20a.html
385;fdeeTg7P-b8J;Constrained variational policy optimization for safe reinforcement learning ;https://proceedings.mlr.press/v162/liu22b.html
386;5JcaCFVcx4kJ;Network abnormal traffic detection model based on semi-supervised deep reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/9577211/
387;kZkrsk60C0gJ;Distributive dynamic spectrum access through deep reinforcement learning: A reservoir computing-based approach ;https://ieeexplore.ieee.org/abstract/document/8474348/
388;FxP7q_EV5soJ;Deep reinforcement learning for autonomous driving ;https://arxiv.org/abs/1811.11329
389;_Xjcx6XUWlAJ;Deep reinforcement learning ;https://link.springer.com/content/pdf/10.1007/978-981-13-8285-7.pdf
390;ib0H8y30StkJ;A deep reinforcement learning strategy for UAV autonomous landing on a moving platform ;https://link.springer.com/article/10.1007/s10846-018-0891-8
391;GUS0U9qCBkYJ;Flow: Architecture and benchmarking for reinforcement learning in traffic control ;https://www.researchgate.net/profile/Abdul-Rahman-Kreidieh/publication/320441979_Flow_Architecture_and_Benchmarking_for_Reinforcement_Learning_in_Traffic_Control/links/5cf6c7f4a6fdcc847506322a/Flow-Architecture-and-Benchmarking-for-Reinforcement-Learning-in-Traffic-Control.pdf
392;8ocFmEFRwd4J;Multi-robot path planning method using reinforcement learning ;https://www.mdpi.com/2076-3417/9/15/3057
393;5h_Qe0d5tYYJ;A study of reinforcement learning for neural machine translation ;https://arxiv.org/abs/1808.08866
394;FvBhs3lJBVUJ;Graying the black box: Understanding dqns ;http://proceedings.mlr.press/v48/zahavy16.html
395;S03jxV6TgKcJ;Reinforcement learning based energy management systems and hydrogen refuelling stations for fuel cell electric vehicles: An overview ;https://www.sciencedirect.com/science/article/pii/S0360319922027008
396;i0N56igtdtIJ;Fusing TensorFlow with building energy simulation for intelligent energy management in smart cities ;https://www.sciencedirect.com/science/article/pii/S2210670718314380
397;4yPqblxLbLMJ;Deep reinforcement learning meets graph neural networks: Exploring a routing optimization use case ;https://www.sciencedirect.com/science/article/pii/S0140366422003784
398;YPH1Ax4lnagJ;Bootstrapped meta-learning ;https://arxiv.org/abs/2109.04504
399;p9SpbQTbkUwJ;Cleanrl: High-quality single-file implementations of deep reinforcement learning algorithms ;https://dl.acm.org/doi/abs/10.5555/3586589.3586863
400;2_wvdeI-1rkJ;Neuroevolution of self-interpretable agents ;https://dl.acm.org/doi/abs/10.1145/3377930.3389847
401;9rGun1BauzcJ;Reinforcement learning, bit by bit ;https://www.nowpublishers.com/article/Details/MAL-097
402;FhuTZeJA9P0J;Few-shot preference learning for human-in-the-loop rl ;https://proceedings.mlr.press/v205/iii23a.html
403;5Ks7kMc1N4wJ;Understanding cities with machine eyes: A review of deep computer vision in urban analytics ;https://www.sciencedirect.com/science/article/pii/S0264275119308443
404;rSCtz1MkBRwJ;Video description: A survey of methods, datasets, and evaluation metrics ;https://dl.acm.org/doi/abs/10.1145/3355390
405;CZyRE-KkwyAJ;Deep reinforcement learning for industrial insertion tasks with visual inputs and natural rewards ;https://ieeexplore.ieee.org/abstract/document/9341714/
406;l2VkqX6TU4oJ;Imagination-augmented agents for deep reinforcement learning ;https://arxiv.org/abs/1707.06203
407;bxajuka_tOkJ;Intelligent on-demand design of phononic metamaterials ;https://www.degruyter.com/document/doi/10.1515/nanoph-2021-0639/html
408;qrxT6fmZibwJ;Approximating explicit model predictive control using constrained neural networks ;https://ieeexplore.ieee.org/abstract/document/8431275/
409;z_THu37CVrsJ;A deep convolutional neural network model for automated identification of abnormal EEG signals ;https://link.springer.com/article/10.1007/s00521-018-3889-z
410;vXHJD4y_BN0J;Deep reinforcement learning for automated radiation adaptation in lung cancer ;https://aapm.onlinelibrary.wiley.com/doi/abs/10.1002/mp.12625
411;gn9LR28b_tIJ;Concise deep reinforcement learning obstacle avoidance for underactuated unmanned marine vessels ;https://www.sciencedirect.com/science/article/pii/S0925231217311943
412;9pbZ8tJeJ7sJ;A brief introduction to machine learning for engineers ;https://www.nowpublishers.com/article/Details/SIG-102
413;EGjzcPkrX40J;Vulnerability of deep reinforcement learning to policy induction attacks ;https://link.springer.com/chapter/10.1007/978-3-319-62416-7_19
414;ekyHPViUuoYJ;Reinforcement learning on variable impedance controller for high-precision robotic assembly ;https://ieeexplore.ieee.org/abstract/document/8793506/
415;vHwG-4CErUAJ;Mapping instructions and visual observations to actions with reinforcement learning ;https://arxiv.org/abs/1704.08795
416;-HBrpcrfKb0J;Electric vehicle charging management based on deep reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/9465776/
417;3a4H_htDB9QJ;Adversarial environment reinforcement learning algorithm for intrusion detection ;https://www.sciencedirect.com/science/article/pii/S1389128618311216
418;L7l1ciyhRggJ;Deep reinforcement learning for imbalanced classification ;https://link.springer.com/article/10.1007/s10489-020-01637-z
419;Nz23-iVFW2cJ;Reinforcement learning with tree-lstm for join order selection ;https://ieeexplore.ieee.org/abstract/document/9101694/
420;HI1AkO0IeIUJ;Faster neural networks straight from jpeg ;https://proceedings.neurips.cc/paper/2018/hash/7af6266cc52234b5aa339b16695f7fc4-Abstract.html
421;WtYBLiDphtcJ;Reinforcement learning in dual-arm trajectory planning for a free-floating space robot ;https://www.sciencedirect.com/science/article/pii/S1270963819325660
422;5V8rljoK9QAJ;Pseudo Dyna-Q: A reinforcement learning framework for interactive recommendation ;https://dl.acm.org/doi/abs/10.1145/3336191.3371801
423;oIm1ItKqK-sJ;Migration modeling and learning algorithms for containers in fog computing ;https://ieeexplore.ieee.org/abstract/document/8338124/
424;Li0iEetwj-QJ;Latent space policies for hierarchical reinforcement learning ;https://proceedings.mlr.press/v80/haarnoja18a.html
425;YoIl3w8urS8J;Resource allocation in IoT edge computing via concurrent federated reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/9454444/
426;SkBXCQ2CN5gJ;Unsupervised domain adaptation of object detectors: A survey ;https://ieeexplore.ieee.org/abstract/document/10075484/
427;Whs_iSYeXh4J;Gnu-rl: A precocial reinforcement learning solution for building hvac control using a differentiable mpc policy ;https://dl.acm.org/doi/abs/10.1145/3360322.3360849
428;P-hbd4THw68J;Agent-based modeling in electricity market using deep deterministic policy gradient algorithm ;https://ieeexplore.ieee.org/abstract/document/9106862/
429;sPPXq_ReHrAJ;Orchestrated scheduling and multi-agent deep reinforcement learning for cloud-assisted multi-UAV charging systems ;https://ieeexplore.ieee.org/abstract/document/9364754/
430;-zc7jmlRkzAJ;Rl unplugged: A suite of benchmarks for offline reinforcement learning ;https://proceedings.neurips.cc/paper/2020/hash/51200d29d1fc15f5a71c1dab4bb54f7c-Abstract.html
431;trlCdLVLv-4J;Research on adaptive job shop scheduling problems based on dueling double DQN ;https://ieeexplore.ieee.org/abstract/document/9218934/
432;nQfpTlVHi2YJ;Reinforced Deterministic and Probabilistic Load Forecasting via -Learning Dynamic Model Selection ;https://ieeexplore.ieee.org/abstract/document/8813103/
433;uD8GCi3U26cJ;Considerations for evaluation and generalization in interpretable machine learning ;https://link.springer.com/chapter/10.1007/978-3-319-98131-4_1
434;aWR13i41ReoJ;UAV path planning using optimization approaches: A survey ;https://link.springer.com/article/10.1007/s11831-022-09742-7
435;BvgMkWFxhC8J;Managing engineering systems with large state and action spaces through deep reinforcement learning ;https://www.sciencedirect.com/science/article/pii/S0951832018313309
436;LyRcGtYrlJUJ;Path planning of coastal ships based on optimized DQN reward function ;https://www.mdpi.com/2077-1312/9/2/210
437;mVNl8owNaowJ;DRL-cloud: Deep reinforcement learning-based resource provisioning and task scheduling for cloud service providers ;https://ieeexplore.ieee.org/abstract/document/8297294/
438;3kMCpHTAtYIJ;Active inference: demystified and compared ;https://direct.mit.edu/neco/article-abstract/33/3/674/97486
439;q1zWpeR61gkJ;Improving financial trading decisions using deep Q-learning: Predicting the number of shares, action strategies, and transfer learning ;https://www.sciencedirect.com/science/article/pii/S0957417418306134
440;abfspMj0cSUJ;Evading machine learning malware detection ;https://www.blackhat.com/docs/us-17/thursday/us-17-Anderson-Bot-Vs-Bot-Evading-Machine-Learning-Malware-Detection-wp.pdf
441;e7nJGleeVFAJ;Exploring model-based planning with policy networks ;https://arxiv.org/abs/1906.08649
442;cH5cdN_b0loJ;Tuning-free plug-and-play proximal algorithm for inverse imaging problems ;http://proceedings.mlr.press/v119/wei20b.html
443;hy24a4YsLU0J;Rudder: Return decomposition for delayed rewards ;https://proceedings.neurips.cc/paper_files/paper/2019/hash/16105fb9cc614fc29e1bda00dab60d41-Abstract.html
444;v0sBlHrp3S0J;Deeprobust: A pytorch library for adversarial attacks and defenses ;https://arxiv.org/abs/2005.06149
445;F2jSRKxl4yEJ;Safe deep reinforcement learning-based adaptive control for USV interception mission ;https://www.sciencedirect.com/science/article/pii/S002980182101756X
446;j9XxXfNOzMEJ;Learning to evade static pe machine learning malware models via reinforcement learning ;https://arxiv.org/abs/1801.08917
447;wPEDOmmhycgJ;Mapping instructions to actions in 3d environments with visual goal prediction ;https://arxiv.org/abs/1809.00786
448;lwBW9fyAKloJ;Deep learning at the mobile edge: Opportunities for 5G networks ;https://www.mdpi.com/2076-3417/10/14/4735
449;Krb2JwZPDocJ;Imitation learning for human pose prediction ;http://openaccess.thecvf.com/content_ICCV_2019/html/Wang_Imitation_Learning_for_Human_Pose_Prediction_ICCV_2019_paper.html
450;DKaYDPZ2XyAJ;Reinforcement learning for facilitating human-robot-interaction in manufacturing ;https://www.sciencedirect.com/science/article/pii/S0278612520301084
451;geJTqX5Cqr8J;A hierarchical framework for improving ride comfort of autonomous vehicles via deep reinforcement learning with external knowledge ;https://onlinelibrary.wiley.com/doi/abs/10.1111/mice.12934
452;0KusetJZXNEJ;Learning visual predictive models of physics for playing billiards ;https://arxiv.org/abs/1511.07404
453;OJaEZNJPaTUJ;1.1 the deep learning revolution and its implications for computer architecture and chip design ;https://ieeexplore.ieee.org/abstract/document/9063049/
454;8HC_uir-ajsJ;Multi-objective optimization for UAV-assisted wireless powered IoT networks based on extended DDPG algorithm ;https://ieeexplore.ieee.org/abstract/document/9455139/
455;OVXnrhL_Pn8J;Reinforcement learning neural turing machines-revised ;https://arxiv.org/abs/1505.00521
456;B_wHNGJglcMJ;Deep reinforcement learning for long‐term pavement maintenance planning ;https://onlinelibrary.wiley.com/doi/abs/10.1111/mice.12558
457;mRAysBddGRMJ;Energy optimization associated with thermal comfort and indoor air control via a deep reinforcement learning algorithm ;https://www.sciencedirect.com/science/article/pii/S0360132319302008
458;iuvcEX1EXeoJ;Foundations of deep reinforcement learning ;https://books.google.com/books?hl=en&lr=&id=0HW7DwAAQBAJ&oi=fnd&pg=PT16&ots=1LiFJKwZpo&sig=X-qQ_64Bu4Y84k2F8S-wIxeVCaU
459;ncyJqHdjin8J;Optimization methods for interpretable differentiable decision trees applied to reinforcement learning ;https://proceedings.mlr.press/v108/silva20a.html
460;8VHK4cU8dcYJ;Reinforcement learning in urban network traffic signal control: A systematic literature review ;https://www.sciencedirect.com/science/article/pii/S0957417422002858
461;u1GKFJdNbXEJ;Observational overfitting in reinforcement learning ;https://arxiv.org/abs/1912.02975
462;UR-sYWzRuh0J;Towards optimal control of air handling units using deep reinforcement learning and recurrent neural network ;https://www.sciencedirect.com/science/article/pii/S0360132319307474
463;khBxQomTc2cJ;Going beyond linear transformers with recurrent fast weight programmers ;https://proceedings.neurips.cc/paper_files/paper/2021/hash/3f9e3767ef3b10a0de4c256d7ef9805d-Abstract.html
464;9jMqFOOu_ycJ;Rrl: Resnet as representation for reinforcement learning ;https://arxiv.org/abs/2107.03380
465;72GEdrQAvFUJ;Learning action-oriented models through active inference ;https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1007805
466;KyvKgLSrNv4J;Recent advances in reinforcement learning in finance ;https://onlinelibrary.wiley.com/doi/abs/10.1111/mafi.12382
467;6upCYm1Of1IJ;A digital twin hierarchy for metal additive manufacturing ;https://www.sciencedirect.com/science/article/pii/S0166361522000641
468;6oz8TmB6HJEJ;Dynamic beam hopping method based on multi-objective deep reinforcement learning for next generation satellite broadband systems ;https://ieeexplore.ieee.org/abstract/document/8957062/
469;gckufa_m58kJ;Deep learning in electron microscopy ;https://iopscience.iop.org/article/10.1088/2632-2153/abd614/meta
470;k1YOR1-IdKUJ;The uncertainty bellman equation and exploration ;http://proceedings.mlr.press/v80/o-donoghue18a/o-donoghue18a.pdf
471;hrMBUBhXc5gJ;Cloud-based health-conscious energy management of hybrid battery systems in electric vehicles with deep reinforcement learning ;https://www.sciencedirect.com/science/article/pii/S0306261921004499
472;aoAOdHiv_VwJ;Bigger, Better, Faster: Human-level Atari with human-level efficiency ;https://proceedings.mlr.press/v202/schwarzer23a.html
473;y5F9xZ1WVjQJ;Reinforcement learning for robust trajectory design of interplanetary missions ;https://arc.aiaa.org/doi/abs/10.2514/1.G005794
474;2UQ0lh9Y9D0J;Sobolev training for neural networks ;https://proceedings.neurips.cc/paper_files/paper/2017/hash/758a06618c69880a6cee5314ee42d52f-Abstract.html
475;WivZ5JVAjsAJ;Recurrent relational networks ;https://proceedings.neurips.cc/paper/7597-recurrent-relational-networks
476;etpcCbzoo4QJ;Learning to ground multi-agent communication with autoencoders ;https://proceedings.neurips.cc/paper_files/paper/2021/hash/80fee67c8a4c4989bf8a580b4bbb0cd2-Abstract.html
477;mKiMUAWwFioJ;End-to-end race driving with deep reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/8460934/
478;jRGU44Nl4pgJ;Retrieval-augmented reinforcement learning ;https://proceedings.mlr.press/v162/goyal22a.html
479;eHgg0QYbghgJ;GAN-powered deep distributional reinforcement learning for resource management in network slicing ;https://ieeexplore.ieee.org/abstract/document/8931561/
480;og1uCKZFR98J;Resource optimization for delay-tolerant data in blockchain-enabled IoT with edge computing: A deep reinforcement learning approach ;https://ieeexplore.ieee.org/abstract/document/9136699/
481;IeT6nc2-sXwJ;A deep-network solution towards model-less obstacle avoidance ;https://ieeexplore.ieee.org/abstract/document/7759428/
482;fF2-5DWa1ZIJ;Smart campus: definition, framework, technologies, and services ;https://ietresearch.onlinelibrary.wiley.com/doi/abs/10.1049/iet-smc.2019.0072
483;LxFYRo8_nzEJ;Dynamic energy conversion and management strategy for an integrated electricity and natural gas system with renewable energy: Deep reinforcement … ;https://www.sciencedirect.com/science/article/pii/S0196890420306075
484;MQNagMiPov0J;Energy management of hybrid electric bus based on deep reinforcement learning in continuous state and action space ;https://www.sciencedirect.com/science/article/pii/S019689041930593X
485;VrV1bbZsdsUJ;Learning to simulate dynamic environments with gamegan ;http://openaccess.thecvf.com/content_CVPR_2020/html/Kim_Learning_to_Simulate_Dynamic_Environments_With_GameGAN_CVPR_2020_paper.html
486;igGjGxmmGUIJ;Reinforcement learning with neural radiance fields ;https://proceedings.neurips.cc/paper_files/paper/2022/hash/6c294f059e3d77d58dbb8fe48f21fe00-Abstract-Conference.html
487;uHrHP3hWc_EJ;Intelligent power control for spectrum sharing in cognitive radios: A deep reinforcement learning approach ;https://ieeexplore.ieee.org/abstract/document/8352517/
488;nOfqG6i6KA4J;Measuring the algorithmic efficiency of neural networks ;https://arxiv.org/abs/2005.04305
489;i-3H5nM7pv0J;Key challenges in automation of earth-moving machines ;https://www.sciencedirect.com/science/article/pii/S0926580516300899
490;j54vt-ZrjsQJ;Edge intelligence: A computational task offloading scheme for dependent IoT application ;https://ieeexplore.ieee.org/abstract/document/9733202/
491;W8Ekqu-brUgJ;opengauss: An autonomous database system ;https://dl.acm.org/doi/abs/10.14778/3476311.3476380
492;Dz0wxtI1iCgJ;Quantum circuit optimization with deep reinforcement learning ;https://arxiv.org/abs/2103.07585
493;F2MFU4XY9RgJ;Amortized bayesian meta-learning ;https://openreview.net/forum?id=rkgpy3C5tX
494;wUeBkCwvk3EJ;Maneuvering target tracking of UAV based on MN-DDPG and transfer learning ;https://www.sciencedirect.com/science/article/pii/S2214914720304815
495;dLqfJrbyvPkJ;Deep reinforcement learning based resource allocation in low latency edge computing networks ;https://ieeexplore.ieee.org/abstract/document/8491089/
496;lBpn0gWphFIJ;Age of information aware trajectory planning of UAVs in intelligent transportation systems: A deep learning approach ;https://ieeexplore.ieee.org/abstract/document/9195789/
497;EWORbbJ6fuAJ;A novel DDPG method with prioritized experience replay ;https://ieeexplore.ieee.org/abstract/document/8122622/
498;dV6i5kRR_eQJ;Fault-tolerant federated reinforcement learning with theoretical guarantee ;https://proceedings.neurips.cc/paper/2021/hash/080acdcce72c06873a773c4311c2e464-Abstract.html
499;1dNkN8wqhQUJ;Structured bayesian pruning via log-normal multiplicative noise ;https://proceedings.neurips.cc/paper_files/paper/2017/hash/dab49080d80c724aad5ebf158d63df41-Abstract.html
500;mTDEA31w2L0J;Efficient exploration through bayesian deep q-networks ;https://ieeexplore.ieee.org/abstract/document/8503252/
501;uw7QkHPesXwJ;Tracing the evolution of AI in the past decade and forecasting the emerging trends ;https://www.sciencedirect.com/science/article/pii/S0957417422013732
502;AuEAF_vP3WoJ;A review on reinforcement learning algorithms and applications in supply chain management ;https://www.tandfonline.com/doi/abs/10.1080/00207543.2022.2140221
503;rjX2Gi-5uLEJ;Deep reinforcement learning with its application for lung cancer detection in medical Internet of Things ;https://www.sciencedirect.com/science/article/pii/S0167739X19303772
504;VP7fQFxG7Q4J;Optimal control via neural networks: A convex approach ;https://arxiv.org/abs/1805.11835
505;T0SMx9YFdi0J;Collaborative data scheduling for vehicular edge computing via deep reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/9047880/
506;C3bDTfc4wr0J;In-context reinforcement learning with algorithm distillation ;https://arxiv.org/abs/2210.14215
507;Oj0N0Oy1ihUJ;Hybrid deep reinforcement learning based eco-driving for low-level connected and automated vehicles along signalized corridors ;https://www.sciencedirect.com/science/article/pii/S0968090X21000164
508;5MfyKycEe6cJ;Stabilizing reinforcement learning in dynamic environment with application to online recommendation ;https://dl.acm.org/doi/abs/10.1145/3219819.3220122
509;p5rH5p_NLoIJ;Artificial intelligence inspired transmission scheduling in cognitive vehicular communications and networks ;https://ieeexplore.ieee.org/abstract/document/8471165/
510;J0OoI5RccQIJ;Cross-type transfer for deep reinforcement learning based hybrid electric vehicle energy management ;https://ieeexplore.ieee.org/abstract/document/9105110/
511;NSkQAp2frj8J;Distributed machine learning for wireless communication networks: Techniques, architectures, and applications ;https://ieeexplore.ieee.org/abstract/document/9446488/
512;h4h0DSzOm7EJ;Transforming cooling optimization for green data center via deep reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/8772127/
513;oTmYGwC2ryoJ;Deep reinforcement learning for selecting demand forecast models to empower Industry 3.5 and an empirical study for a semiconductor component distributor ;https://www.tandfonline.com/doi/abs/10.1080/00207543.2020.1733125
514;GmQwJfhmps8J;Confuciux: Autonomous hardware resource assignment for dnn accelerators using reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/9251929/
515;kJiEkHX5PZMJ;From active learning to deep reinforcement learning: Intelligent active flow control in suppressing vortex-induced vibration ;https://pubs.aip.org/aip/pof/article/33/6/063607/1065626
516;Eltrp8TZDiAJ;Adaptive optics based on machine learning: a review ;https://www.researching.cn/ArticlePdf/m00091/2022/5/7/200082.pdf
517;M-c9Ri3u-2oJ;Foundation models for decision making: Problems, methods, and opportunities ;https://arxiv.org/abs/2303.04129
518;5Y4AW7TA-YkJ;One solution is not all you need: Few-shot extrapolation via structured maxent rl ;https://proceedings.neurips.cc/paper/2020/hash/5d151d1059a6281335a10732fc49620e-Abstract.html
519;M0DJ1C6myugJ;A novel deep reinforcement learning controller based type-II fuzzy system: Frequency regulation in microgrids ;https://ieeexplore.ieee.org/abstract/document/8970451/
520;KjU5ZIJcJfIJ;Interpreting deep learning-based networking systems ;https://dl.acm.org/doi/abs/10.1145/3387514.3405859
521;c7q2rfhkFX4J;CIRS: Bursting filter bubbles by counterfactual interactive recommender system ;https://dl.acm.org/doi/abs/10.1145/3594871
522;FmLvMFE5ZzIJ;Time-driven feature-aware jointly deep reinforcement learning for financial signal representation and algorithmic trading ;https://www.sciencedirect.com/science/article/pii/S0957417419305822
523;-bWKhMJtiu4J;Dispatch of autonomous vehicles for taxi services: A deep reinforcement learning approach ;https://www.sciencedirect.com/science/article/pii/S0968090X19312227
524;9yvLv4asV5QJ;Cooperative perception with deep reinforcement learning for connected vehicles ;https://ieeexplore.ieee.org/abstract/document/9304570/
525;ddZc758RuQcJ;Parametrized deep q-networks learning: Reinforcement learning with discrete-continuous hybrid action space ;https://arxiv.org/abs/1810.06394
526;CVk9GrXIQw0J;Show, describe and conclude: On exploiting the structure information of chest x-ray reports ;https://arxiv.org/abs/2004.12274
527;nThiR77Z_J0J;rlpyt: A research code base for deep reinforcement learning in pytorch ;https://arxiv.org/abs/1909.01500
528;KL1wOy3w8EgJ;Deep reinforcement learning for energy-efficient networking with reconfigurable intelligent surfaces ;https://ieeexplore.ieee.org/abstract/document/9149380/
529;Dtz65CG8at4J;Multi-agent connected autonomous driving using deep reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/9207663/
530;XTKphfwxsOMJ;Dynamic deep neural networks: Optimizing accuracy-efficiency trade-offs by selective execution ;https://ojs.aaai.org/index.php/AAAI/article/view/11630
531;cbPW_0X6Nd4J;Deep reinforcement learning in transportation research: A review ;https://www.sciencedirect.com/science/article/pii/S2590198221001317
532;XAAWN8cF_BUJ;Path planning for intelligent robots based on deep Q-learning with experience replay and heuristic knowledge ;https://ieeexplore.ieee.org/abstract/document/8853432/
533;XAqOEGTXTCsJ;Reinforcement learning for batch bioprocess optimization ;https://www.sciencedirect.com/science/article/pii/S0098135419304168
534;q-tXqEKltYIJ;Politex: Regret bounds for policy iteration using expert prediction ;http://proceedings.mlr.press/v97/lazic19a.html
535;G9J1IhWFjLsJ;Reinforcement learning with quantum variational circuit ;https://aaai.org/ojs/index.php/AIIDE/article/view/7437
536;2_Q0836fh1UJ;Deep reinforcement learning based control for Autonomous Vehicles in CARLA ;https://link.springer.com/article/10.1007/s11042-021-11437-3
537;zaa1dNNI530J;Should i run offline reinforcement learning or behavioral cloning? ;https://openreview.net/forum?id=AP1MKT37rJ
538;Foh5NnRcpIUJ;Deep deterministic policy gradient for urban traffic light control ;https://arxiv.org/abs/1703.09035
539;5RcMM9yhLh0J;Deep reinforcement learning for list-wise recommendations ;https://arxiv.org/abs/1801.00209
540;ma0KMYCcmKoJ;Dark, beyond deep: A paradigm shift to cognitive ai with humanlike common sense ;https://www.sciencedirect.com/science/article/pii/S2095809920300345
541;DFq_7MEx9YEJ;Deep reinforcement learning with a natural language action space ;https://arxiv.org/abs/1511.04636
542;9fejD_zmRNQJ;Machine learning techniques for THz imaging and time-domain spectroscopy ;https://www.mdpi.com/1424-8220/21/4/1186
543;5pv8KGdUnKYJ;Machine learning with neuromorphic photonics ;https://ieeexplore.ieee.org/abstract/document/8662590/
544;kKizDCJbQAgJ;The autonomous navigation and obstacle avoidance for USVs with ANOA deep reinforcement learning method ;https://www.sciencedirect.com/science/article/pii/S0950705119305350
545;Hq-YHMB69eIJ;Approximately solving mean field games via entropy-regularized deep reinforcement learning ;http://proceedings.mlr.press/v130/cui21a.html
546;MMzXtw9gmNoJ;Weighing counts: Sequential crowd counting by reinforcement learning ;https://link.springer.com/chapter/10.1007/978-3-030-58607-2_10
547;2utpajW8GIIJ;Robust detection of adversarial attacks by modeling the intrinsic properties of deep neural networks ;https://proceedings.neurips.cc/paper/2018/hash/e7a425c6ece20cbc9056f98699b53c6f-Abstract.html
548;NH8pkCyy6rQJ;Deep learning for portfolio optimization ;https://jfds.pm-research.com/content/early/2020/08/26/jfds.2020.1.042.full
549;3uVF1Z6VnvIJ;Dqnviz: A visual analytics approach to understand deep q-networks ;https://ieeexplore.ieee.org/abstract/document/8454905/
550;D0380DKPFyAJ;Leveraging UAVs for coverage in cell-free vehicular networks: A deep reinforcement learning approach ;https://ieeexplore.ieee.org/abstract/document/9082162/
551;QN3TkhS8aJYJ;Deep learning in visual tracking: A review ;https://ieeexplore.ieee.org/abstract/document/9666461/
552;l8aDn7kPfHkJ;Dynamic path planning of unknown environment based on deep reinforcement learning ;https://www.hindawi.com/journals/jr/2018/5781591/
553;dFjdwso5pv4J;Provably efficient reinforcement learning in partially observable dynamical systems ;https://proceedings.neurips.cc/paper_files/paper/2022/hash/03d7e13f0092405804f3a381ade8f3f0-Abstract-Conference.html
554;9ja-DubC4xoJ;AI agents envisioning the future: Forecast-based operation of renewable energy storage systems using hydrogen with Deep Reinforcement Learning ;https://www.sciencedirect.com/science/article/pii/S0196890422001972
555;yZwJx4MSmvwJ;A multi-agent deep reinforcement learning approach for enhancement of COVID-19 CT image segmentation ;https://www.mdpi.com/2075-4426/12/2/309
556;0RhEyQOy3YEJ;Deephoyer: Learning sparser neural network with differentiable scale-invariant sparsity measures ;https://arxiv.org/abs/1908.09979
557;ZNu56J-2P7IJ;Adafocus v2: End-to-end training of spatial dynamic networks for video recognition ;https://ieeexplore.ieee.org/abstract/document/9879690/
558;KJoku61NoecJ;Nearly horizon-free offline reinforcement learning ;https://proceedings.neurips.cc/paper_files/paper/2021/hash/8396b14c5dff55d13eea57487bf8ed26-Abstract.html
559;_Y_6fGJGZ3IJ;Provable reinforcement learning with a short-term memory ;https://proceedings.mlr.press/v162/efroni22a.html
560;sUB0CZO2ksUJ;Deep reinforcement learning-based spectrum allocation in integrated access and backhaul networks ;https://ieeexplore.ieee.org/abstract/document/9086877/
561;Brz2e9ID8UkJ;Flexible resource block allocation to multiple slices for radio access network slicing using deep reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/9057705/
562;EdoMrBHV1koJ;Convergence and sample complexity of gradient methods for the model-free linear–quadratic regulator problem ;https://ieeexplore.ieee.org/abstract/document/9448427/
563;UZTUkZeVN_8J;Efficient water desalination with graphene nanopores obtained using artificial intelligence ;https://www.nature.com/articles/s41699-021-00246-9
564;Y8xkmbgL9r4J;Lane change decision-making through deep reinforcement learning with rule-based constraints ;https://ieeexplore.ieee.org/abstract/document/8852110/
565;altSI0b7GYQJ;Building HVAC control with reinforcement learning for reduction of energy cost and demand charge ;https://www.sciencedirect.com/science/article/pii/S0378778821001171
566;9mBPtSsXlxYJ;Data-driven dynamic resource scheduling for network slicing: A deep reinforcement learning approach ;https://www.sciencedirect.com/science/article/pii/S0020025519303986
567;pot5XTqx3Z0J;Intelligent secure mobile edge computing for beyond 5G wireless networks ;https://www.sciencedirect.com/science/article/pii/S1874490721000203
568;myp3hUGITwkJ;A digital twin-based sim-to-real transfer for deep reinforcement learning-enabled industrial robot grasping ;https://www.sciencedirect.com/science/article/pii/S0736584522000539
569;wShLhHdGby4J;Reinforcement learning of beam codebooks in millimeter wave and terahertz MIMO systems ;https://ieeexplore.ieee.org/abstract/document/9610084/
570;Iu89axknarcJ;Soft actor-critic for navigation of mobile robots ;https://link.springer.com/article/10.1007/s10846-021-01367-5
571;4PojuKUkMX0J;A cookbook of self-supervised learning ;https://arxiv.org/abs/2304.12210
572;CeNckrZaZ7AJ;Asynchronous temporal fields for action recognition ;http://openaccess.thecvf.com/content_cvpr_2017/html/Sigurdsson_Asynchronous_Temporal_Fields_CVPR_2017_paper.html
573;aLyFbbeWwsMJ;Transfer learning ;https://books.google.com/books?hl=en&lr=&id=dG_IDwAAQBAJ&oi=fnd&pg=PR9&ots=Ud05dlXVxR&sig=Lf6JbbPVcSv45z6yw2ECQW5L1p8
574;Ui8nA43N4h0J;Revisiting parameter sharing in multi-agent deep reinforcement learning ;https://openreview.net/forum?id=MWj_P-Lk3jC
575;ggPymVvSCU0J;Application of deep reinforcement learning in stock trading strategies and stock forecasting ;https://link.springer.com/article/10.1007/s00607-019-00773-w
576;TLdRRS4_3p8J;Fathom: Reference workloads for modern deep learning methods ;https://ieeexplore.ieee.org/abstract/document/7581275/
577;yX6dSHFLpD0J;Deep active inference as variational policy gradients ;https://www.sciencedirect.com/science/article/pii/S0022249620300298
578;t3dV8N2r29UJ;Neural packet classification ;https://dl.acm.org/doi/abs/10.1145/3341302.3342221
579;hDaQoI_E_2cJ;Deep reinforcement learning for semisupervised hyperspectral band selection ;https://ieeexplore.ieee.org/abstract/document/9358199/
580;Lrap2UNP1IkJ;Use of proximal policy optimization for the joint replenishment problem ;https://www.sciencedirect.com/science/article/pii/S0166361519308218
581;r_ucTx8fIOsJ;Graphvite: A high-performance cpu-gpu hybrid system for node embedding ;https://dl.acm.org/doi/abs/10.1145/3308558.3313508
582;9ZA14_J-ZpEJ;Reinforcement learning techniques for optimal power control in grid-connected microgrids: A comprehensive review ;https://ieeexplore.ieee.org/abstract/document/9261330/
583;SbcOq-1oQrgJ;Deep reinforcement learning for general video game ai ;https://ieeexplore.ieee.org/abstract/document/8490422/
584;NbRINpyzFFkJ;Quantum neuron: an elementary building block for machine learning on quantum computers ;https://arxiv.org/abs/1711.11240
585;fDAUm01IFksJ;Artificial intelligence and augmented intelligence collaboration: regaining trust and confidence in the financial sector ;https://www.tandfonline.com/doi/abs/10.1080/13600834.2018.1488659
586;jN86VkRrqmkJ;Cross-domain ensemble distillation for domain generalization ;https://link.springer.com/chapter/10.1007/978-3-031-19806-9_1
587;79PWUPAy9fcJ;Cooperative wind farm control with deep reinforcement learning and knowledge-assisted learning ;https://ieeexplore.ieee.org/abstract/document/8999726/
588;A5EwTLwlDRwJ;Adversarial attack and defense in reinforcement learning-from AI security view ;https://link.springer.com/article/10.1186/s42400-019-0027-x
589;pzQ69czFYF0J;Experience replay optimization ;https://arxiv.org/abs/1906.08387
590;f20Z1uyb2-8J;Edge computing and its role in Industrial Internet: Methodologies, applications, and future directions ;https://www.sciencedirect.com/science/article/pii/S0020025520311865
591;CjztQDVawSEJ;Virtual-taobao: Virtualizing real-world online retail environment for reinforcement learning ;https://ojs.aaai.org/index.php/AAAI/article/view/4419
592;0Z14151EarwJ;First order constrained optimization in policy space ;https://proceedings.neurips.cc/paper/2020/hash/af5d5ef24881f3c3049a7b9bfe74d58b-Abstract.html
593;dITtrka5JzQJ;Combining model-based and model-free updates for trajectory-centric reinforcement learning ;http://proceedings.mlr.press/v70/chebotar17a.html
594;ubDobEqzKFQJ;Reinforcement learning versus evolutionary computation: A survey on hybrid algorithms ;https://www.sciencedirect.com/science/article/pii/S2210650217302766
595;GxL8U1qWkdQJ;A soft actor-critic-based energy management strategy for electric vehicles with hybrid energy storage systems ;https://www.sciencedirect.com/science/article/pii/S0378775322001239
596;jxzG3fISGRIJ;Improving stochastic policy gradients in continuous control with deep reinforcement learning using the beta distribution ;https://proceedings.mlr.press/v70/chou17a.html
597;VCUEwyRP8CwJ;Pirlnav: Pretraining with imitation and rl finetuning for objectnav ;http://openaccess.thecvf.com/content/CVPR2023/html/Ramrakhya_PIRLNav_Pretraining_With_Imitation_and_RL_Finetuning_for_ObjectNav_CVPR_2023_paper.html
598;-ZxpU_GBiWAJ;Deep reinforcement learning for traffic signal control: A review ;https://ieeexplore.ieee.org/abstract/document/9241006/
599;occeEN4ExZcJ;Multi-agent system and reinforcement learning approach for distributed intelligence in a flexible smart manufacturing system ;https://www.sciencedirect.com/science/article/pii/S0278612520301916
600;F6-PtyVceV8J;Reinforcement learning-based multiaccess control and battery prediction with energy harvesting in IoT systems ;https://ieeexplore.ieee.org/abstract/document/8473693/
601;pIi_Uv_IlOQJ;An improved task allocation scheme in serverless computing using gray wolf Optimization (GWO) based reinforcement learning (RIL) approach ;https://link.springer.com/article/10.1007/s11277-020-07981-0
602;q-Cj9V9JIxkJ;Motion planning for autonomous driving: The state of the art and future perspectives ;https://ieeexplore.ieee.org/abstract/document/10122127/
603;RQf3dgSOe0wJ;The unfolding argument: Why IIT and other causal structure theories cannot explain consciousness ;https://www.sciencedirect.com/science/article/pii/S105381001830521X
604;jj48dTuru1kJ;Blockchain-Based Distributed Software-Defined Vehicular Networks: A Dueling Deep -Learning Approach ;https://ieeexplore.ieee.org/abstract/document/8852698/
605;-VrQlR6PSogJ;Image-based deep reinforcement meta-learning for autonomous lunar landing ;https://arc.aiaa.org/doi/abs/10.2514/1.A35072
606;aA9AWoIj1LUJ;A machine learning approach to 5G infrastructure market optimization ;https://ieeexplore.ieee.org/abstract/document/8632676/
607;z2lnhEru-XkJ;Cooperative deep Q-learning with Q-value transfer for multi-intersection signal control ;https://ieeexplore.ieee.org/abstract/document/8674720/
608;z4vANdzB4nwJ;Demand-driven deep reinforcement learning for scalable fog and service placement ;https://ieeexplore.ieee.org/abstract/document/9416796/
609;Iv_11KHR_mkJ;Network offloading policies for cloud robotics: a learning-based approach ;https://link.springer.com/article/10.1007/s10514-021-09987-4
610;-I0NZAQW6EwJ;Toward self‐driving processes: A deep reinforcement learning approach to control ;https://aiche.onlinelibrary.wiley.com/doi/abs/10.1002/aic.16689
611;45yFh46o3BQJ;Optimisation of colour generation from dielectric nanostructures using reinforcement learning ;https://opg.optica.org/abstract.cfm?uri=oe-27-4-5874
612;iGnfPCezVwwJ;Dynamic reservation and deep reinforcement learning based autonomous resource slicing for virtualized radio access networks ;https://ieeexplore.ieee.org/abstract/document/8682105/
613;YCH_Z2EfSVAJ;A deep reinforcement learning approach to mountain railway alignment optimization ;https://onlinelibrary.wiley.com/doi/abs/10.1111/mice.12694
614;vvfo76ubaYAJ;Neurovectorizer: End-to-end vectorization with deep reinforcement learning ;https://dl.acm.org/doi/abs/10.1145/3368826.3377928
615;hYtkaphA7xkJ;Gcomb: Learning budget-constrained combinatorial algorithms over billion-sized graphs ;https://proceedings.neurips.cc/paper/2020/hash/e7532dbeff7ef901f2e70daacb3f452d-Abstract.html
616;8RifHmxIgO0J;Deep multi-agent reinforcement learning for highway on-ramp merging in mixed traffic ;https://ieeexplore.ieee.org/abstract/document/10159552/
617;7IWWmBaD80IJ;A survey on interactive reinforcement learning: Design principles and open challenges ;https://dl.acm.org/doi/abs/10.1145/3357236.3395525
618;iGZmXbFiS4QJ;Guiding pretraining in reinforcement learning with large language models ;https://arxiv.org/abs/2302.06692
619;TVLNSn_q3ksJ;Polygonal building extraction by frame field learning ;http://openaccess.thecvf.com/content/CVPR2021/html/Girard_Polygonal_Building_Extraction_by_Frame_Field_Learning_CVPR_2021_paper.html
620;a7Pa8zc60SIJ;Scalable and efficient training of large convolutional neural networks with differential privacy ;https://proceedings.neurips.cc/paper_files/paper/2022/hash/fa5617c176e76fee83f3f9947fdf9f3f-Abstract-Conference.html
621;Rer6nvrZ9k0J;Deep reinforcement learning based approach for optimal power flow of distribution networks embedded with renewable energy and storage devices ;https://ieeexplore.ieee.org/abstract/document/9465777/
622;0pqA6y_Qx3QJ;Deep reinforcement learning for the real time control of stormwater systems ;https://www.sciencedirect.com/science/article/pii/S0309170820302499
623;bsO_lX-boA4J;Reinforced active learning for image segmentation ;https://arxiv.org/abs/2002.06583
624;G84Pe7CHf6gJ;UAV autonomous target search based on deep reinforcement learning in complex disaster scene ;https://ieeexplore.ieee.org/abstract/document/8787847/
625;_PaE6jV2FNUJ;Recent advances in deep learning: An overview ;https://arxiv.org/abs/1807.08169
626;ZxhSHCbJ8HQJ;Digital transformation in smart farm and forest operations needs human-centered AI: Challenges and future directions ;https://www.mdpi.com/1424-8220/22/8/3043
627;1sFBXbtZ6DYJ;One transformer can understand both 2d & 3d molecular data ;https://arxiv.org/abs/2210.01765
628;SGSyo6N-kbcJ;Evolutionary population curriculum for scaling multi-agent reinforcement learning ;https://arxiv.org/abs/2003.10423
629;OeXIh6pfjuwJ;Learning-based energy-efficient data collection by unmanned vehicles in smart cities ;https://ieeexplore.ieee.org/abstract/document/8207610/
630;bwtLGlE9OGcJ;Evolving reinforcement learning algorithms ;https://arxiv.org/abs/2101.03958
631;zhkccMZFVK8J;A reinforcement learning approach to irrigation decision-making for rice using weather forecasts ;https://www.sciencedirect.com/science/article/pii/S0378377421001037
632;-V3pgOFGUG4J;When is realizability sufficient for off-policy reinforcement learning? ;https://proceedings.mlr.press/v202/zanette23a.html
633;TfJXryz6o3AJ;Adaptable and data-driven softwarized networks: Review, opportunities, and challenges ;https://ieeexplore.ieee.org/abstract/document/8653330/
634;Q_gPrCbSwIIJ;Airsim drone racing lab ;http://proceedings.mlr.press/v123/madaan20a.html
635;NeJWbsdknE4J;End-to-end deep reinforcement learning for lane keeping assist ;https://arxiv.org/abs/1612.04340
636;Hx744nE-f2kJ;NeoRL: A near real-world benchmark for offline reinforcement learning ;https://proceedings.neurips.cc/paper_files/paper/2022/hash/9cd828eb8dc81a84fb6bf89a94263e1b-Abstract-Datasets_and_Benchmarks.html
637;tmJJALiYrBwJ;An empirical study on program failures of deep learning jobs ;https://dl.acm.org/doi/abs/10.1145/3377811.3380362
638;udr3fyP0aTkJ;A model-based reinforcement learning with adversarial training for online recommendation ;https://proceedings.neurips.cc/paper/2019/hash/e49eb6523da9e1c347bc148ea8ac55d3-Abstract.html
639;DCngSdT_YuoJ;Secant: Self-expert cloning for zero-shot generalization of visual policies ;https://arxiv.org/abs/2106.09678
640;yu5jLHvau9oJ;Machines augmenting entrepreneurs: Opportunities (and threats) at the Nexus of artificial intelligence and entrepreneurship ;https://www.sciencedirect.com/science/article/pii/S0883902622000398
641;JKDFxR6xavQJ;Communication in multi-agent reinforcement learning: Intention sharing ;https://openreview.net/forum?id=qpsl2dR9twy
642;bLn2ZWzD8jsJ;Video relationship reasoning using gated spatio-temporal energy graph ;http://openaccess.thecvf.com/content_CVPR_2019/html/Tsai_Video_Relationship_Reasoning_Using_Gated_Spatio-Temporal_Energy_Graph_CVPR_2019_paper.html
643;t7HlnbbBjIUJ;Adversarial defense via learning to generate diverse attacks ;http://openaccess.thecvf.com/content_ICCV_2019/html/Jang_Adversarial_Defense_via_Learning_to_Generate_Diverse_Attacks_ICCV_2019_paper.html
644;i1dMLO_hMBoJ;Hierarchical deep reinforcement learning for continuous action control ;https://ieeexplore.ieee.org/abstract/document/8310962/
645;DsI94wgGH84J;Scaling map-elites to deep neuroevolution ;https://dl.acm.org/doi/abs/10.1145/3377930.3390217
646;3LAuWDE6sy8J;Research trends in artificial intelligence applications in human factors health care: mapping review ;https://humanfactors.jmir.org/2021/2/e28236
647;_ozvq-d1sjYJ;Model-free reinforcement learning in infinite-horizon average-reward markov decision processes ;http://proceedings.mlr.press/v119/wei20c.html
648;7brgCUm5X7AJ;Grid path planning with deep reinforcement learning: Preliminary results ;https://www.sciencedirect.com/science/article/pii/S1877050918300553
649;yhb4gP0jHPwJ;Automated eco-driving in urban scenarios using deep reinforcement learning ;https://www.sciencedirect.com/science/article/pii/S0968090X2100005X
650;fwzKqx01fDAJ;Memory-based deep reinforcement learning for POMDPs ;https://ieeexplore.ieee.org/abstract/document/9636140/
651;USCk5_Ljo4YJ;Deep reinforcement scheduling for mobile crowdsensing in fog computing ;https://dl.acm.org/doi/abs/10.1145/3234463
652;RHSz44hn3FsJ;Breaking the curse of multiagents in a large state space: Rl in markov games with independent linear function approximation ;https://proceedings.mlr.press/v195/cui23a.html
653;NH-3fefUqtEJ;The problem with DDPG: understanding failures in deterministic environments with sparse rewards ;https://arxiv.org/abs/1911.11679
654;l08G3-C6Iq8J;Deep reinforcement learning for wireless sensor scheduling in cyber–physical systems ;https://www.sciencedirect.com/science/article/pii/S0005109819306223
655;tx-s72iinsgJ;Structural attack against graph based android malware detection ;https://dl.acm.org/doi/abs/10.1145/3460120.3485387
656;qhBa-_AqBF4J;Scalable deep reinforcement learning algorithms for mean field games ;https://proceedings.mlr.press/v162/lauriere22a.html
657;sVsjGOi1cmkJ;A review on the design and optimization of antennas using machine learning algorithms and techniques ;https://onlinelibrary.wiley.com/doi/abs/10.1002/mmce.22356
658;HtQ5SnurdzYJ;Continuous meta-learning without tasks ;https://proceedings.neurips.cc/paper/2020/hash/cc3f5463bc4d26bc38eadc8bcffbc654-Abstract.html
659;KlAC2CBZ3Z8J;The effects of memory replay in reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/8636075/
660;YSPcLtfPipgJ;Reinforcement learning interpretation methods: A survey ;https://ieeexplore.ieee.org/abstract/document/9194697/
661;zOde1R-qDDoJ;Deep learning in automated ultrasonic NDE–developments, axioms and opportunities ;https://www.sciencedirect.com/science/article/pii/S0963869522001025
662;tUmuJ4gBvkgJ;Incremental mobile user profiling: Reinforcement learning with spatial knowledge graph for modeling event streams ;https://dl.acm.org/doi/abs/10.1145/3394486.3403128
663;7QeL0vDOAEwJ;Uncertainty-driven imagination for continuous deep reinforcement learning ;http://proceedings.mlr.press/v78/kalweit17a.html
664;T4DGBH-KlaMJ;Automatic data augmentation for generalization in reinforcement learning ;https://proceedings.neurips.cc/paper/2021/hash/2b38c2df6a49b97f706ec9148ce48d86-Abstract.html
665;H3txY_1gewsJ;Hrl4in: Hierarchical reinforcement learning for interactive navigation with mobile manipulators ;http://proceedings.mlr.press/v100/li20a.html
666;GqPljIsaF6cJ;Dynamic weights in multi-objective deep reinforcement learning ;http://proceedings.mlr.press/v97/abels19a.html
667;c8v868DN3e4J;An intelligent financial portfolio trading strategy using deep Q-learning ;https://www.sciencedirect.com/science/article/pii/S0957417420303973
668;zQRhSCA4o7wJ;Rebalancing shared mobility-on-demand systems: A reinforcement learning approach ;https://ieeexplore.ieee.org/abstract/document/8317908/
669;xpmkc343jb0J;Microstructure representation and reconstruction of heterogeneous materials via deep belief network for computational material design ;https://asmedigitalcollection.asme.org/mechanicaldesign/article-abstract/139/7/071404/383783
670;RBvGnWcgvocJ;When should we prefer offline reinforcement learning over behavioral cloning? ;https://arxiv.org/abs/2204.05618
671;mMhQRZu7lRAJ;Robust deep reinforcement learning through adversarial loss ;https://proceedings.neurips.cc/paper/2021/hash/dbb422937d7ff56e049d61da730b3e11-Abstract.html
672;5dNEKv-QdjEJ;Deep reinforcement learning for pedestrian collision avoidance and human-machine cooperative driving ;https://www.sciencedirect.com/science/article/pii/S0020025520302851
673;5lrE-mp72KcJ;Efficient adversarial training without attacking: Worst-case-aware robust reinforcement learning ;https://proceedings.neurips.cc/paper_files/paper/2022/hash/8d6b1d775014eff18256abeb207202ad-Abstract-Conference.html
674;G6xgptuMnM8J;Pipe-SGD: A decentralized pipelined SGD framework for distributed deep net training ;https://proceedings.neurips.cc/paper_files/paper/2018/hash/2c6a0bae0f071cbbf0bb3d5b11d90a82-Abstract.html
675;LoiADt9_ffgJ;Exploring multi-objective exercise recommendations in online education systems ;https://dl.acm.org/doi/abs/10.1145/3357384.3357995
676;ebp9If2-uFkJ;Iteratively questioning and answering for interpretable legal judgment prediction ;https://aaai.org/ojs/index.php/AAAI/article/view/5479
677;1MzDd3CfEZoJ;Sharp variance-dependent bounds in reinforcement learning: Best of both worlds in stochastic and deterministic environments ;https://proceedings.mlr.press/v202/zhou23t.html
678;nkvnErkb3FkJ;Dashbot: Insight-driven dashboard generation based on deep reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/9906971/
679;QkErUjSZGiAJ;Interactive inverse design of layered phononic crystals based on reinforcement learning ;https://www.sciencedirect.com/science/article/pii/S2352431620300262
680;fOzI1zY-yjUJ;Automated lane change strategy using proximal policy optimization-based deep reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/9304668/
681;Rq7fXgDNdbEJ;A robot exploration strategy based on q-learning network ;https://ieeexplore.ieee.org/abstract/document/7784001/
682;ItsPYPJfb3YJ;Contextual imagined goals for self-supervised robotic learning ;https://proceedings.mlr.press/v100/nair20a.html
683;iWMVjBMyDkwJ;Physics-informed neural networks for the shallow-water equations on the sphere ;https://www.sciencedirect.com/science/article/pii/S0021999122000869
684;Vy4VXbj-VTAJ;Overcoming model bias for robust offline deep reinforcement learning ;https://www.sciencedirect.com/science/article/pii/S0952197621002141
685;yKTG7IG6sB0J;Deep reinforcement learning-based approach to tackle topic-aware influence maximization ;https://link.springer.com/article/10.1007/s41019-020-00117-1
686;9a1kbj2o9OIJ;A hierarchical neural model of data prefetching ;https://dl.acm.org/doi/abs/10.1145/3445814.3446752
687;pxLDsfj6fXcJ;Teachaugment: Data augmentation optimization using teacher knowledge ;http://openaccess.thecvf.com/content/CVPR2022/html/Suzuki_TeachAugment_Data_Augmentation_Optimization_Using_Teacher_Knowledge_CVPR_2022_paper.html
688;yz7rgBzJPQMJ;Model-based reinforcement learning with value-targeted regression ;https://proceedings.mlr.press/v120/jia20a.html
689;UaZAFs59TWQJ;Improved inception-residual convolutional neural network for object recognition ;https://link.springer.com/article/10.1007/s00521-018-3627-6
690;BJJqiQgylIYJ;Evaluating the energy efficiency of deep convolutional neural networks on CPUs and GPUs ;https://ieeexplore.ieee.org/abstract/document/7723730/
691;7Et8-u4z1EsJ;Pixelrl: Fully convolutional network with reinforcement learning for image processing ;https://ieeexplore.ieee.org/abstract/document/8936404/
692;HyqjDV95j9kJ;Reinforcement learning based resource management for fog computing environment: Literature review, challenges, and open issues ;https://ieeexplore.ieee.org/abstract/document/9718357/
693;YomkdczIGiAJ;Continual learning with node-importance based adaptive group sparse regularization ;https://proceedings.neurips.cc/paper/2020/hash/258be18e31c8188555c2ff05b4d542c3-Abstract.html
694;TXPDODFoiIcJ;Survey of deep learning paradigms for speech processing ;https://link.springer.com/article/10.1007/s11277-022-09640-y
695;1pC7FmmRi2kJ;Current trends in the development of intelligent unmanned autonomous systems ;https://link.springer.com/article/10.1631/FITEE.1601650
696;a6LQSLhWqMwJ;Autoshard: Automated embedding table sharding for recommender systems ;https://dl.acm.org/doi/abs/10.1145/3534678.3539034
697;j6YOAtfZdaMJ;Unmanned aerial vehicle path planning algorithm based on deep reinforcement learning in large-scale and dynamic environments ;https://ieeexplore.ieee.org/abstract/document/9348925/
698;Afd1uziWykUJ;Mathdqn: Solving arithmetic word problems via deep reinforcement learning ;https://ojs.aaai.org/index.php/AAAI/article/view/11981
699;RFTXwx_NVWEJ;Unsupervised learning of visual 3d keypoints for control ;https://proceedings.mlr.press/v139/chen21b.html
700;hn589s9xTOYJ;Reinforcement learning for test case prioritization ;https://ieeexplore.ieee.org/abstract/document/9394799/
701;SXQvOE6rQLYJ;A multi-objective trade-off framework for cloud resource scheduling based on the deep Q-network algorithm ;https://link.springer.com/article/10.1007/s10586-019-03042-9
702;hT3f1fRPyiQJ;Meta reinforcement learning for sim-to-real domain adaptation ;https://ieeexplore.ieee.org/abstract/document/9196540/
703;2SBCe5HAok4J;Reinforcement learning for mobile robotics exploration: A survey ;https://ieeexplore.ieee.org/abstract/document/9612713/
704;nne0CZb6h8QJ;The transformer network for the traveling salesman problem ;https://arxiv.org/abs/2103.03012
705;LJEFzzjEwSYJ;Deep reinforcement learning approaches for process control ;https://ieeexplore.ieee.org/abstract/document/7983780/
706;87D8v5EVKlUJ;Deep reinforcement learning-based controller for SOC management of multi-electrical energy storage system ;https://ieeexplore.ieee.org/abstract/document/9097915/
707;aJUASVAQxLcJ;Trainify: A CEGAR-Driven Training and Verification Framework for Safe Deep Reinforcement Learning ;https://link.springer.com/chapter/10.1007/978-3-031-13185-1_10
708;yB3VjUDieBcJ;Local energy trading behavior modeling with deep reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/8496766/
709;hI8G7aPC-LsJ;Learning to learn with gradients ;https://search.proquest.com/openview/210a3c63c79ad88b6e313f11e1c36116/1?pq-origsite=gscholar&cbl=18750
710;Zlwl07cIKckJ;A deep reinforcement learning based hyper-heuristic for combinatorial optimisation with uncertainties ;https://www.sciencedirect.com/science/article/pii/S0377221721008821
711;OW8UYB8xJawJ;Leave no trace: Learning to reset for safe and autonomous reinforcement learning ;https://arxiv.org/abs/1711.06782
712;Wqy_yVxshRUJ;Deup: Direct epistemic uncertainty prediction ;https://arxiv.org/abs/2102.08501
713;WnY4G4PR-IkJ;Practical implementation and evaluation of deep reinforcement learning control for a radiant heating system ;https://dl.acm.org/doi/abs/10.1145/3276774.3276775
714;A_9HCbm2x8cJ;Automated penetration testing using deep reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/9229752/
715;Q5TDlhvbbJEJ;Q-learning with ucb exploration is sample efficient for infinite-horizon mdp ;https://arxiv.org/abs/1901.09311
716;HoQJoshpa5wJ;TROVE: A context-awareness trust model for VANETs using reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/9003228/
717;EtuLbcekqKkJ;Resilient distribution networks by microgrid formation using deep reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/9786037/
718;LniYYFqNKhoJ;Energy-efficient mode selection and resource allocation for D2D-enabled heterogeneous networks: A deep reinforcement learning approach ;https://ieeexplore.ieee.org/abstract/document/9237143/
719;AKXBHL2PsZIJ;Episodic exploration for deep deterministic policies: An application to starcraft micromanagement tasks ;https://arxiv.org/abs/1609.02993
720;kMEfbHLsy6MJ;Towards generalization in target-driven visual navigation by using deep reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/9102361/
721;STrdUuz0nkQJ;Dropconnect is effective in modeling uncertainty of bayesian deep networks ;https://www.nature.com/articles/s41598-021-84854-x
722;_Ru5kXUKoKAJ;Deep implicit coordination graphs for multi-agent reinforcement learning ;https://arxiv.org/abs/2006.11438
723;cs8lFcZCRqcJ;Auc-oriented graph neural network for fraud detection ;https://dl.acm.org/doi/abs/10.1145/3485447.3512178
724;oA6iU0dd5usJ;Actor-critic sequence training for image captioning ;https://arxiv.org/abs/1706.09601
725;rDmn7HjLmEoJ;SimGANs: Simulator-based generative adversarial networks for ECG synthesis to improve deep ECG classification ;http://proceedings.mlr.press/v119/golany20a.html
726;MDtNnSc2RHAJ;Gated-attention architectures for task-oriented language grounding ;https://ojs.aaai.org/index.php/AAAI/article/view/11832
727;x9nKGHj2TOwJ;3DCNN-DQN-RNN: A deep reinforcement learning framework for semantic parsing of large-scale 3D point clouds ;http://openaccess.thecvf.com/content_iccv_2017/html/Liu_3DCNN-DQN-RNN_A_Deep_ICCV_2017_paper.html
728;SP_0oqaiOa8J;Surrogate gradients for analog neuromorphic computing ;https://www.pnas.org/doi/abs/10.1073/pnas.2109194119
729;GjPJIQFhEKgJ;Sequence tutor: Conservative fine-tuning of sequence generation models with kl-control ;http://proceedings.mlr.press/v70/jaques17a
730;ygEkyF5ds-IJ;Continuous control of a polymerization system with deep reinforcement learning ;https://www.sciencedirect.com/science/article/pii/S0959152418304876
731;YaHsqjju6rsJ;SecOFF-FCIoT: Machine learning based secure offloading in Fog-Cloud of things for smart city applications ;https://www.sciencedirect.com/science/article/pii/S2542660518301938
732;JSH95zZOwv0J;Vrl3: A data-driven framework for visual deep reinforcement learning ;https://proceedings.neurips.cc/paper_files/paper/2022/hash/d4cc7a2d0d70736e29a3b48c3729bc06-Abstract-Conference.html
733;XfCUBrszRdAJ;Intelligent laser welding through representation, prediction, and control learning: An architecture with deep neural networks and reinforcement learning ;https://www.sciencedirect.com/science/article/pii/S0957415815001555
734;sbpBr3NBdjoJ;Human-centric dialog training via offline reinforcement learning ;https://arxiv.org/abs/2010.05848
735;9qlGTgZ7E_EJ;Progressive relation learning for group activity recognition ;http://openaccess.thecvf.com/content_CVPR_2020/html/Hu_Progressive_Relation_Learning_for_Group_Activity_Recognition_CVPR_2020_paper.html
736;8wgH1zvLIdQJ;Network intrusion detection based on extended RBF neural network with offline reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/9612220/
737;BiNuYxDKjFQJ;Collaborative deep reinforcement learning for multi-object tracking ;http://openaccess.thecvf.com/content_ECCV_2018/html/Liangliang_Ren_Collaborative_Deep_Reinforcement_ECCV_2018_paper.html
738;ID8Hwbesiu8J;Expert level control of ramp metering based on multi-task deep reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/8011495/
739;ZsmgbulYNYwJ;Evaluation of human-AI teams for learned and rule-based agents in Hanabi ;https://proceedings.neurips.cc/paper/2021/hash/86e8f7ab32cfd12577bc2619bc635690-Abstract.html
740;1JMkaOAG0r0J;A general framework for sample-efficient function approximation in reinforcement learning ;https://arxiv.org/abs/2209.15634
741;MmyjE8-Ahy4J;UAV autonomous aerial combat maneuver strategy generation with observation error based on state-adversarial deep deterministic policy gradient and inverse … ;https://www.mdpi.com/2079-9292/9/7/1121
742;GAtTMTuvP-EJ;Hierarchical representations and explicit memory: Learning effective navigation policies on 3d scene graphs using graph neural networks ;https://ieeexplore.ieee.org/abstract/document/9812179/
743;ovK2ENOC4xcJ;A deep reinforcement learning approach for rail renewal and maintenance planning ;https://www.sciencedirect.com/science/article/pii/S0951832022002575
744;A7ttR3qI3wYJ;Neural certificates for safe control policies ;https://arxiv.org/abs/2006.08465
745;VM-ADykvr-oJ;Autonomous maneuver decision making of dual-UAV cooperative air combat based on deep reinforcement learning ;https://www.mdpi.com/2079-9292/11/3/467
746;wZbG3aU6ss0J;Visual object tracking: A survey ;https://www.sciencedirect.com/science/article/pii/S1077314222001011
747;McKjBAJPKDQJ;Exponentially weighted imitation learning for batched historical data ;https://proceedings.neurips.cc/paper/2018/hash/4aec1b3435c52abbdf8334ea0e7141e0-Abstract.html
748;ONnB4xjUsuEJ;Rcaa: Relational context-aware agents for person search ;http://openaccess.thecvf.com/content_ECCV_2018/html/Xiaojun_Chang_RCAA_Relational_Context-Aware_ECCV_2018_paper.html
749;MHY-8RD22RsJ;Multiple mobile robot task and motion planning: A survey ;https://dl.acm.org/doi/abs/10.1145/3564696
750;hI34_NC3TzoJ;Deep reinforcement learning based direct torque control strategy for distributed drive electric vehicles considering active safety and energy saving … ;https://www.sciencedirect.com/science/article/pii/S0360544221019733
751;cqPzzOhmsocJ;Off-policy learning in two-stage recommender systems ;https://dl.acm.org/doi/abs/10.1145/3366423.3380130
752;dxpUGIAlX1UJ;Bayesian optimization for accelerating hyper-parameter tuning ;https://ieeexplore.ieee.org/abstract/document/8791696/
753;khtlgVz4WyMJ;Converging robotic technologies in targeted neural rehabilitation: a review of emerging solutions and challenges ;https://www.mdpi.com/1424-8220/21/6/2084
754;uUy-rr7waSIJ;Empirical analysis of PGA-MAP-Elites for Neuroevolution in Uncertain Domains ;https://dl.acm.org/doi/abs/10.1145/3577203
755;xbS2i9lV6TMJ;Twin-delayed ddpg: A deep reinforcement learning technique to model a continuous movement of an intelligent robot agent ;https://dl.acm.org/doi/abs/10.1145/3387168.3387199
756;QF8HAt8GhbEJ;Fabric defect detection based on a deep convolutional neural network using a two-stage strategy ;https://journals.sagepub.com/doi/abs/10.1177/0040517520935984
757;sGyKnPuX0jwJ;Memory as a computational resource ;https://www.cell.com/trends/cognitive-sciences/fulltext/S1364-6613(20)30305-3
758;uLq-l60lkqcJ;A reinforcement neural architecture search method for rolling bearing fault diagnosis ;https://www.sciencedirect.com/science/article/pii/S0263224119312849
759;D6dx0YEjPacJ;Distributed reinforcement learning for multi-robot decentralized collective construction ;https://link.springer.com/chapter/10.1007/978-3-030-05816-6_3
760;6YY-IOj3wroJ;Stock movement prediction via gated recurrent unit network based on reinforcement learning with incorporated attention mechanisms ;https://www.sciencedirect.com/science/article/pii/S0925231221014508
761;8XlmSIHG3EQJ;Online learned continual compression with adaptive quantization modules ;https://proceedings.mlr.press/v119/caccia20a.html
762;dwnm9ptae7QJ;Videoflow: A conditional flow-based model for stochastic video generation ;https://arxiv.org/abs/1903.01434
763;7Ai6iNxTtLwJ;Performance and cost-efficient spark job scheduling based on deep reinforcement learning in cloud computing environments ;https://ieeexplore.ieee.org/abstract/document/9599497/
764;QCUs7bTF3pgJ;A survey on model-based reinforcement learning ;https://arxiv.org/abs/2206.09328
765;lLpT0-oSM-EJ;Jointly learning to recommend and advertise ;https://dl.acm.org/doi/abs/10.1145/3394486.3403384
766;nAztpuEcpKIJ;Analysis of stochastic processes through replay buffers ;https://proceedings.mlr.press/v162/di-castro22a.html
767;p_SvnAkxj3EJ;Deep reinforcement learning for portfolio management of markets with a dynamic number of assets ;https://www.sciencedirect.com/science/article/pii/S0957417420307776
768;BHVKavkXs7YJ;Twig: Multi-agent task management for colocated latency-critical cloud services ;https://ieeexplore.ieee.org/abstract/document/9065442/
769;iSBd69oRhDwJ;Robotic grasping using deep reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/9216986/
770;Vshg7E_pV3YJ;Divide-and-conquer reinforcement learning ;https://arxiv.org/abs/1711.09874
771;1ZWJ0-I_c0QJ;Graph policy gradients for large scale robot control ;http://proceedings.mlr.press/v100/khan20a.html
772;BU7yfG6ZUg0J;PERCEIVE: deep learning-based cellular uplink prediction using real-time scheduling patterns ;https://dl.acm.org/doi/abs/10.1145/3386901.3388911
773;DRU4jvpX270J;Reinforcement learning-based downlink interference control for ultra-dense small cells ;https://ieeexplore.ieee.org/abstract/document/8868117/
774;lX9udRXsgb4J;Deep reinforcement learning for robust emotional classification in facial expression recognition ;https://www.sciencedirect.com/science/article/pii/S0950705120304081
775;04lbIM0O5ZkJ;Human-like autonomous vehicle speed control by deep reinforcement learning with double Q-learning ;https://ieeexplore.ieee.org/abstract/document/8500630/
776;SdUh8X9pz-IJ;Deep reinforcement learning based dynamic channel allocation algorithm in multibeam satellite systems ;https://ieeexplore.ieee.org/abstract/document/8302493/
777;4HGNJww3yE8J;Tree-structured reinforcement learning for sequential object localization ;https://proceedings.neurips.cc/paper_files/paper/2016/hash/812b4ba287f5ee0bc9d43bbf5bbe87fb-Abstract.html
778;1QKyfE13pesJ;A novel deep reinforcement learning based methodology for short-term HVAC system energy consumption prediction ;https://www.sciencedirect.com/science/article/pii/S0140700719303160
779;B4BrbLHlbRwJ;DRLinFluids: An open-source Python platform of coupling deep reinforcement learning and OpenFOAM ;https://pubs.aip.org/aip/pof/article/34/8/081801/2846652
780;824oxkzznn4J;Machine learning for financial risk management: a survey ;https://ieeexplore.ieee.org/abstract/document/9249416/
781;v4lmCf4i7yIJ;3D UAV trajectory and data collection optimisation via deep reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/9701330/
782;5oS_gQcWqMMJ;Deep reinforcement learning for real autonomous mobile robot navigation in indoor environments ;https://arxiv.org/abs/2005.13857
783;BoVFq9tykagJ;Deep reinforcement learning with the confusion-matrix-based dynamic reward function for customer credit scoring ;https://www.sciencedirect.com/science/article/pii/S0957417422004316
784;8HItpuuiFbgJ;A survey of domain-specific architectures for reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/9694573/
785;EbdigqJVZqQJ;Reinforcement learning with perturbed rewards ;https://ojs.aaai.org/index.php/AAAI/article/view/6086
786;CoC-2LYGW8gJ;Provably efficient online hyperparameter optimization with population-based bandits ;https://proceedings.neurips.cc/paper/2020/hash/c7af0926b294e47e52e46cfebe173f20-Abstract.html
787;NxiutN1REmUJ;Deep multiagent reinforcement learning: Challenges and directions ;https://link.springer.com/article/10.1007/s10462-022-10299-x
788;KyUFh4vLtKgJ;The application of deep reinforcement learning to distributed spectrum access in dynamic heterogeneous environments with partial observations ;https://ieeexplore.ieee.org/abstract/document/9089307/
789;fNtFBfEsYP4J;ICRA: an intelligent clustering routing approach for UAV ad hoc networks ;https://ieeexplore.ieee.org/abstract/document/9700761/
790;OJYJ8P9wEAkJ;OnRL: improving mobile video telephony via online reinforcement learning ;https://dl.acm.org/doi/abs/10.1145/3372224.3419186
791;4G5D6ghYBnAJ;Knowledge-primed neural networks enable biologically interpretable deep learning on single-cell sequencing data ;https://genomebiology.biomedcentral.com/articles/10.1186/s13059-020-02100-5
792;fRHj8UClxbYJ;Is multiagent deep reinforcement learning the answer or the question? A brief survey ;https://www.researchgate.net/profile/Pablo-Hernandez-Leal/publication/328280687_Is_multiagent_deep_reinforcement_learning_the_answer_or_the_question_A_brief_survey/links/5d152c8f92851cf440517170/Is-multiagent-deep-reinforcement-learning-the-answer-or-the-question-A-brief-survey.pdf
793;3iI9O8TI_3UJ;Non-cooperative energy efficient power allocation game in D2D communication: A multi-agent deep reinforcement learning approach ;https://ieeexplore.ieee.org/abstract/document/8766985/
794;ve-2EY7bPn0J;Discretizing continuous action space for on-policy optimization ;https://ojs.aaai.org/index.php/AAAI/article/view/6059
795;gBFw3wlR-OAJ;On improving deep reinforcement learning for pomdps ;https://arxiv.org/abs/1704.07978
796;MDUJ920US38J;Muzero with self-competition for rate control in vp9 video compression ;https://arxiv.org/abs/2202.06626
797;BdLTmNycxqYJ;Imitation learning for non-autoregressive neural machine translation ;https://arxiv.org/abs/1906.02041
798;IHC_LcIAQnwJ;Active MR k-space Sampling with Reinforcement Learning ;https://link.springer.com/chapter/10.1007/978-3-030-59713-9_3
799;8T8JaAub3IYJ;PIC: permutation invariant critic for multi-agent deep reinforcement learning ;http://proceedings.mlr.press/v100/liu20a.html
800;TuH9j9IoS9UJ;Market sentiment-aware deep reinforcement learning approach for stock portfolio allocation ;https://www.sciencedirect.com/science/article/pii/S2215098621000070
801;p_Hf9qCbjVQJ;Visual reinforcement learning with self-supervised 3d representations ;https://ieeexplore.ieee.org/abstract/document/10077386/
802;jixjmJchK1YJ;A survey on active deep learning: from model driven to data driven ;https://dl.acm.org/doi/abs/10.1145/3510414
803;0NnUt8rwrQAJ;A deep reinforcement learning approach for global routing ;https://asmedigitalcollection.asme.org/mechanicaldesign/article-abstract/142/6/061701/1046956
804;TWtaB3GJGhIJ;Intelligent fault diagnosis for planetary gearbox using time-frequency representation and deep reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/9420305/
805;hph38GSMUSYJ;Active one-shot learning ;https://arxiv.org/abs/1702.06559
806;060SPIZgzYoJ;Assessing deep generative models in chemical composition space ;https://pubs.acs.org/doi/abs/10.1021/acs.chemmater.2c01860
807;PRFFwI5UYYUJ;Transfer learning for related reinforcement learning tasks via image-to-image translation ;http://proceedings.mlr.press/v97/gamrian19a.html
808;3eOYLXq6H1MJ;Meta-learning update rules for unsupervised representation learning ;https://arxiv.org/abs/1804.00222
809;L9k4UYdWwS8J;A multi-step predictive deep reinforcement learning algorithm for HVAC control systems in smart buildings ;https://www.sciencedirect.com/science/article/pii/S0360544222017601
810;ruv8Y-VjxVkJ;Efficiently solving the practical vehicle routing problem: A novel joint learning approach ;https://dl.acm.org/doi/abs/10.1145/3394486.3403356
811;CMQV8eN4MUgJ;Survey on the attention based RNN model and its applications in computer vision ;https://arxiv.org/abs/1601.06823
812;xxjD8EyzfnoJ;Generative adversarial learning for spectrum sensing ;https://ieeexplore.ieee.org/abstract/document/8422223/
813;MxPkP54k6kEJ;Minimax value interval for off-policy evaluation and policy optimization ;https://proceedings.neurips.cc/paper/2020/hash/1cd138d0499a68f4bb72bee04bbec2d7-Abstract.html
814;DbqiWBlVnSwJ;Reinforcement learning with multiple relational attention for solving vehicle routing problems ;https://ieeexplore.ieee.org/abstract/document/9478307/
815;9r1b9l7vx84J;On reinforcement learning for full-length game of starcraft ;https://ojs.aaai.org/index.php/AAAI/article/view/4394
816;_gunua-lZjUJ;DQN-based optimization framework for secure sharded blockchain systems ;https://ieeexplore.ieee.org/abstract/document/9133069/
817;vLQscG4lGlQJ;Continuous coordination as a realistic scenario for lifelong learning ;https://proceedings.mlr.press/v139/nekoei21a.html
818;ugN8KKAn7kAJ;DDPG-based adaptive robust tracking control for aerial manipulators with decoupling approach ;https://ieeexplore.ieee.org/abstract/document/9345436/
819;yAQxO2EHiX4J;Online computation offloading and resource scheduling in mobile-edge computing ;https://ieeexplore.ieee.org/abstract/document/9321469/
820;tG_KjAeDq1UJ;A simulation-deep reinforcement learning (SiRL) approach for epidemic control optimization ;https://link.springer.com/article/10.1007/s10479-022-04926-7
821;1qQf50thG5AJ;Robot skill acquisition in assembly process using deep reinforcement learning ;https://www.sciencedirect.com/science/article/pii/S0925231219301316
822;PoUkmojz-LcJ;Model-based meta-reinforcement learning for flight with suspended payloads ;https://ieeexplore.ieee.org/abstract/document/9345959/
823;Lxf45d8RECsJ;Reinforcement learning applied to Forex trading ;https://www.sciencedirect.com/science/article/pii/S1568494618305349
824;rdGSwyXfzuMJ;Real-time artificial intelligence for accelerator control: A study at the Fermilab Booster ;https://journals.aps.org/prab/abstract/10.1103/PhysRevAccelBeams.24.104601
825;q5nPgr49mgcJ;Honor of kings arena: an environment for generalization in competitive reinforcement learning ;https://proceedings.neurips.cc/paper_files/paper/2022/hash/4dbb61cb68671edc4ca3712d70083b9f-Abstract-Datasets_and_Benchmarks.html
826;I1Yb-MUmsmcJ;Offline reinforcement learning as anti-exploration ;https://ojs.aaai.org/index.php/AAAI/article/view/20783
827;kpmduCPJq0IJ;A tutorial on optimal control and reinforcement learning methods for quantum technologies ;https://www.sciencedirect.com/science/article/pii/S0375960122001360
828;v6xzIvo54o4J;A deep Q-learning portfolio management framework for the cryptocurrency market ;https://link.springer.com/article/10.1007/s00521-020-05359-8
829;THBWS7r2x6kJ;Back to basics: Benchmarking canonical evolution strategies for playing atari ;https://arxiv.org/abs/1802.08842
830;ivvkgN15_lEJ;Learning transferable cooperative behavior in multi-agent teams ;https://arxiv.org/abs/1906.01202
831;fNy0jFi65wYJ;Empiricism without magic: Transformational abstraction in deep convolutional neural networks ;https://link.springer.com/article/10.1007/s11229-018-01949-1
832;XrWiyFXXZVAJ;Combining neural networks and tree search for task and motion planning in challenging environments ;https://ieeexplore.ieee.org/abstract/document/8206505/
833;Q2M3W92cG6YJ;Parallel reinforcement learning-based energy efficiency improvement for a cyber-physical system ;https://ieeexplore.ieee.org/abstract/document/9016408/
834;KxlHRVJSgMUJ;Adversarial policy training against deep reinforcement learning ;https://www.usenix.org/conference/usenixsecurity21/presentation/wu-xian
835;8jCp2-3hlAYJ;DIMA: Distributed cooperative microservice caching for internet of things in edge computing by deep reinforcement learning ;https://link.springer.com/article/10.1007/s11280-021-00939-7
836;AJHSKLtVuCEJ;Towards comprehensive testing on the robustness of cooperative multi-agent reinforcement learning ;https://openaccess.thecvf.com/content/CVPR2022W/ArtOfRobust/html/Guo_Towards_Comprehensive_Testing_on_the_Robustness_of_Cooperative_Multi-Agent_Reinforcement_CVPRW_2022_paper.html
837;jaYNYW6X_IgJ;A survey on machine learning techniques for routing optimization in SDN ;https://ieeexplore.ieee.org/abstract/document/9493245/
838;kIhNo1DWrEoJ;Optimistic MLE: A Generic Model-Based Algorithm for Partially Observable Sequential Decision Making ;https://dl.acm.org/doi/abs/10.1145/3564246.3585161
839;KXL17bQyn38J;Machine learning approaches for reconfigurable intelligent surfaces: A survey ;https://ieeexplore.ieee.org/abstract/document/9729826/
840;ns_GySn06dAJ;Minimum throughput maximization for multi-UAV enabled WPCN: A deep reinforcement learning method ;https://ieeexplore.ieee.org/abstract/document/8950047/
841;-nQXzxP6ypsJ;Safe reinforcement learning for autonomous lane changing using set-based prediction ;https://ieeexplore.ieee.org/abstract/document/9294259/
842;l9PVkv-5Yt8J;Multimodal safety-critical scenarios generation for decision-making algorithms evaluation ;https://ieeexplore.ieee.org/abstract/document/9355111/
843;tzKET9skbQwJ;Using reinforcement learning with partial vehicle detection for intelligent traffic signal control ;https://ieeexplore.ieee.org/abstract/document/9050641/
844;0UPVOBkEMAQJ;Choosing the best of both worlds: Diverse and novel recommendations through multi-objective reinforcement learning ;https://dl.acm.org/doi/abs/10.1145/3488560.3498471
845;3GwnDOOGqDcJ;Plato: Policy learning using adaptive trajectory optimization ;https://ieeexplore.ieee.org/abstract/document/7989379/
846;_triRhYx4sAJ;Explainable deep learning in healthcare: A methodological survey from an attribution view ;https://wires.onlinelibrary.wiley.com/doi/abs/10.1002/wsbm.1548
847;-Vzho4QqHE8J;Superposition of many models into one ;https://proceedings.neurips.cc/paper/9269-superposition-of-many-models-into-one
848;oA93K4ZQHBcJ;Machine learning for optical fiber communication systems: An introduction and overview ;https://pubs.aip.org/aip/app/article-abstract/6/12/121101/1024561
849;Pe08qHDyp-kJ;Deep reinforcement learning for dynamic treatment regimes on medical registry data ;https://ieeexplore.ieee.org/abstract/document/8031178/
850;j8VJ07wLbEAJ;Lagrangian control through deep-rl: Applications to bottleneck decongestion ;https://ieeexplore.ieee.org/abstract/document/8569615/
851;Efg3cBto_fsJ;Optimizing matching time intervals for ride-hailing services using reinforcement learning ;https://www.sciencedirect.com/science/article/pii/S0968090X21002527
852;zVhhUN7kIpkJ;Trust-pcl: An off-policy trust region method for continuous control ;https://arxiv.org/abs/1707.01891
853;XufGxWoANjQJ;Discrete deep reinforcement learning for mapless navigation ;https://ieeexplore.ieee.org/abstract/document/9196739/
854;pK81MG_ZQYUJ;Brain-inspired cognitive model with attention for self-driving cars ;https://ieeexplore.ieee.org/abstract/document/7954050/
855;GQfsIZNCKzEJ;TIDE: Time-relevant deep reinforcement learning for routing optimization ;https://www.sciencedirect.com/science/article/pii/S0167739X19305424
856;eQv8nF-leSgJ;Interference and generalization in temporal difference learning ;https://proceedings.mlr.press/v119/bengio20a.html
857;0S0KSDiscwQJ;Cybersecurity threats and their mitigation approaches using Machine Learning—A Review ;https://www.mdpi.com/2624-800X/2/3/27
858;xRJET9YRuWEJ;Dear: Deep reinforcement learning for online advertising impression in recommender systems ;https://ojs.aaai.org/index.php/AAAI/article/view/16156
859;GdRoW1dIYq0J;Emergent behaviors in mixed-autonomy traffic ;http://proceedings.mlr.press/v78/wu17a.html
860;Y7c5BzTPPSIJ;A reinforcement learning approach to rare trajectory sampling ;https://iopscience.iop.org/article/10.1088/1367-2630/abd7bd/meta
861;3IY8kUJSn8kJ;Constrained deep reinforcement learning for energy sustainable multi-UAV based random access IoT networks with NOMA ;https://ieeexplore.ieee.org/abstract/document/9177252/
862;kA3YrHCubWYJ;Deep reinforcement learning-based computation offloading for 5G vehicle-aware multi-access edge computing network ;https://ieeexplore.ieee.org/abstract/document/9631180/
863;mNVabhc6cY8J;Learning multimodal rewards from rankings ;https://proceedings.mlr.press/v164/myers22a.html
864;X3DQ-agrmlYJ;Automated vehicle's behavior decision making using deep reinforcement learning and high-fidelity simulation environment ;https://www.sciencedirect.com/science/article/pii/S0968090X19311301
865;txshRwz-g1kJ;Reinforcement learning-based adaptive PID controller for DPS ;https://www.sciencedirect.com/science/article/pii/S0029801820309951
866;oaazC18USXEJ;Policy smoothing for provably robust reinforcement learning ;https://arxiv.org/abs/2106.11420
867;5ciyFeZglwoJ;Double deep q-learning for optimal execution ;https://www.tandfonline.com/doi/abs/10.1080/1350486X.2022.2077783
868;5OV7ryACOfMJ;CX-ToM: Counterfactual explanations with theory-of-mind for enhancing human trust in image recognition models ;https://www.cell.com/iscience/pdf/S2589-0042(21)01551-0.pdf
869;1IhXPEKVAMEJ;From discriminant to complete: Reinforcement searching-agent learning for weakly supervised object detection ;https://ieeexplore.ieee.org/abstract/document/9007022/
870;8IShlhvSLmsJ;An empirical study of the impact of hyperparameter tuning and model optimization on the performance properties of deep neural networks ;https://dl.acm.org/doi/abs/10.1145/3506695
871;aaFsqwQRmoEJ;Deep reinforcement learning for load-balancing aware network control in IoT edge systems ;https://ieeexplore.ieee.org/abstract/document/9555233/
872;QGl5g3kJkQMJ;On deep reinforcement learning for traffic engineering in SD-WAN ;https://ieeexplore.ieee.org/abstract/document/9279336/
873;2nxE8lEmRS4J;The neuroconnectionist research programme ;https://www.nature.com/articles/s41583-023-00705-w
874;U6X4WF2yEjEJ;Cooperative multimodal approach to depression detection in twitter ;https://ojs.aaai.org/index.php/AAAI/article/view/3775
875;b6NRvqP7ue8J;Time: A training-in-memory architecture for memristor-based deep neural networks ;https://dl.acm.org/doi/abs/10.1145/3061639.3062326
876;OT1v-jNGTxsJ;Adaptive neuro-fuzzy PID controller based on twin delayed deep deterministic policy gradient algorithm ;https://www.sciencedirect.com/science/article/pii/S0925231220304367
877;n6yePwjQ_QQJ;Mapper: Multi-agent path planning with evolutionary reinforcement learning in mixed dynamic environments ;https://ieeexplore.ieee.org/abstract/document/9340876/
878;d-x2mTAkHDcJ;Meta-reward-net: Implicitly differentiable reward learning for preference-based reinforcement learning ;https://proceedings.neurips.cc/paper_files/paper/2022/hash/8be9c134bb193d8bd3827d4df8488228-Abstract-Conference.html
879;nc6owma-rhgJ;Deep reinforcement learning for robotic assembly of mixed deformable and rigid objects ;https://ieeexplore.ieee.org/abstract/document/8594353/
880;Y-_W4-NKusYJ;Fine-grained gap-dependent bounds for tabular mdps via adaptive multi-step bootstrap ;http://proceedings.mlr.press/v134/xu21a.html
881;lfTdSXIkqPwJ;Autonomous penetration testing based on improved deep q-network ;https://www.mdpi.com/2076-3417/11/19/8823
882;4Qu-AY13fO4J;Autonomous unmanned aerial vehicle navigation using reinforcement learning: A systematic review ;https://www.sciencedirect.com/science/article/pii/S095219762200358X
883;zn2bLyLCgZUJ;Unsupervised paraphrasing via deep reinforcement learning ;https://dl.acm.org/doi/abs/10.1145/3394486.3403231
884;y3SI4_xR93oJ;Distributed agent-based deep reinforcement learning for large scale traffic signal control ;https://www.sciencedirect.com/science/article/pii/S095070512200106X
885;Z7AK4fuduywJ;Real-time scheduling for dynamic partial-no-wait multiobjective flexible job shop by deep reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/9521514/
886;d9sHXtOelcQJ;Deepthermal: Combustion optimization for thermal power generating units using offline reinforcement learning ;https://ojs.aaai.org/index.php/AAAI/article/view/20393
887;TdmHHNzlal4J;Learning bellman complete representations for offline policy evaluation ;https://proceedings.mlr.press/v162/chang22b.html
888;L6Uy2YbUQAgJ;Giraffe: Using deep reinforcement learning to play chess ;https://arxiv.org/abs/1509.01549
889;qSAEzWf_PjQJ;Meta-reinforcement learning for robotic industrial insertion tasks ;https://ieeexplore.ieee.org/abstract/document/9340848/
890;d5q1cuTPUUUJ;Social coordination and altruism in autonomous driving ;https://ieeexplore.ieee.org/abstract/document/9905741/
891;d9608la21GMJ;Global path planning algorithm based on double DQN for multi-tasks amphibious unmanned surface vehicle ;https://www.sciencedirect.com/science/article/pii/S0029801822020923
892;YGw9uwB3ABIJ;Open-sourced reinforcement learning environments for surgical robotics ;https://arxiv.org/abs/1903.02090
893;cBxKuYAKmgYJ;CoPace: Edge computation offloading and caching for self-driving with deep reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/9580706/
894;rws7wEuWvt4J;Learning heuristics over large graphs via deep reinforcement learning ;https://arxiv.org/abs/1903.03332
895;RPMdZxwsymwJ;Rethinking the implementation tricks and monotonicity constraint in cooperative multi-agent reinforcement learning ;https://arxiv.org/abs/2102.03479
896;IChiHAgHMQYJ;Policy gradient adaptive critic design with dynamic prioritized experience replay for wastewater treatment process control ;https://ieeexplore.ieee.org/abstract/document/9520253/
897;sQPGpDRvdrQJ;Binarized-blstm-rnn based human activity recognition ;https://ieeexplore.ieee.org/abstract/document/7743581/
898;qo9w4sASrNQJ;An empirical review of automated machine learning ;https://www.mdpi.com/2073-431X/10/1/11
899;xdqSzeAkIIUJ;Deep reinforcement learning for visual object tracking in videos ;https://arxiv.org/abs/1701.08936
900;KeMPpDPOhD0J;Pommerman: A multi-agent playground ;https://arxiv.org/abs/1809.07124
901;E2ud5Ogvr44J;Procedural generation of videos to train deep action recognition networks ;https://openaccess.thecvf.com/content_cvpr_2017/poster/1978_POSTER.pdf
902;aelZ1U90jacJ;Deep reinforcement learning for network slicing with heterogeneous resource requirements and time varying traffic dynamics ;https://ieeexplore.ieee.org/abstract/document/9012702/
903;uVvJbNdu_IYJ;Provably efficient reinforcement learning with general value function approximation ;https://ask.qcloudimg.com/draft/4932496/bj3y1htbm.pdf
904;7FpoxkxnCYEJ;A bi-level framework for learning to solve combinatorial optimization on graphs ;https://proceedings.neurips.cc/paper/2021/hash/b2f627fff19fda463cb386442eac2b3d-Abstract.html
905;Gfth7ylkt4cJ;Collaborative pushing and grasping of tightly stacked objects via deep reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/9536651/
906;LPjopaSK6icJ;Cloud resource scheduling with deep reinforcement learning and imitation learning ;https://ieeexplore.ieee.org/abstract/document/9200455/
907;vpMm5kv_16oJ;Harmonious lane changing via deep reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/9325948/
908;T4_QBB9U_2UJ;A deep reinforcement learning based multi-criteria decision support system for optimizing textile chemical process ;https://www.sciencedirect.com/science/article/pii/S0166361520306072
909;MJs-POTZQygJ;Forecasting extreme labor displacement: A survey of AI practitioners ;https://www.sciencedirect.com/science/article/pii/S0040162520311495
910;bFSctPcOPOYJ;Deep reinforcement learning for market making in corporate bonds: beating the curse of dimensionality ;https://www.tandfonline.com/doi/abs/10.1080/1350486X.2020.1714455
911;bx3sBzxdhpgJ;Hierarchical reinforcement learning for open-domain dialog ;https://ojs.aaai.org/index.php/AAAI/article/view/6400
912;hRJHG-pShhIJ;Application of deep reinforcement learning in mobile robot path planning ;https://ieeexplore.ieee.org/abstract/document/8244061/
913;m_Z53temBWwJ;Temporal abstraction in reinforcement learning with the successor representation ;https://www.jmlr.org/papers/volume24/21-1213/21-1213.pdf
914;t59eMXzISxYJ;Deep reinforcement learning in quantitative algorithmic trading: A review ;https://arxiv.org/abs/2106.00123
915;5ABa6VS19NwJ;Online parking assignment in an environment of partially connected vehicles: A multi-agent deep reinforcement learning approach ;https://www.sciencedirect.com/science/article/pii/S0968090X22000699
916;t1XvGwtKGx8J;Detecting flaky tests in probabilistic and machine learning applications ;https://dl.acm.org/doi/abs/10.1145/3395363.3397366
917;QeRH4jv_C14J;Multi-agent reinforcement learning for cooperative lane changing of connected and autonomous vehicles in mixed traffic ;https://link.springer.com/article/10.1007/s43684-022-00023-5
918;CW9tRY9IXdAJ;Crop: Certifying robust policies for reinforcement learning through functional smoothing ;https://arxiv.org/abs/2106.09292
919;vCNLznT5akYJ;Off-policy fitted q-evaluation with differentiable function approximators: Z-estimation and inference theory ;https://proceedings.mlr.press/v162/zhang22al.html
920;304EOyUg7EkJ;Too Many Cooks: Bayesian Inference for Coordinating Multi‐Agent Collaboration ;https://onlinelibrary.wiley.com/doi/abs/10.1111/tops.12525
921;ZHtWux2kUf8J;Learning tailored adaptive bitrate algorithms to heterogeneous network conditions: A domain-specific priors and meta-reinforcement learning approach ;https://ieeexplore.ieee.org/abstract/document/9796516/
922;4zXvCf6iQqYJ;Optimal elevator group control via deep asynchronous actor–critic learning ;https://ieeexplore.ieee.org/abstract/document/8998335/
923;Hk0DK3PQNF0J;On reliability of reinforcement learning based production scheduling systems: a comparative survey ;https://link.springer.com/article/10.1007/s10845-022-01915-2
924;cjw5syIsJNAJ;BLOX: Macro neural architecture search benchmark and algorithms ;https://proceedings.neurips.cc/paper_files/paper/2022/hash/c7589a96e8adfcf5a006c452b3758fd5-Abstract-Datasets_and_Benchmarks.html
925;lRkcbfO6hxEJ;A survey of dynamic spectrum allocation based on reinforcement learning algorithms in cognitive radio networks ;https://link.springer.com/article/10.1007/s10462-018-9639-x
926;-zYghzWw4uMJ;SCOPE: An open and softwarized prototyping platform for NextG systems ;https://dl.acm.org/doi/abs/10.1145/3458864.3466863
927;cZaZ56pxRIMJ;Stability-certified reinforcement learning: A control-theoretic perspective ;https://ieeexplore.ieee.org/abstract/document/9296215/
928;-lnqmBED9FcJ;Replay in minds and machines ;https://www.sciencedirect.com/science/article/pii/S0149763421003444
929;LT5Z1Q6NoGkJ;Explainable reinforcement learning in production control of job shop manufacturing system ;https://www.tandfonline.com/doi/abs/10.1080/00207543.2021.1972179
930;_qOqHh5PdqEJ;Revisiting knowledge distillation: An inheritance and exploration framework ;http://openaccess.thecvf.com/content/CVPR2021/html/Huang_Revisiting_Knowledge_Distillation_An_Inheritance_and_Exploration_Framework_CVPR_2021_paper.html
931;QYhGt8uRvgsJ;Reinforcement learning for autonomous driving with latent state inference and spatial-temporal relationships ;https://ieeexplore.ieee.org/abstract/document/9562006/
932;5RSyvHHkXV0J;Action schema networks: Generalised policies with deep learning ;https://ojs.aaai.org/index.php/AAAI/article/view/12089
933;kuJwdSYoujcJ;Appl: Adaptive planner parameter learning ;https://www.sciencedirect.com/science/article/pii/S0921889022000744
934;cytGb_3EufMJ;Adapting deep visuomotor representations with weak pairwise constraints ;https://link.springer.com/chapter/10.1007/978-3-030-43089-4_44
935;ydA5E3Ze1i0J;Quantum error correction for the toric code using deep reinforcement learning ;https://quantum-journal.org/papers/q-2019-09-02-183/
936;zxTxX-zL4ZsJ;A survey of learning-based control of robotic visual servoing systems ;https://www.sciencedirect.com/science/article/pii/S0016003221006621
937;EN_Q6QCUIPMJ;DQELR: An adaptive deep Q-network-based energy-and latency-aware routing protocol design for underwater acoustic sensor networks ;https://ieeexplore.ieee.org/abstract/document/8606050/
938;dLToGKYNN_kJ;Understanding domain randomization for sim-to-real transfer ;https://arxiv.org/abs/2110.03239
939;0fnhejrV8rMJ;Pontryagin differentiable programming: An end-to-end learning and control framework ;https://proceedings.neurips.cc/paper/2020/hash/5a7b238ba0f6502e5d6be14424b20ded-Abstract.html
940;WRanK_pqHXUJ;Deep multi-user reinforcement learning for dynamic spectrum access in multichannel wireless networks ;https://ieeexplore.ieee.org/abstract/document/8254101/
941;DE8gZ2cPeNkJ;Selective data acquisition in the wild for model charging ;https://dl.acm.org/doi/abs/10.14778/3523210.3523223
942;6K7YJpoH8QQJ;A survey of explainable reinforcement learning ;https://arxiv.org/abs/2202.08434
943;R6jzaRbihksJ;Graph convolutional recurrent networks for reward shaping in reinforcement learning ;https://www.sciencedirect.com/science/article/pii/S0020025522006442
944;a2bjHcP31GkJ;Optimization of the electricity generation of a wave energy converter using deep reinforcement learning ;https://www.sciencedirect.com/science/article/pii/S0029801821016590
945;NXKBZtq1vRoJ;A review on deep reinforcement learning for fluid mechanics: An update ;https://pubs.aip.org/aip/pof/article/34/11/111301/2846714
946;vJA6obpRlacJ;Dsac: Distributional soft actor critic for risk-sensitive reinforcement learning ;https://arxiv.org/abs/2004.14547
947;88LOKkvjYeIJ;Modern perspectives on reinforcement learning in finance ;https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3449401
948;mMH_kYQ1WDAJ;Semantic-transferable weakly-supervised endoscopic lesions segmentation ;http://openaccess.thecvf.com/content_ICCV_2019/html/Dong_Semantic-Transferable_Weakly-Supervised_Endoscopic_Lesions_Segmentation_ICCV_2019_paper.html
949;NP9JYZZjDFsJ;Adarl: What, where, and how to adapt in transfer reinforcement learning ;https://arxiv.org/abs/2107.02729
950;ekkov1PRkMYJ;Early rumour detection ;https://aclanthology.org/N19-1163/
951;mOobSqZ5wW4J;Learn to navigate: cooperative path planning for unmanned surface vehicles using deep reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/8897592/
952;FcYptqvH0sYJ;From distributed machine learning to federated learning: In the view of data privacy and security ;https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.6002
953;JrHNsqypCZgJ;Deep reinforcement learning for combinatorial optimization: Covering salesman problems ;https://ieeexplore.ieee.org/abstract/document/9523517/
954;XL-D5cSvqf4J;Urban driving with multi-objective deep reinforcement learning ;https://arxiv.org/abs/1811.08586
955;wHYIAg_WeyYJ;Incorporating behavioral constraints in online AI systems ;https://ojs.aaai.org/index.php/AAAI/article/view/3762
956;Dr94B8xMXQ4J;Off-policy reinforcement learning for efficient and effective gan architecture search ;https://link.springer.com/chapter/10.1007/978-3-030-58571-6_11
957;eZ7ccsP2pGcJ;Striving for simplicity in off-policy deep reinforcement learning ;https://openreview.net/forum?id=ryeUg0VFwr
958;XrWw36sGFGgJ;Cooperative edge caching: A multi-agent deep learning based approach ;https://ieeexplore.ieee.org/abstract/document/9144224/
959;XfYDQIyNjssJ;Building ethically bounded AI ;https://ojs.aaai.org/index.php/AAAI/article/view/5051
960;IqdmnqmgMCQJ;Physics informed deep reinforcement learning for aircraft conflict resolution ;https://ieeexplore.ieee.org/abstract/document/9430767/
961;D1arKZu3regJ;Microgrid energy management using deep Q-network reinforcement learning ;https://www.sciencedirect.com/science/article/pii/S1110016822001284
962;l5dLXT3VU0UJ;Automatic view generation with deep learning and reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/9101360/
963;vz5QLm65wIkJ;Multiagent soft q-learning ;https://arxiv.org/abs/1804.09817
964;iR12yQCmZE4J;Quantum neural networks: Concepts, applications, and challenges ;https://ieeexplore.ieee.org/abstract/document/9528698/
965;NIDZy0M4RSUJ;A review of deep learning algorithms and their applications in healthcare ;https://www.mdpi.com/1999-4893/15/2/71
966;WTyZdHGXxZEJ;A mean-field game approach to cloud resource management with function approximation ;https://proceedings.neurips.cc/paper_files/paper/2022/hash/eb3c8135137c8a60425a0320869ad87e-Abstract-Conference.html
967;QAofRTbGojkJ;Deep reinforcement learning: a survey ;https://ieeexplore.ieee.org/abstract/document/9904958/
968;ygzrM2Omk84J;Unrestricted adversarial examples ;https://arxiv.org/abs/1809.08352
969;OPkh4_DZtPAJ;Automated spectroscopic modelling with optimised convolutional neural networks ;https://www.nature.com/articles/s41598-020-80486-9
970;KZmgm33c8NoJ;Deep reinforcement learning techniques in diversified domains: a survey ;https://link.springer.com/article/10.1007/s11831-021-09552-3
971;PRJ7t6mt5BAJ;Constraints penalized q-learning for safe offline reinforcement learning ;https://ojs.aaai.org/index.php/AAAI/article/view/20855
972;sEB9iaw3u4oJ;Learning how to drive in a real world simulation with deep q-networks ;https://ieeexplore.ieee.org/abstract/document/7995727/
973;nk6IVSOOCHsJ;Constrained deep q-learning gradually approaching ordinary q-learning ;https://www.frontiersin.org/articles/10.3389/fnbot.2019.00103/full
974;gB0JpaLHnf0J;Real-time scheduling for distributed permutation flowshops with dynamic job arrivals using deep reinforcement learning ;https://www.sciencedirect.com/science/article/pii/S1474034622002348
975;-VW4RM0wnY8J;Deep reinforcement learning with stacked hierarchical attention for text-based games ;https://proceedings.neurips.cc/paper/2020/hash/bf65417dcecc7f2b0006e1f5793b7143-Abstract.html
976;bKkBbeSiYNcJ;Distributed reinforcement learning algorithm for dynamic economic dispatch with unknown generation cost functions ;https://ieeexplore.ieee.org/abstract/document/8789399/
977;sEjuxUYGZXEJ;Reinforcement learning for autonomous defence in software-defined networking ;https://link.springer.com/chapter/10.1007/978-3-030-01554-1_9
978;VBFgmoGli_YJ;Chalet: Cornell house agent learning environment ;https://arxiv.org/abs/1801.07357
979;h-MKexWCagAJ;Learning to unknot ;https://iopscience.iop.org/article/10.1088/2632-2153/abe91f/meta
980;BBn5dpK4qu4J;Deep reinforcement agent for scheduling in HPC ;https://ieeexplore.ieee.org/abstract/document/9460549/
981;mcR227pdOisJ;Reinforcement learning based dynamic model combination for time series forecasting ;https://ojs.aaai.org/index.php/AAAI/article/view/20618
982;9F66eK_QivUJ;FedAdapt: Adaptive Offloading for IoT Devices in Federated Learning ;https://ieeexplore.ieee.org/abstract/document/9778210/
983;d01NKiDEmsQJ;Meta-learning of sequential strategies ;https://arxiv.org/abs/1905.03030
984;d0-gZdwGyUsJ;Active world model learning with progress curiosity ;http://proceedings.mlr.press/v119/kim20e.html
985;kjV1YseV1VIJ;On-policy deep reinforcement learning for the average-reward criterion ;http://proceedings.mlr.press/v139/zhang21q.html
986;KTw3b_ZPGHkJ;The phenomenon of policy churn ;https://proceedings.neurips.cc/paper_files/paper/2022/hash/114292cf3f930ba157ed33f66997fee2-Abstract-Conference.html
987;mEKjJPH2KxEJ;A unified framework for alternating offline model training and policy learning ;https://proceedings.neurips.cc/paper_files/paper/2022/hash/6dc02cf4905e873ca6fd0dfc7907e230-Abstract-Conference.html
988;gBEbiUnXIzkJ;A domain-agnostic approach for characterization of lifelong learning systems ;https://www.sciencedirect.com/science/article/pii/S0893608023000072
989;57x2DxGiWeoJ;Comyco: Quality-aware adaptive video streaming via imitation learning ;https://dl.acm.org/doi/abs/10.1145/3343031.3351014
990;wcrhW0QAOrkJ;On pathologies in KL-regularized reinforcement learning from expert demonstrations ;https://proceedings.neurips.cc/paper/2021/hash/eecca5b6365d9607ee5a9d336962c534-Abstract.html
991;ozdoUBZkbc0J;Deep reinforcement learning for black-box testing of android apps ;https://dl.acm.org/doi/abs/10.1145/3502868
992;kTWi8KWdyFAJ;State of the art control of atari games using shallow reinforcement learning ;https://arxiv.org/abs/1512.01563
993;iy4TJL8IV9cJ;A reinforcement learning-based framework for disruption risk identification in supply chains ;https://www.sciencedirect.com/science/article/pii/S0167739X21003034
994;pb5SEp5K2ncJ;Deep reinforcement learning for dynamic flexible job shop scheduling with random job arrival ;https://www.mdpi.com/2227-9717/10/4/760
995;MrUy6wr2sUUJ;Deep reinforcement learning with temporal logics ;https://link.springer.com/chapter/10.1007/978-3-030-57628-8_1
996;1gNUovgxEQkJ;Exploring applications of deep reinforcement learning for real-world autonomous driving systems ;https://arxiv.org/abs/1901.01536
997;clH2_mF2DkUJ;Explaining therapy predictions with layer-wise relevance propagation in neural networks ;https://ieeexplore.ieee.org/abstract/document/8419358/
998;hgOGL5HZl5gJ;Derin öğrenme ve görüntü analizinde kullanılan derin öğrenme modelleri ;https://dergipark.org.tr/en/pub/gbad/issue/31228/330663
999;WttyypWndOEJ;Trajectory planning for multi-robot systems: Methods and applications ;https://www.sciencedirect.com/science/article/pii/S0957417421001019
1000;AYJMavnHWQAJ;Proactive human–robot collaboration: Mutual-cognitive, predictable, and self-organising perspectives ;https://www.sciencedirect.com/science/article/pii/S0736584522001922
1001;Pez5ZFS2tZAJ;A review of motion planning algorithms for intelligent robots ;https://link.springer.com/article/10.1007/s10845-021-01867-z
1002;64Ut5fo-IZUJ;Path planning for multi-arm manipulators using deep reinforcement learning: Soft actor–critic with hindsight experience replay ;https://www.mdpi.com/1424-8220/20/20/5911
1003;JSmAry0awqsJ;Energy-efficient path planning for a single-load automated guided vehicle in a manufacturing workshop ;https://www.sciencedirect.com/science/article/pii/S0360835221003016
1004;tAzbaqSIO5EJ;A review of path-planning approaches for multiple mobile robots ;https://www.mdpi.com/2075-1702/10/9/773
1005;_VteqT51UHoJ;A modified cuckoo search algorithm implemented with SCA and PSO for multi-robot cooperation and path planning ;https://www.sciencedirect.com/science/article/pii/S1389041723000050
1006;UmcArto6JicJ;The intelligent path planning system of agricultural robot via reinforcement learning ;https://www.mdpi.com/1424-8220/22/12/4316
1007;KjEF0YfAGIEJ;Motion planning of robot manipulators for a smoother path using a twin delayed deep deterministic policy gradient with hindsight experience replay ;https://www.mdpi.com/2076-3417/10/2/575
1008;CMpbbeUBl_sJ;Methods of condition monitoring and fault detection for electrical machines ;https://www.mdpi.com/1996-1073/14/22/7459
1009;rDs4byCLc6YJ;A multi-robot path-planning algorithm for autonomous navigation using meta-reinforcement learning based on transfer learning ;https://www.sciencedirect.com/science/article/pii/S1568494621005263
1010;McS4mLAolToJ;A novel hierarchical soft actor-critic algorithm for multi-logistics robots task allocation ;https://ieeexplore.ieee.org/abstract/document/9363881/
1011;ynbhupDGt7kJ;Review of autonomous path planning algorithms for mobile robots ;https://www.mdpi.com/2504-446X/7/3/211
1012;c0KZ5PGV3rkJ;A reinforcement learning‐based approach for modeling and coverage of an unknown field using a team of autonomous ground vehicles ;https://onlinelibrary.wiley.com/doi/abs/10.1002/int.22331
1013;TEX01NIRyWUJ;An intelligence-based hybrid PSO-SA for mobile robot path planning in warehouse ;https://www.sciencedirect.com/science/article/pii/S1877750322002976
1014;POi7FZsPEzoJ;Highly optimized Q‐learning‐based bees approach for mobile robot path planning in static and dynamic environments ;https://onlinelibrary.wiley.com/doi/abs/10.1002/rob.22052
1015;cZaDpjr-tCMJ;Integral reinforcement learning-based multi-robot minimum time-energy path planning subject to collision avoidance and unknown environmental disturbances ;https://ieeexplore.ieee.org/abstract/document/9134394/
1016;3mk85NXAvHMJ;Adaptive Routing in Wireless Mesh Networks Using Hybrid Reinforcement Learning Algorithm ;https://ieeexplore.ieee.org/abstract/document/9906058/
1017;UbpOSRoi3H8J;Research on motion planning based on flocking control and reinforcement learning for multi-robot systems ;https://www.mdpi.com/2075-1702/9/4/77
1018;EoaMSsC8XS8J;An overview of reinforcement learning methods for variable speed limit control ;https://www.mdpi.com/2076-3417/10/14/4917
1019;opTgHuELzaMJ;Multi-agent deep reinforcement learning for multi-robot applications: a survey ;https://www.mdpi.com/1424-8220/23/7/3625
1020;9HOwf6W6h6sJ;Multi-robot path planning based on improved artificial potential field and fuzzy inference system ;https://content.iospress.com/articles/journal-of-intelligent-and-fuzzy-systems/ifs200869
1021;gAmCuoAZ8gsJ;Neural tracking control of a four-wheeled mobile robot with mecanum wheels ;https://www.mdpi.com/2076-3417/12/11/5322
1022;q8RyAcgCWv4J;Deep reinforcement learning for cooperative robots based on adaptive sentiment feedback ;https://www.sciencedirect.com/science/article/pii/S0957417423017001
1023;LNA61nCZNxYJ;Distributed Multi-Mobile Robot Path Planning and Obstacle Avoidance Based on ACO–DWA in Unknown Complex Terrain ;https://www.mdpi.com/2079-9292/11/14/2144
1024;R7T39ApMkyMJ;A Local-and-Global Attention Reinforcement Learning Algorithm for Multiagent Cooperative Navigation ;https://ieeexplore.ieee.org/abstract/document/9953939/
1025;Koy7paUbPj8J;Towards the achievement of path planning with multi-robot systems in dynamic environments ;https://link.springer.com/article/10.1007/s10846-021-01555-3
1026;CrJY4z2GtDsJ;Improvised multi-robot cooperation strategy for hunting a dynamic target ;https://ieeexplore.ieee.org/abstract/document/9523684/
1027;qs_LTqF_waMJ;A global path planning algorithm for robots using reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/8961753/
1028;LvfZ1dNfoJUJ;Social navigation for mobile robots in the emergency department ;https://ieeexplore.ieee.org/abstract/document/9561897/
1029;gl-POzPf_08J;A systematic review on recent advances in autonomous mobile robot navigation ;https://www.sciencedirect.com/science/article/pii/S2215098623000204
1030;H0RoCuI8GacJ;An improved dueling deep double-q network based on prioritized experience replay for path planning of unmanned surface vehicles ;https://www.mdpi.com/2077-1312/9/11/1267
1031;DC69MOPrKEMJ;Decentralized multi-robot collision avoidance: A systematic review from 2015 to 2021 ;https://www.mdpi.com/2073-8994/14/3/610
1032;iNMA2219OsgJ;A Semi-Automatic Wheelchair with Navigation Based on Virtual-Real 2D Grid Maps and EEG Signals ;https://www.mdpi.com/2076-3417/12/17/8880
1033;lOlS7kbQfZAJ;TOOLTANGO: Common sense Generalization in Predicting Sequential Tool Interactions for Robot Plan Synthesis ;https://www.jair.org/index.php/jair/article/view/13791
1034;2zEWfHHvbH0J;A Path-Planning Approach Based on Potential and Dynamic Q-Learning for Mobile Robots in Unknown Environment ;https://www.hindawi.com/journals/cin/2022/2540546/
1035;vvVEc6mr1pMJ;Counterfactual-based action evaluation algorithm in multi-agent reinforcement learning ;https://www.mdpi.com/2076-3417/12/7/3439
1036;4wGKTvizqkMJ;Multi AGV coordination tolerant to communication failures ;https://www.mdpi.com/2218-6581/10/2/55
1037;svQpTvKaRcUJ;Improvement of dynamic window approach using reinforcement learning in dynamic environments ;https://link.springer.com/article/10.1007/s12555-021-0462-9
1038;WTyFBsvJE3MJ;Multi-robot co-operation for stick carrying application using hybridization of meta-heuristic algorithm ;https://www.sciencedirect.com/science/article/pii/S0378475422000106
1039;cCYpuNu1e0cJ;Indoor emergency path planning based on the Q-learning optimization algorithm ;https://www.mdpi.com/2220-9964/11/1/66
1040;V4uxbw7LwgoJ;Controlling fleets of autonomous mobile robots with reinforcement learning: a brief survey ;https://www.mdpi.com/2218-6581/11/5/85
1041;5wAs_rwqRooJ;A fuzzy analytic hierarchy process and cooperative game theory combined multiple mobile robot navigation algorithm ;https://www.mdpi.com/1424-8220/20/10/2827
1042;xZw1OtLKJssJ;An experimental safety response mechanism for an autonomous moving robot in a smart manufacturing environment using q-learning algorithm and speech … ;https://www.mdpi.com/1424-8220/22/3/941
1043;kQ6MnXEldDQJ;Tango: Commonsense generalization in predicting tool interactions for mobile manipulators ;https://arxiv.org/abs/2105.04556
1044;xp_cLKCdsPgJ;An efficient multi-robot path planning solution using A* and coevolutionary algorithms ;https://content.iospress.com/articles/integrated-computer-aided-engineering/ica220695
1045;MQjLIJcemj0J;Situating robots in the emergency department ;https://par.nsf.gov/biblio/10145648
1046;arOWOettJUsJ;Real-Time Hierarchical Map Segmentation for Coordinating Multirobot Exploration ;https://ieeexplore.ieee.org/abstract/document/9819930/
1047;I8MSt6FRSBgJ;Reinforcement learning-based algorithm to avoid obstacles by the anthropomorphic robotic arm ;https://www.mdpi.com/2076-3417/12/13/6629
1048;a9Wfc5Nv7ZMJ;Algorithms for path optimizations: a short survey ;https://link.springer.com/article/10.1007/s00607-022-01126-w
1049;ZWul-aMwd8gJ;Optimal solving of constrained path-planning problems with graph convolutional networks and optimized tree search ;https://ieeexplore.ieee.org/abstract/document/8968113/
1050;Twol_Lw4cxAJ;Long-term planning with deep reinforcement learning on autonomous drones ;https://ieeexplore.ieee.org/abstract/document/9259811/
1051;LWKXIMGqVP0J;A mixing algorithm of ACO and ABC for solving path planning of mobile robot ;https://www.sciencedirect.com/science/article/pii/S1568494623008864
1052;iUppZJ3QGrEJ;Informed anytime Bi-directional Fast Marching Tree for optimal motion planning in complex cluttered environments ;https://www.sciencedirect.com/science/article/pii/S0957417422022813
1053;KLaFdC_qqWsJ;A Framework and Algorithm for Human-Robot Collaboration Based on Multimodal Reinforcement Learning ;https://www.hindawi.com/journals/cin/2022/2341898/
1054;pRGvhxKsqEAJ;Deep reinforcement learning for path planning by cooperative robots: Existing approaches and challenges ;https://ieeexplore.ieee.org/abstract/document/9347628/
1055;xjpsWX1mZ2EJ;Learning user-defined sub-goals using memory editing in reinforcement learning ;https://arxiv.org/abs/2205.00399
1056;PHpXQBtgplsJ;Artificial Potential Field Incorporated Deep-Q-Network Algorithm for Mobile Robot Path Prediction. ;https://cdn.techscience.cn/ueditor/files/iasc/TSP_IASC-35-1/TSP_IASC_28126/TSP_IASC_28126.pdf
1057;oX_PAAEDey0J;Reinforcement-learning-based route generation for heavy-traffic autonomous mobile robot systems ;https://www.mdpi.com/1424-8220/21/14/4809
1058;Rm8yhgMrPggJ;Special issue on mobile robots navigation ;https://www.mdpi.com/2076-3417/10/4/1317/htm
1059;Pkqa2svKiMUJ;A multi-robot deep Q-learning framework for priority-based sanitization of railway stations ;https://link.springer.com/article/10.1007/s10489-023-04529-0
1060;ZEJ3zC0X1ZUJ;Global dynamic path‐planning algorithm in gravity‐aided inertial navigation system ;https://ietresearch.onlinelibrary.wiley.com/doi/abs/10.1049/sil2.12056
1061;ZvsqxRz5nF8J;Reinforcement learning for swarm robotics: An overview of applications, algorithms and simulators ;https://www.sciencedirect.com/science/article/pii/S2667241323000241
1062;RYvtvpsjL-EJ;Development of the neural-based navigation system for a ground-based mobile robot ;https://ieeexplore.ieee.org/abstract/document/9384825/
1063;olRbSNn2d-0J;基于深度强化学习的机器人运动控制研究进展 ;http://kzyjc.alljournals.cn/html/2022/2/20220203.htm
1064;x9-SWYvtCJcJ;A reinforcement learning model for material handling task assignment and route planning in dynamic production logistics environment ;https://www.sciencedirect.com/science/article/pii/S2212827121012038
1065;iv1B-CS_cQ0J;Flexible Route Planning for Multiple Mobile Robots by Combining Q–Learning and Graph Search Algorithm ;https://www.mdpi.com/2076-3417/13/3/1879
1066;yDGkrRjQdPgJ;Optimal Route Generation and Route-Following Control for Autonomous Vessel ;https://www.mdpi.com/2077-1312/11/5/970
1067;TV4J7wri9KcJ;Dynamic Analysis and Path Planning of a Turtle-Inspired Amphibious Spherical Robot ;https://www.mdpi.com/2072-666X/13/12/2130
1068;nALA1G60sb0J;Research Hotspots and Frontier Prospects in the Field of Agroforestry Picking Robots in China—Cite Space Bibliographic Analysis ;https://www.mdpi.com/1999-4907/14/9/1874
1069;hnNRIcICS1IJ;Development of a Cascade Intelligent System for Path Planning of the Group of Marine Robotic Complexes ;https://www.mdpi.com/2077-1312/11/3/610
1070;uXR9adICqocJ;Reinforcement learning based path planning using a topological map for mobile service robot ;https://ieeexplore.ieee.org/abstract/document/10234766/
1071;1YAmz7mJPQsJ;Deep Reinforcement Learning Algorithms for Path Planning Domain in Grid-like Environment ;https://www.mdpi.com/2076-3417/11/23/11335
1072;N6lFDxrNH0MJ;Optimized-Weighted-Speedy Q-Learning Algorithm for Multi-UGV in Static Environment Path Planning under Anti-Collision Cooperation Mechanism ;https://www.mdpi.com/2227-7390/11/11/2476
1073;C70dRK3k0-UJ;Optimal Morphologies of n-Omino-Based Reconfigurable Robot for Area Coverage Task Using Metaheuristic Optimization ;https://www.mdpi.com/2227-7390/11/4/948
1074;xFlDKdlgqh0J;GoalNet: Inferring Conjunctive Goal Predicates from Human Plan Demonstrations for Robot Instruction Following ;https://arxiv.org/abs/2205.07081
1075;tofcFhypXnUJ;Path Planning for Autonomous Vehicles in Unknown Dynamic Environment Based on Deep Reinforcement Learning ;https://www.mdpi.com/2076-3417/13/18/10056
1076;XMYe3kQetA8J;Digital-Twin-Driven AGV Scheduling and Routing in Automated Container Terminals ;https://www.mdpi.com/2227-7390/11/12/2678
1077;RQbiwJaZ_UwJ;Methods of Condition Monitoring and Fault Detection for Electrical Machines. Energies 2021, 14, 7459 ;https://www.academia.edu/download/74710795/pdf.pdf
1078;0xY3U4DsyKQJ;Path planning method of mobile robot based on Q-learning ;https://iopscience.iop.org/article/10.1088/1742-6596/2181/1/012030/meta
1079;wx9RVBKFqLUJ;MARBLER: An Open Platform for Standarized Evaluation of Multi-Robot Reinforcement Learning Algorithms ;https://arxiv.org/abs/2307.03891
1080;hQZyKsBSGT4J;Reinforcement learning with modified exploration strategy for mobile robot path planning ;https://www.cambridge.org/core/journals/robotica/article/reinforcement-learning-with-modified-exploration-strategy-for-mobile-robot-path-planning/464947897085CB3DA37A658C7FEF4775
1081;a-7DbU5QuwcJ;A Novel Algorithm for Optimal Trajectory Generation Using Q Learning ;https://link.springer.com/article/10.1007/s42979-023-01876-0
1082;vc99EyWl1kEJ;Distributed multirobot path planning based on MRDWA-MADDPG ;https://ieeexplore.ieee.org/abstract/document/10242333/
1083;Cuievs0ZqUAJ;Cooperative Sampling Path Planning of Underwater Glider Fleet with Simultaneous Launch and Recovery ;https://link.springer.com/article/10.1007/s11802-023-5373-3
1084;NfbY07Gqn4UJ;移动机器人路径规划算法的研究综述. ;https://search.ebscohost.com/login.aspx?direct=true&profile=ehost&scope=site&authtype=crawler&jrnl=10028331&AN=152484337&h=yAyQ8xLb1ZIzPMGj0VY%2Fjsx5ewTEPknnZoOqlSRmbwcmHDgo5yko6czVjOSk%2FXxlZrU3W3KL14si%2BEdg5bPOwA%3D%3D&crl=c
1085;VL11LqYB7IIJ;A deep reinforcement learning strategy for autonomous robot flocking. ;https://search.ebscohost.com/login.aspx?direct=true&profile=ehost&scope=site&authtype=crawler&jrnl=20888708&AN=172294753&h=bTOzrZWNV9zybYgARidRDvGtLHTlb3wDlOfLodDIn0zHyJa69RApZjLiNHRDRCYjiPtzzEXf64MBXoDOly2NzA%3D%3D&crl=c
1086;1KkR3h2NaTcJ;Plugin Framework-Based Neuro-Symbolic Grounded Task Planning for Multi-Agent System ;https://www.mdpi.com/1424-8220/21/23/7896
1087;aJ6SRPQkegwJ;Trip Planning for Autonomous Vehicles with Wireless Data Transfer Needs Using Reinforcement Learning ;https://ieeexplore.ieee.org/abstract/document/9973646/
1088;jCKGdj6gAS0J;The Development of a Multi-Agent System for Controlling an Autonomous Robot. ;http://ceur-ws.org/Vol-3013/20210096.pdf
1089;Sa0CZZpy94cJ;An efficient multi-robot path planning solution using A* and coevolutionary algorithms ;https://digibuo.uniovi.es/dspace/handle/10651/67799
1090;u2QZBkvdJIsJ;A deep Q-Learning based Path Planning and Navigation System for Firefighting Environments ;https://arxiv.org/abs/2011.06450
1091;OGAv39VborgJ;Deep Q learning based reinforcement learning and Kalman filter method for mobile robot trajectory control and tracking ;https://pubs.aip.org/aip/acp/article/2888/1/020025/2910981
1092;ut3QyMyEDs4J;Toward a Heterogeneous Multi-robot Framework for Priority-Based Sanitization of Railway Stations ;https://link.springer.com/chapter/10.1007/978-3-031-27181-6_27
1093;Gk8VVTZR_AwJ;Voronoi-based collision avoidance using localization uncertainty region ;https://ieeexplore.ieee.org/abstract/document/9894486/
1094;BNsjo03pyoEJ;Performance Evaluation of Reinforcement Learning and Graph Search-based Algorithm for Mobile Robot Path Planning ;https://ieeexplore.ieee.org/abstract/document/10252984/
1095;-e3gmXL-sSAJ;Autonomous multi-robot allocation and formation control for remote sensing in environmental exploration ;https://www.spiedigitallibrary.org/conference-proceedings-of-spie/12540/125400U/Autonomous-multi-robot-allocation-and-formation-control-for-remote-sensing/10.1117/12.2663894.short
1096;5QLwqr3Qx98J;Optimal Path Planning of Planetary Rovers with Safety Considerable ;https://link.springer.com/chapter/10.1007/978-981-16-9492-9_325
1097;0c5dTWwzpBIJ;Path Planning for Amphibious Robots based on Multi-optimization Strategy A* Algorithm ;https://ieeexplore.ieee.org/abstract/document/10216165/
1098;k6H6mZytLSEJ;Trajectory planning for hypersonic vehicles with reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/9549361/
1099;TtHtvWssXMMJ;Deep reinforcement learning for crowd-aware robotic navigation ;https://erepo.uef.fi/bitstream/handle/123456789/30642/urn_isbn_978-952-61-4979-0.pdf?sequence=1
1100;B0i0EQmHHv8J;Automatic UAV Swarm Task Planning in Cooperative Region Coverage Detection based on Greedy Policy ;https://ieeexplore.ieee.org/abstract/document/9986918/
1101;wgTtmc0tT-UJ;Intelligent Hybrid Approaches for Mobile Robots Path Planning ;https://opus.lib.uts.edu.au/handle/10453/171955
1102;uhJksq0jLM0J;Overview of Methods for Collision Avoidance for Unmanned Aerial Vehicles ;https://ieeexplore.ieee.org/abstract/document/10221230/
1103;7OgRwncwi0gJ;Path planning of mobile robot based on deep reinforcement learning with transfer learning strategy ;https://ieeexplore.ieee.org/abstract/document/10023708/
1104;5NpcxfbeCGwJ;Path Planning for Teams of Mobile Robots ;https://dl.acm.org/doi/abs/10.1145/3584376.3584391
1105;lZevP8VTKZwJ;Learn to Follow: Lifelong Multi-agent Pathfinding with Decentralized Replanning ;https://openreview.net/forum?id=vMV4tsA639
1106;EwNyYwtWl3AJ;A Safety Response Mechanism for an Autonomous Moving Robot in a Small Manufacturing Environment using Q-learning Algorithm and Speech Recognition ;https://www.researchsquare.com/article/rs-703829/latest
1107;0mhax_diEgQJ;重大装备制造多机器人任务分配与运动规划技术研究综述 ;http://www.aas.net.cn/cn/article/doi/10.16383/j.aas.c220957
1108;OZ6CLzzMPyoJ;Bayesian Deep Multi-Agent Multimodal Reinforcement Learning for Embedded Systems in Games, Natural Language Processing and Robotics ;https://osf.io/sjrkh/download
1109;EzUQ4PhrAKUJ;GUT-AI Initiative ;https://files.osf.io/v1/resources/bxw4h/providers/osfstorage/64a2938067aff81183edf745?format=pdf&action=download&direct&version=3
1110;cneVzRJGinMJ;Improvements to Vanilla Implementation of Q-Learning Used in Path Planning of an Agent ;https://link.springer.com/chapter/10.1007/978-981-16-6616-2_24
1111;s6lSwBT15HoJ;A Comparison of Two Decoupled Methods for Simultaneous Multiple Robots Path Planning ;https://hal.science/hal-03954543/
1112;cHhUoK6WGtkJ;Multi-robot Multi-path Intelligent Planning Based on Universal Conflict Resolution and Free Crossing Emergence ;https://ieeexplore.ieee.org/abstract/document/9512768/
1113;34Za1gaB7W4J;Collaborative Robot Learning For Indoor Environment ;https://ieeexplore.ieee.org/abstract/document/10193717/
1114;Db8n_ziEg-sJ;Path Planning Method for Multi-robot Formation System Based on Hierarchical Reinforcement Learning ;https://link.springer.com/chapter/10.1007/978-981-19-6226-4_20
1115;JuFg3KTxIeUJ;DATA-EFFICIENT DEEP REINFORCEMENT LEARNING WITH CONVOLUTION-BASED STATE ENCODER NETWORKS ;https://www.actapress.com/PDFViewer.aspx?paperId=54826
1116;zMU5WnQPsRMJ;Path Planning using Deep Q-learning Network and Artificial Potential Fields for a Robot Formation ;http://dspace.library.uvic.ca/handle/1828/13891
1117;P6kQbIIgp_8J;Deep Reinforcement Learning for Intelligent Frontier Ranking in Search-and-rescue Scenarios ;https://digital.wpi.edu/downloads/fb494c631
1118;Bh347ZrEvsMJ;Multi-AGV pathfinding for automatic warehouse applications ;https://ieeexplore.ieee.org/abstract/document/9728597/
1119;i0ADs8EYoUIJ;" SAARTHI-A self-learning system for autonomous navigation using Symbolic Computing ;http://dr.ddn.upes.ac.in:8080/jspui/bitstream/123456789/3780/1/Niharika.pdf
1120;csfFSRJZpcgJ;防疫物资" 无接触" 机器人配送优化研究. ;https://search.ebscohost.com/login.aspx?direct=true&profile=ehost&scope=site&authtype=crawler&jrnl=10028331&AN=171947947&h=bz1HFlfJZOsF360tmNmWrQ5gO8FktvItxV%2B29Dq0QPv4yMp9N%2BnfgmJt9anSIDcbSNJl7Pa5dhK8ueQPV6stXg%3D%3D&crl=c
1121;-3S_zOV2AOEJ;Robot Navigation in Dynamic Environment Based on Reinforcement Learning ;http://essay.utwente.nl/85320/
1122;r-ZNJuS3XGsJ;Theoretical and Mathematical Concepts Formulation behind the Development of AI-ML Algorithms for Path Planning in Robots ;https://www.philstat.org/index.php/MSEA/article/view/1581
1123;rQJ_tM5Am1wJ;Path Planning Algorithm Development Using Configuration Space Obstacles and Equidistant Paths Using AI & ML ;http://philstat.org/index.php/MSEA/article/view/1580
1124;nCmfngsnS4cJ;An Optimized Self-Learning Algorithm for Autonomous Navigation in an Unknown Environment ;http://www.jgenng.com/wp-content/uploads/2020/09/volume10-issue7-04.pdf
1125;LXPq_VEqqA0J;MARBLER: An Open Platform for Standarized Evaluation of Multi-Robot Reinforcement Learning Algorithms Supplementary Material ;https://shubhlohiya.github.io/MARBLER/assets/supplementary.pdf
1126;ZL72Y7broOYJ;The Estimation and Control of Multi-agent Systems in Stochastic Spatiotemporal Environment ;https://search.proquest.com/openview/44c5bd096009d5d1e2a802104fb1331e/1?pq-origsite=gscholar&cbl=18750&diss=y
1127;uIIHDnE4xoEJ;Coverage control of agricultural fields using heterogeneous multi-robot systems ;https://search.proquest.com/openview/7bf2bfcbf50f272afb8bba0ab4b82c40/1?pq-origsite=gscholar&cbl=18750&diss=y
1128;ZgSUu-FdEccJ;Técnicas de aprendizaje por refuerzo para el problema de cobertura de áreas con robots aéreos ;https://oa.upm.es/id/eprint/71418
1129;r1MmYEldVFQJ;EARTHQUAKE GROUND MOTION MATCHING ON SHAKING TABLE USING REINFORCEMENT LEARNING CONTROLLER ;https://www.researchgate.net/profile/Nouredine-Bourahla/publication/344437464_EARTHQUAKE_GROUND_MOTION_MATCHING_ON_SHAKING_TABLE_USING_REINFORCEMENT_LEARNING_CONTROLLER/links/5f756427299bf1b53e035a9b/EARTHQUAKE-GROUND-MOTION-MATCHING-ON-SHAKING-TABLE-USING-REINFORCEMENT-LEARNING-CONTROLLER.pdf
1130;k9FccY0ZO2QJ;蚁群优化算法的无人机室内航迹规划 ;http://www.chinacaj.net/d/file/76-2022-02/567f0430039d12e4c3de506a02a5efc3.pdf
1131;5B8VbYdrtdwJ;УПРАВЛЕНИЕ МОБИЛЬНЫМ РОБОТОМ С ПРИМЕНЕНИЕМ НЕЙРОННОЙ СЕТИ ДЛЯ ПЛАНИРОВАНИЯ ДВИЖЕНИЯ В НЕКАРТОГРАФИРОВАННОЙ … ;https://cyberleninka.ru/article/n/upravlenie-mobilnym-robotom-s-primeneniem-neyronnoy-seti-dlya-planirovaniya-dvizheniya-v-nekartografirovannoy-srede-s
1132;mOJeBOO0HqsJ;Benchmarking von Verhaltens-Algorithmen für die Applikation in Motorsport-Szenarien ;https://tuprints.ulb.tu-darmstadt.de/20463/
1133;jOHLfh7YPjcJ;Arquitectura de software para navegación autónoma y coordinada de enjambres de drones en labores de lucha contra incendios forestales y urbanos ;https://e-archivo.uc3m.es/handle/10016/32463
1134;UEXf31cO4nQJ;Dynamic Analysis and Path Planning of a Turtle-Inspired Amphibious Spherical Robot. Micromachines 2022, 13, 2130 ;https://europepmc.org/article/pmc/pmc9784272
1135;fXT4VsBZzPgJ;АЛГОРИТМЫ СИСТЕМЫ УПРАВЛЕНИЯ ДВИЖЕНИЕМ МОБИЛЬНОГО РОБОТА ПРИМЕНЯЕТСЯ НЕЙРОННАЯ СЕТЬ В СРЕДЕ С … ;https://elibrary.ru/item.asp?id=49512892
1136;rA4Y04TkbQEJ;How to train your robot with deep reinforcement learning: lessons we have learned ;https://journals.sagepub.com/doi/abs/10.1177/0278364920987859
1137;QiNdf-e_jkMJ;Social physics ;https://www.sciencedirect.com/science/article/pii/S037015732100404X
1138;HfvCsUH5L58J;Deep reinforcement learning for autonomous driving: A survey ;https://ieeexplore.ieee.org/abstract/document/9351818/
1139;kH3A0qipx5IJ;Curl: Contrastive unsupervised representations for reinforcement learning ;http://proceedings.mlr.press/v119/laskin20a.html
1140;REsY-xYTIXgJ;Solving rubik's cube with a robot hand ;https://arxiv.org/abs/1910.07113
1141;qS7UVldJKZwJ;Outracing champion Gran Turismo drivers with deep reinforcement learning ;https://www.nature.com/articles/s41586-021-04357-7
1142;epKAknd7IpoJ;Image augmentation is all you need: Regularizing deep reinforcement learning from pixels ;https://openreview.net/forum?id=GY6-6sTvGaf
1143;WfoAW4QdOZcJ;Daydreamer: World models for physical robot learning ;https://proceedings.mlr.press/v205/wu23c.html
1144;cr9dy8WRaIcJ;Reinforcement learning with prototypical representations ;http://proceedings.mlr.press/v139/yarats21a.html
1145;bNdV4PVBP54J;Image augmentation is all you need: Regularizing deep reinforcement learning from pixels ;https://arxiv.org/abs/2004.13649
1146;vCDt1Chv78sJ;Deep learning, reinforcement learning, and world models ;https://www.sciencedirect.com/science/article/pii/S0893608022001150
1147;zCWnwF7qn4MJ;Stochastic latent actor-critic: Deep reinforcement learning with a latent variable model ;https://proceedings.neurips.cc/paper/2020/hash/08058bf500242562c0d031ff830ad094-Abstract.html
1148;MdyXqaJ5FLEJ;Accelerating reinforcement learning with learned skill priors ;https://proceedings.mlr.press/v155/pertsch21a.html
1149;kJKBrRGuQfMJ;Dynamics-aware unsupervised discovery of skills ;https://arxiv.org/abs/1907.01657
1150;uRGWy78iHVkJ;Mastering visual continuous control: Improved data-augmented reinforcement learning ;https://arxiv.org/abs/2107.09645
1151;CNbAgcBTt_cJ;Learning to walk via deep reinforcement learning ;https://arxiv.org/abs/1812.11103
1152;aaluOvD1-8MJ;Brax--A Differentiable Physics Engine for Large Scale Rigid Body Simulation ;https://arxiv.org/abs/2106.13281
1153;ccgXiVct85IJ;robosuite: A modular simulation framework and benchmark for robot learning ;https://arxiv.org/abs/2009.12293
1154;bL8f1cmU7SQJ;Battery thermal-and health-constrained energy management for hybrid electric bus based on soft actor-critic DRL algorithm ;https://ieeexplore.ieee.org/abstract/document/9160869/
1155;RNcOCuJuEh4J;Improving sample efficiency in model-free reinforcement learning from images ;https://ojs.aaai.org/index.php/AAAI/article/view/17276
1156;N3d0NnBApNAJ;Recovery rl: Safe reinforcement learning with learned recovery zones ;https://ieeexplore.ieee.org/abstract/document/9392290/
1157;N60CGTD-jesJ;Towards Self-X cognitive manufacturing network: An industrial knowledge graph-based multi-agent reinforcement learning approach ;https://www.sciencedirect.com/science/article/pii/S0278612521001643
1158;_So_NjYYD4YJ;Learning latent plans from play ;https://proceedings.mlr.press/v100/lynch20a.html
1159;QrWLJXB2NsQJ;Instruction-driven history-aware policies for robotic manipulations ;https://proceedings.mlr.press/v205/guhur23a.html
1160;k-VdTwcs0VQJ;Model-free deep reinforcement learning for urban autonomous driving ;https://ieeexplore.ieee.org/abstract/document/8917306/
1161;zC-Tk-r7j9AJ;Goal-conditioned reinforcement learning with imagined subgoals ;https://proceedings.mlr.press/v139/chane-sane21a
1162;AYydNKwyxTsJ;End-to-end robotic reinforcement learning without reward engineering ;https://arxiv.org/abs/1904.07854
1163;s9JDTiK26iYJ;What matters in on-policy reinforcement learning? a large-scale empirical study ;https://arxiv.org/abs/2006.05990
1164;6NwMR6JxVz0J;Interactive gibson benchmark: A benchmark for interactive navigation in cluttered environments ;https://ieeexplore.ieee.org/abstract/document/8954627/
1165;2bpoS9hoBuEJ;Soft actor-critic for discrete action settings ;https://arxiv.org/abs/1910.07207
1166;sDbsrRTdhHQJ;Interpretable end-to-end urban autonomous driving with latent deep reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/9346000/
1167;J7BmhiMy2ZUJ;A theory of regularized markov decision processes ;https://proceedings.mlr.press/v97/geist19a.html
1168;NqiiF2nRcTwJ;Skew-fit: State-covering self-supervised reinforcement learning ;https://arxiv.org/abs/1903.03698
1169;BYqPVwa8Q6EJ;The primacy bias in deep reinforcement learning ;https://proceedings.mlr.press/v162/nikishin22a.html
1170;ANAemb2O44UJ;Challenges of real-world reinforcement learning: definitions, benchmarks and analysis ;https://link.springer.com/article/10.1007/s10994-021-05961-4
1171;sZC2YqCu2JwJ;Reinforced neighborhood selection guided multi-relational graph neural networks ;https://dl.acm.org/doi/abs/10.1145/3490181
1172;4outWBn2XIEJ;Learning to manipulate deformable objects without demonstrations ;https://arxiv.org/abs/1910.13439
1173;4nunaZ8kwc8J;Randomized ensembled double q-learning: Learning fast without a model ;https://arxiv.org/abs/2101.05982
1174;4EE50gQUF8cJ;Global optimality guarantees for policy gradient methods ;https://arxiv.org/abs/1906.01786
1175;esImADUMVGEJ;Priority-aware task offloading in vehicular fog computing based on deep reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/9277911/
1176;EzS89Q8xnwsJ;Parrot: Data-driven behavioral priors for reinforcement learning ;https://arxiv.org/abs/2011.10024
1177;-sc7xxECuQ4J;Learning to be safe: Deep rl with a safety critic ;https://arxiv.org/abs/2010.14603
1178;tX3FFAWoXJUJ;Temporal difference learning for model predictive control ;https://arxiv.org/abs/2203.04955
1179;tHy7NkuUJVQJ;Maximum entropy rl (provably) solves some robust rl problems ;https://arxiv.org/abs/2103.06257
1180;716KOxoQjdsJ;Energy management strategies for fuel cell hybrid electric vehicles: Classification, comparison, and outlook ;https://www.sciencedirect.com/science/article/pii/S019689042200958X
1181;OtQMguzZd7wJ;Effective diversity in population based reinforcement learning ;https://proceedings.neurips.cc/paper/2020/hash/d1dc3a8270a6f9394f88847d7f0050cf-Abstract.html
1182;ckyauss1vtIJ;Deep reinforcement learning for predictive aircraft maintenance using probabilistic remaining-useful-life prognostics ;https://www.sciencedirect.com/science/article/pii/S0951832022005233
1183;xIhFxjQgap0J;What matters for on-policy deep actor-critic methods? a large-scale study ;https://openreview.net/forum?id=nIAxjsniDzg&
1184;f-sEoesTufIJ;Controlling overestimation bias with truncated mixture of continuous distributional quantile critics ;http://proceedings.mlr.press/v119/kuznetsov20a.html
1185;n2Dq5pZM01EJ;The ingredients of real-world robotic reinforcement learning ;https://arxiv.org/abs/2004.12570
1186;HYYuGoqBr_oJ;Learning to walk in the real world with minimal human effort ;https://arxiv.org/abs/2002.08550
1187;Ad9rWJj9iQcJ;A survey of deep RL and IL for autonomous driving policy learning ;https://ieeexplore.ieee.org/abstract/document/9660769/
1188;BCjbY5bK_QEJ;A game theoretic framework for model based reinforcement learning ;http://proceedings.mlr.press/v119/rajeswaran20a.html
1189;y8SlWrAtaeEJ;Training effective deep reinforcement learning agents for real-time life-cycle production optimization ;https://www.sciencedirect.com/science/article/pii/S0920410521013887
1190;XqSdUMm_TeQJ;Generalization in reinforcement learning by soft data augmentation ;https://ieeexplore.ieee.org/abstract/document/9561103/
1191;nEGW2wYbh88J;Better exploration with optimistic actor critic ;https://proceedings.neurips.cc/paper_files/paper/2019/hash/a34bacf839b923770b2c360eefa26748-Abstract.html
1192;LJ1TqJbf-CcJ;Experimental evaluation of model-free reinforcement learning algorithms for continuous HVAC control ;https://www.sciencedirect.com/science/article/pii/S0306261921005961
1193;1Tvrzc4hYN8J;Coordinated energy management for a cluster of buildings through deep reinforcement learning ;https://www.sciencedirect.com/science/article/pii/S0360544221009737
1194;-oj-f5rHhPMJ;WCSAC: Worst-case soft actor critic for safety-constrained reinforcement learning ;https://ojs.aaai.org/index.php/AAAI/article/view/17272
1195;OiqGoFRoeP4J;Chainerrl: A deep reinforcement learning library ;https://dl.acm.org/doi/abs/10.5555/3546258.3546335
1196;d3eXnNU7W1AJ;Simulation intelligence: Towards a new generation of scientific methods ;https://arxiv.org/abs/2112.03235
1197;_Q0nuaWSoRkJ;Toolflownet: Robotic manipulation with tools via predicting tool flow from point clouds ;https://proceedings.mlr.press/v205/seita23a.html
1198;AQhmZpqu8cQJ;Variable impedance control in end-effector space: An action space for reinforcement learning in contact-rich tasks ;https://ieeexplore.ieee.org/abstract/document/8968201/
1199;wUaffXKtTdEJ;RL/DRL meets vehicular task offloading using edge and vehicular cloudlet: A survey ;https://ieeexplore.ieee.org/abstract/document/9723463/
1200;jsCRdUYj5AwJ;Urban traffic control in software defined internet of things via a multi-agent deep reinforcement learning approach ;https://ieeexplore.ieee.org/abstract/document/9210820/
1201;NTmd3X5s038J;iGibson 1.0: A simulation environment for interactive tasks in large realistic scenes ;https://ieeexplore.ieee.org/abstract/document/9636667/
1202;X3RYQ_LoHTwJ;Recsim: A configurable simulation platform for recommender systems ;https://arxiv.org/abs/1909.04847
1203;0j0fdnGwfBQJ;Fop: Factorizing optimal joint policy of maximum-entropy multi-agent reinforcement learning ;https://proceedings.mlr.press/v139/zhang21m.html
1204;FT-iXm0smp0J;Deep reinforcement learning for continuous electric vehicles charging control with dynamic user behaviors ;https://ieeexplore.ieee.org/abstract/document/9493711/
1205;p9SpbQTbkUwJ;Cleanrl: High-quality single-file implementations of deep reinforcement learning algorithms ;https://dl.acm.org/doi/abs/10.5555/3586589.3586863
1206;cTSMYAu4ZmIJ;Safe reinforcement learning by imagining the near future ;https://proceedings.neurips.cc/paper/2021/hash/73b277c11266681122132d024f53a75b-Abstract.html
1207;gyudRUPA32QJ;Maniskill: Generalizable manipulation skill benchmark with large-scale demonstrations ;https://arxiv.org/abs/2107.14483
1208;ZnKjEfbdF9QJ;What matters for adversarial imitation learning? ;https://proceedings.neurips.cc/paper/2021/hash/7b647a7d88f4d6319bf0d600d168dbeb-Abstract.html
1209;LFOoA5mWN-kJ;Soft actor-critic–based multi-objective optimized energy conversion and management strategy for integrated energy systems with renewable energy ;https://www.sciencedirect.com/science/article/pii/S0196890421005574
1210;1UaV8XXAZDAJ;Distributional soft actor-critic: Off-policy reinforcement learning for addressing value estimation errors ;https://ieeexplore.ieee.org/abstract/document/9448360/
1211;39cpFKdftWMJ;A survey on masked autoencoder for self-supervised learning in vision and beyond ;https://arxiv.org/abs/2208.00173
1212;Xuxily4fJJAJ;Cog: Connecting new skills to past experience with offline reinforcement learning ;https://arxiv.org/abs/2010.14500
1213;psLdNfPzQHQJ;Hit and lead discovery with explorative rl and fragment-based molecule generation ;https://proceedings.neurips.cc/paper_files/paper/2021/hash/41da609c519d77b29be442f8c1105647-Abstract.html
1214;8vF22Raxk7YJ;Hierarchical reinforcement learning for air-to-air combat ;https://ieeexplore.ieee.org/abstract/document/9476700/
1215;nIsEHXNZiI4J;On the relationship between active inference and control as inference ;https://link.springer.com/chapter/10.1007/978-3-030-64919-7_1
1216;50Rx5pwpTU8J;Rloc: Terrain-aware legged locomotion using reinforcement learning and optimal control ;https://ieeexplore.ieee.org/abstract/document/9779429/
1217;UcOYlKxYQ6wJ;Learning from suboptimal demonstration via self-supervised reward regression ;https://proceedings.mlr.press/v155/chen21b.html
1218;FqEWxbqV8jEJ;Reset-free reinforcement learning via multi-task learning: Learning dexterous manipulation behaviors without human intervention ;https://ieeexplore.ieee.org/abstract/document/9561384/
1219;fL8ksvntlRAJ;Continual world: A robotic benchmark for continual reinforcement learning ;https://proceedings.neurips.cc/paper/2021/hash/ef8446f35513a8d6aa2308357a268a7e-Abstract.html
1220;IwYAPZlz9ogJ;An empirical investigation of the challenges of real-world reinforcement learning ;https://arxiv.org/abs/2003.11881
1221;xd0ZFQyWXpcJ;Predictive information accelerates learning in rl ;https://proceedings.neurips.cc/paper/2020/hash/89b9e0a6f6d1505fe13dea0f18a2dcfa-Abstract.html
1222;9jMqFOOu_ycJ;Rrl: Resnet as representation for reinforcement learning ;https://arxiv.org/abs/2107.03380
1223;KyvKgLSrNv4J;Recent advances in reinforcement learning in finance ;https://onlinelibrary.wiley.com/doi/abs/10.1111/mafi.12382
1224;MqywAw-UsxgJ;Primal wasserstein imitation learning ;https://arxiv.org/abs/2006.04678
1225;DBiJLhyUwgkJ;Discor: Corrective feedback in reinforcement learning via distribution correction ;https://proceedings.neurips.cc/paper/2020/hash/d7f426ccbc6db7e235c57958c21c5dfa-Abstract.html
1226;1YZ73yUacmMJ;Off-policy policy gradient with state distribution correction ;https://arxiv.org/abs/1904.08473
1227;7eMxJz8WxD0J;Understanding the complexity gains of single-task rl with a curriculum ;https://proceedings.mlr.press/v202/li23as.html
1228;ZH794KXUJO8J;Imitation learning via off-policy distribution matching ;https://arxiv.org/abs/1912.05032
1229;wc3FHYSzalUJ;Automatic curriculum learning through value disagreement ;https://proceedings.neurips.cc/paper/2020/hash/566f0ea4f6c2e947f36795c8f58ba901-Abstract.html
1230;aSZ4pEdg1UUJ;Safe reinforcement learning with stability guarantee for motion planning of autonomous vehicles ;https://ieeexplore.ieee.org/abstract/document/9478933/
1231;-R0m5-Ja5i8J;Towards human-level bimanual dexterous manipulation with reinforcement learning ;https://proceedings.neurips.cc/paper_files/paper/2022/hash/217a2a387f52c30755c37b0a73430291-Abstract-Datasets_and_Benchmarks.html
1232;8wM8ysJ1mgwJ;Xirl: Cross-embodiment inverse reinforcement learning ;https://proceedings.mlr.press/v164/zakka22a.html
1233;yQEawwb5MkoJ;Diagnosing bottlenecks in deep q-learning algorithms ;https://proceedings.mlr.press/v97/fu19a.html
1234;LnPtR3n1fsgJ;Coarse-to-fine q-attention: Efficient learning for visual robotic manipulation via discretisation ;http://openaccess.thecvf.com/content/CVPR2022/html/James_Coarse-To-Fine_Q-Attention_Efficient_Learning_for_Visual_Robotic_Manipulation_via_Discretisation_CVPR_2022_paper.html
1235;MxARzcrRsx4J;The path planning of mobile robot by neural networks and hierarchical reinforcement learning ;https://www.frontiersin.org/articles/10.3389/fnbot.2020.00063/full
1236;fWlEy5K0JBMJ;On the effectiveness of fine-tuning versus meta-reinforcement learning ;https://proceedings.neurips.cc/paper_files/paper/2022/hash/a951f595184aec1bb885ce165b47209a-Abstract-Conference.html
1237;kJiEkHX5PZMJ;From active learning to deep reinforcement learning: Intelligent active flow control in suppressing vortex-induced vibration ;https://pubs.aip.org/aip/pof/article/33/6/063607/1065626
1238;0XhO8JT-X90J;Offline meta-reinforcement learning with online self-supervision ;https://proceedings.mlr.press/v162/pong22a.html
1239;RTwC1LvDRgIJ;High robustness energy management strategy of hybrid electric vehicle based on improved soft actor-critic deep reinforcement learning ;https://www.sciencedirect.com/science/article/pii/S0360544222017091
1240;V0XscXbIFzwJ;Offline pre-trained multi-agent decision transformer: One big sequence model tackles all smac tasks ;https://arxiv.org/abs/2112.02845
1241;nThiR77Z_J0J;rlpyt: A research code base for deep reinforcement learning in pytorch ;https://arxiv.org/abs/1909.01500
1242;ZAx3BoPxHgcJ;d3rlpy: An offline deep reinforcement learning library ;https://dl.acm.org/doi/abs/10.5555/3586589.3586904
1243;yjdVn0ACx_sJ;Optimizing risk-based breast cancer screening policies with reinforcement learning ;https://www.nature.com/articles/s41591-021-01599-w
1244;RtOSanObFKgJ;Rewriting history with inverse rl: Hindsight inference for policy improvement ;https://proceedings.neurips.cc/paper/2020/hash/a97da629b098b75c294dffdc3e463904-Abstract.html
1245;SNdILgfS0voJ;Is bang-bang control all you need? solving continuous control with bernoulli policies ;https://proceedings.neurips.cc/paper_files/paper/2021/hash/e46be61f0050f9cc3a98d5d2192cb0eb-Abstract.html
1246;AEtxUFaI99YJ;Efficient deep reinforcement learning with imitative expert priors for autonomous driving ;https://ieeexplore.ieee.org/abstract/document/9694460/
1247;pr-JUzg8xDoJ;Two-stage deep reinforcement learning for inverter-based volt-var control in active distribution networks ;https://ieeexplore.ieee.org/abstract/document/9274529/
1248;ikjKEL8BdA0J;Continuous-discrete reinforcement learning for hybrid control in robotics ;http://proceedings.mlr.press/v100/neunert20a.html
1249;KaQbonQr1DgJ;Denoised mdps: Learning world models better than the world itself ;https://arxiv.org/abs/2206.15477
1250;fmbsntj42McJ;Learning barrier certificates: Towards safe reinforcement learning with zero training-time violations ;https://proceedings.neurips.cc/paper_files/paper/2021/hash/d71fa38b648d86602d14ac610f2e6194-Abstract.html
1251;Iu89axknarcJ;Soft actor-critic for navigation of mobile robots ;https://link.springer.com/article/10.1007/s10846-021-01367-5
1252;4Dp7r3WoHREJ;Online multi-agent reinforcement learning for decentralized inverter-based volt-var control ;https://ieeexplore.ieee.org/abstract/document/9356806/
1253;pjbTzgX8Y6wJ;A deep reinforcement learning-based multi-agent framework to enhance power system resilience using shunt resources ;https://ieeexplore.ieee.org/abstract/document/9427147/
1254;BEo6yGKo0OsJ;Q-attention: Enabling efficient learning for vision-based robotic manipulation ;https://ieeexplore.ieee.org/abstract/document/9672702/
1255;GxL8U1qWkdQJ;A soft actor-critic-based energy management strategy for electric vehicles with hybrid energy storage systems ;https://www.sciencedirect.com/science/article/pii/S0378775322001239
1256;E7dcPnLzUD0J;Robel: Robotics benchmarks for learning with low-cost robots ;https://proceedings.mlr.press/v100/ahn20a
1257;hccprQXckKYJ;Occupant-centered real-time control of indoor temperature using deep learning algorithms ;https://www.sciencedirect.com/science/article/pii/S0360132321010246
1258;4vpBhqP9wi0J;Deep reinforcement learning: A state-of-the-art walkthrough ;http://www.jair.org/index.php/jair/article/view/12412
1259;xDBwtiv_wmAJ;Why so pessimistic? estimating uncertainties for offline rl through ensembles, and why their independence matters ;https://proceedings.neurips.cc/paper_files/paper/2022/hash/7423902b5534e2b267438c85444a54b1-Abstract-Conference.html
1260;3br4n4jT0twJ;Disentangling transfer in continual reinforcement learning ;https://proceedings.neurips.cc/paper_files/paper/2022/hash/2938ad0434a6506b125d8adaff084a4a-Abstract-Conference.html
1261;HVdj8kwfiaQJ;Bail: Best-action imitation learning for batch deep reinforcement learning ;https://proceedings.neurips.cc/paper/2020/hash/d55cbf210f175f4a37916eafe6c04f0d-Abstract.html
1262;3HDGQUNj2kkJ;Reinforcement learning with videos: Combining offline observations with interaction ;https://arxiv.org/abs/2011.06507
1263;6z5CCfSOz-kJ;Model-augmented actor-critic: Backpropagating through paths ;https://arxiv.org/abs/2005.08068
1264;ZTg2oJgTX8gJ;Comparison of online and offline deep reinforcement learning with model predictive control for thermal energy management ;https://www.sciencedirect.com/science/article/pii/S0926580522000012
1265;n_BskROgZpwJ;Mural: Meta-learning uncertainty-aware rewards for outcome-driven reinforcement learning ;https://proceedings.mlr.press/v139/li21g.html
1266;BtwLfyauUgIJ;Towards robust bisimulation metric learning ;https://proceedings.neurips.cc/paper_files/paper/2021/hash/256bf8e6923a52fda8ddf7dc050a1148-Abstract.html
1267;NH-3fefUqtEJ;The problem with DDPG: understanding failures in deterministic environments with sparse rewards ;https://arxiv.org/abs/1911.11679
1268;0lDv21fk4WEJ;A self-tuning actor-critic algorithm ;https://proceedings.neurips.cc/paper/2020/hash/f02208a057804ee16ac72ff4d3cec53b-Abstract.html
1269;in0-UKENob4J;Learning to generalize from sparse and underspecified rewards ;https://proceedings.mlr.press/v97/agarwal19e.html
1270;hPa9Md_gsYUJ;A cooperative charging control strategy for electric vehicles based on multiagent deep reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/9716749/
1271;qtVcuql1kdYJ;Hierarchical skills for efficient exploration ;https://proceedings.neurips.cc/paper/2021/hash/60106888f8977b71e1f15db7bc9a88d1-Abstract.html
1272;xE_r2MY1Vz8J;Sim2real transfer for reinforcement learning without dynamics randomization ;https://ieeexplore.ieee.org/abstract/document/9341260/
1273;6n5vfmRFe84J;Residual pathway priors for soft equivariance constraints ;https://proceedings.neurips.cc/paper/2021/hash/fc394e9935fbd62c8aedc372464e1965-Abstract.html
1274;fiKOJrji-w4J;Hybrid rl: Using both offline and online data can make rl efficient ;https://arxiv.org/abs/2210.06718
1275;oJ3V76eZBFcJ;Supported policy optimization for offline reinforcement learning ;https://proceedings.neurips.cc/paper_files/paper/2022/hash/caa934a507a952698d54efb24845fc4b-Abstract-Conference.html
1276;lW-aKTc25koJ;An improved two-stage deep reinforcement learning approach for regulation service disaggregation in a virtual power plant ;https://ieeexplore.ieee.org/abstract/document/9744119/
1277;XStyZGJpR2oJ;Aw-opt: Learning robotic skills with imitation andreinforcement at scale ;https://proceedings.mlr.press/v164/lu22a.html
1278;5k1lQCYu7SUJ;Optimizing for the future in non-stationary mdps ;https://proceedings.mlr.press/v119/chandak20a.html
1279;LMC1ba-Z980J;Actor-critic reinforcement learning for control with stability guarantee ;https://ieeexplore.ieee.org/abstract/document/9146733/
1280;Iur7-t7_kRsJ;Guided reinforcement learning with learned skills ;https://arxiv.org/abs/2107.10253
1281;2kPmYDOcRYUJ;A brief overview of ChatGPT: The history, status quo and potential future development ;https://ieeexplore.ieee.org/abstract/document/10113601/
1282;9KksuVCl8aoJ;Grounding language in play ;https://www.academia.edu/download/93604914/2005.07648v1.pdf
1283;Io9ZWpVMGg0J;Leveraging deep reinforcement learning for traffic engineering: A survey ;https://ieeexplore.ieee.org/abstract/document/9507541/
1284;01_KlGeNzEwJ;Approximate convex decomposition for 3d meshes with collision-aware concavity and tree search ;https://dl.acm.org/doi/abs/10.1145/3528223.3530103
1285;vZhXD80NbKoJ;On the model-based stochastic value gradient for continuous reinforcement learning ;http://proceedings.mlr.press/v144/amos21a
1286;fjhaqTS8QDUJ;Orchestrating the development lifecycle of machine learning-based IoT applications: A taxonomy and survey ;https://dl.acm.org/doi/abs/10.1145/3398020
1287;auE1onywoSkJ;Generalized hindsight for reinforcement learning ;https://proceedings.neurips.cc/paper/2020/hash/57e5cb96e22546001f1d6520ff11d9ba-Abstract.html
1288;1Ados76bNgsJ;Reinforcement learning control of constrained dynamic systems with uniformly ultimate boundedness stability guarantee ;https://www.sciencedirect.com/science/article/pii/S0005109821002090
1289;_YSoGSOSFpgJ;Does self-supervised learning really improve reinforcement learning from pixels? ;https://proceedings.neurips.cc/paper_files/paper/2022/hash/c75abb33341363ee874a71f81dc45a3a-Abstract-Conference.html
1290;-9eG2c4_eA8J;Deep reinforcement learning and adaptive policy transfer for generalizable well control optimization ;https://www.sciencedirect.com/science/article/pii/S0920410522007240
1291;7kqw-qznClEJ;Tactile sim-to-real policy transfer via real-to-sim image translation ;https://proceedings.mlr.press/v164/church22a.html
1292;8HItpuuiFbgJ;A survey of domain-specific architectures for reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/9694573/
1293;NxiutN1REmUJ;Deep multiagent reinforcement learning: Challenges and directions ;https://link.springer.com/article/10.1007/s10462-022-10299-x
1294;cYMvrVl_gV4J;Naturalistic data-driven and emission reduction-conscious energy management for hybrid electric vehicle based on improved soft actor-critic algorithm ;https://www.sciencedirect.com/science/article/pii/S037877532300023X
1295;D0IqRtYdtlwJ;VER: Scaling On-Policy RL Leads to the Emergence of Navigation in Embodied Rearrangement ;https://proceedings.neurips.cc/paper_files/paper/2022/hash/32d2cf79062126dc032ca4235068f52e-Abstract-Conference.html
1296;WipnVWzOJg4J;RIS-aided ground-aerial NOMA communications: A distributionally robust DRL approach ;https://ieeexplore.ieee.org/abstract/document/9681874/
1297;q5nPgr49mgcJ;Honor of kings arena: an environment for generalization in competitive reinforcement learning ;https://proceedings.neurips.cc/paper_files/paper/2022/hash/4dbb61cb68671edc4ca3712d70083b9f-Abstract-Datasets_and_Benchmarks.html
1298;qJayiS-dyzoJ;Offline model-based adaptable policy learning ;https://proceedings.neurips.cc/paper/2021/hash/470e7a4f017a5476afb7eeb3f8b96f9b-Abstract.html
1299;t0S7mqGMIbgJ;Optimal policy characterization enhanced actor-critic approach for electric vehicle charging scheduling in a power distribution network ;https://ieeexplore.ieee.org/abstract/document/9211734/
1300;jXM9WW1DKx8J;Efficient hyperparameter optimization through model-based reinforcement learning ;https://www.sciencedirect.com/science/article/pii/S0925231220310523
1301;WwfUbCbuLdQJ;Inverse reinforcement learning without reinforcement learning ;https://proceedings.mlr.press/v202/swamy23a.html
1302;_WVTFC6j9nwJ;Deep reinforcement learning-based joint task and energy offloading in UAV-aided 6G intelligent edge networks ;https://www.sciencedirect.com/science/article/pii/S0140366422002195
1303;-YeEBrVmD8YJ;Augmented world models facilitate zero-shot dynamics generalization from a single offline environment ;http://proceedings.mlr.press/v139/ball21a.html
1304;QCuIIJcnFbIJ;Cal-ql: Calibrated offline rl pre-training for efficient online fine-tuning ;https://arxiv.org/abs/2303.05479
1305;dE-ngnv_zwQJ;Policy gradient and actor-critic learning in continuous time and space: Theory and algorithms ;https://dl.acm.org/doi/abs/10.5555/3586589.3586864
1306;kxeJcH4wHt4J;Iso-dream: Isolating and leveraging noncontrollable visual dynamics in world models ;https://proceedings.neurips.cc/paper_files/paper/2022/hash/9316769afaaeeaad42a9e3633b14e801-Abstract-Conference.html
1307;hzj3HQL5mQ4J;Simultaneously transmitting and reflecting reconfigurable intelligent surface (STAR-RIS) assisted UAV communications ;https://ieeexplore.ieee.org/abstract/document/9849460/
1308;3KMqXdj5G2kJ;An equivalence between loss functions and non-uniform sampling in experience replay ;https://proceedings.neurips.cc/paper/2020/hash/a3bf6e4db673b6449c2f7d13ee6ec9c0-Abstract.html
1309;G3Ysht8GB34J;DRL-based V2V computation offloading for blockchain-enabled vehicular networks ;https://ieeexplore.ieee.org/abstract/document/9720111/
1310;OHcBXiDRY3AJ;Identifying optimal cycles in quantum thermal machines with reinforcement-learning ;https://www.nature.com/articles/s41534-021-00512-0
1311;rzenMRa8BIoJ;Robot navigation in constrained pedestrian environments using reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/9560893/
1312;kuJwdSYoujcJ;Appl: Adaptive planner parameter learning ;https://www.sciencedirect.com/science/article/pii/S0921889022000744
1313;bRyNb8f8kucJ;Deep reinforcement learning based optimization for a tightly coupled nuclear renewable integrated energy system ;https://www.sciencedirect.com/science/article/pii/S0306261922013708
1314;IuPjnOTZz_AJ;A closer look at offline rl agents ;https://proceedings.neurips.cc/paper_files/paper/2022/hash/3908cadfcc99db12001eafb1207353e9-Abstract-Conference.html
1315;56HqbnYW2uQJ;Recurrent model-free rl can be a strong baseline for many pomdps ;https://arxiv.org/abs/2110.05038
1316;vJA6obpRlacJ;Dsac: Distributional soft actor critic for risk-sensitive reinforcement learning ;https://arxiv.org/abs/2004.14547
1317;YJfoXLWizEgJ;Learning General World Models in a Handful of Reward-Free Deployments ;https://proceedings.neurips.cc/paper_files/paper/2022/hash/ab6a2c6ee757afe43882121281f6065c-Abstract-Conference.html
1318;eRwg1Wr7WfUJ;Discovered policy optimisation ;https://proceedings.neurips.cc/paper_files/paper/2022/hash/688c7a82e31653e7c256c6c29fd3b438-Abstract-Conference.html
1319;Po-kDyD43GMJ;Towards real-time reinforcement learning control of a wave energy converter ;https://www.mdpi.com/2077-1312/8/11/845
1320;P1ATVJtkE_QJ;Learning high-DOF reaching-and-grasping via dynamic representation of gripper-object interaction ;https://arxiv.org/abs/2204.13998
1321;r1L8U8B3z1UJ;Synthesizing the optimal gait of a quadruped robot with soft actuators using deep reinforcement learning ;https://www.sciencedirect.com/science/article/pii/S0736584522000692
1322;FtVWg8TI5YMJ;Nearly minimax optimal offline reinforcement learning with linear function approximation: Single-agent mdp and markov game ;https://arxiv.org/abs/2205.15512
1323;kMGHN8hS4QIJ;Dropout q-functions for doubly efficient reinforcement learning ;https://arxiv.org/abs/2110.02034
1324;EbbkPIw4kbEJ;Simnet: Enabling robust unknown object manipulation from pure synthetic data via stereo ;https://proceedings.mlr.press/v164/kollar22a.html
1325;U7o-O1tqqSIJ;A context-based meta-reinforcement learning approach to efficient hyperparameter optimization ;https://www.sciencedirect.com/science/article/pii/S0925231221019421
1326;8kOkR137JbkJ;Laser: Learning a latent action space for efficient reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/9561232/
1327;QDeCJ_0uyekJ;Deep reinforcement scheduling of energy storage systems for real-time voltage regulation in unbalanced LV networks with high PV penetration ;https://ieeexplore.ieee.org/abstract/document/9466427/
1328;R_LzTIqMYhEJ;Spectral decomposition representation for reinforcement learning ;https://arxiv.org/abs/2208.09515
1329;3wDg628Yym0J;Improved deep reinforcement learning with expert demonstrations for urban autonomous driving ;https://ieeexplore.ieee.org/abstract/document/9827073/
1330;gUMMeHA2PjMJ;Cem: Constrained entropy maximization for task-agnostic safe exploration ;https://ojs.aaai.org/index.php/AAAI/article/view/26281
1331;dAHNPWFDKgIJ;Investigating the role of model-based learning in exploration and transfer ;https://proceedings.mlr.press/v202/walker23a.html
1332;tryutrZCCLcJ;Online transfer learning strategy for enhancing the scalability and deployment of deep reinforcement learning control in smart buildings ;https://www.sciencedirect.com/science/article/pii/S0306261922018554
1333;ZiG82fqMJ80J;Sparse graphical memory for robust planning ;https://proceedings.neurips.cc/paper/2020/hash/385822e359afa26d52b5b286226f2cea-Abstract.html
1334;Zd3bAFpANFAJ;Real-world challenges for multi-agent reinforcement learning in grid-interactive buildings ;https://www.sciencedirect.com/science/article/pii/S2666546822000489
1335;SjryH06q8YsJ;Deep reinforcement learning based moving object grasping ;https://www.sciencedirect.com/science/article/pii/S0020025521001158
1336;dJG4JmbE6RUJ;Roma: Robust model adaptation for offline model-based optimization ;https://proceedings.neurips.cc/paper_files/paper/2021/hash/24b43fb034a10d78bec71274033b4096-Abstract.html
1337;YOTzz8dp1NAJ;Deep reinforcement learning for closed-loop blood glucose control ;http://proceedings.mlr.press/v126/fox20a.html
1338;2_EhepaBxb0J;Health-considered energy management strategy for fuel cell hybrid electric vehicle based on improved soft actor critic algorithm adopted with Beta policy ;https://www.sciencedirect.com/science/article/pii/S0196890423007082
1339;6VS5GzknN9MJ;Ready policy one: World building through active learning ;https://proceedings.mlr.press/v119/ball20a.html
1340;SppRRZiLYJMJ;Variational recurrent models for solving partially observable control tasks ;https://arxiv.org/abs/1912.10703
1341;f88V5noyLgQJ;Deconstructing the inductive biases of hamiltonian neural networks ;https://arxiv.org/abs/2202.04836
1342;dlXOT4poTIwJ;Stap: Sequencing task-agnostic policies ;https://ieeexplore.ieee.org/abstract/document/10160220/
1343;uIfnM2SychYJ;A dynamic internal trading price strategy for networked microgrids: a deep reinforcement learning-based game-theoretic approach ;https://ieeexplore.ieee.org/abstract/document/9760514/
1344;TLEsYfkhFQkJ;Model-reference reinforcement learning for collision-free tracking control of autonomous surface vehicles ;https://ieeexplore.ieee.org/abstract/document/9454561/
1345;wn74WJgBvEsJ;A Dual Representation Framework for Robot Learning with Human Guidance ;https://proceedings.mlr.press/v205/zhang23a.html
1346;I4gLUzN_mTMJ;Smooth exploration for robotic reinforcement learning ;https://proceedings.mlr.press/v164/raffin22a.html
1347;NL22mq8LIzUJ;Reinforcement learning control of a biomechanical model of the upper extremity ;https://www.nature.com/articles/s41598-021-93760-1
1348;orPRstdiNuAJ;Why should i trust you, bellman? the bellman error is a poor replacement for value error ;https://arxiv.org/abs/2201.12417
1349;4aUrOogz1OsJ;Pods: Policy optimization via differentiable simulation ;http://proceedings.mlr.press/v139/mora21a.html
1350;TQVzTARlmV8J;Efficient resource allocation for multi-beam satellite-terrestrial vehicular networks: A multi-agent actor-critic method with attention mechanism ;https://ieeexplore.ieee.org/abstract/document/9641753/
1351;jEEZ_aGDRI0J;Design-bench: Benchmarks for data-driven offline model-based optimization ;https://proceedings.mlr.press/v162/trabucco22a.html
1352;oeezbGjfBBoJ;Relmogen: Leveraging motion generation in reinforcement learning for mobile manipulation ;https://arxiv.org/abs/2008.07792
1353;x_kSGgWIjBEJ;Deep reinforcement learning for navigation in aaa video games ;https://arxiv.org/abs/2011.04764
1354;C4C1QkIIEvsJ;Shape control of deformable linear objects with offline and online learning of local linear deformation models ;https://ieeexplore.ieee.org/abstract/document/9812244/
1355;bSDMHVZZ3lgJ;Model predictive actor-critic: Accelerating robot skill acquisition with deep reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/9561298/
1356;DZrfh6GX2EgJ;Real-time reinforcement learning ;https://proceedings.neurips.cc/paper/2019/hash/54e36c5ff5f6a1802925ca009f3ebb68-Abstract.html
1357;0vxyhHOYrfoJ;A predictive and adaptive control strategy to optimize the management of integrated energy systems in buildings ;https://www.sciencedirect.com/science/article/pii/S2352484721014979
1358;-KRTyWHor94J;Energy management strategy via maximum entropy reinforcement learning for an extended range logistics vehicle ;https://www.sciencedirect.com/science/article/pii/S0360544222010088
1359;1NyKghwDzQAJ;Safety-constrained reinforcement learning with a distributional safety critic ;https://link.springer.com/article/10.1007/s10994-022-06187-8
1360;JhWjDZKBweYJ;Reinforcement Learning Methods for Computation Offloading: A Systematic Review ;https://dl.acm.org/doi/abs/10.1145/3603703
1361;EET-hJxyViIJ;Unsupervised skill discovery with bottleneck option learning ;https://arxiv.org/abs/2106.14305
1362;WIPwMTBAmNAJ;Efficient continuous control with double actors and regularized critics ;https://ojs.aaai.org/index.php/AAAI/article/view/20732
1363;Ot8FlORmWK8J;Same state, different task: Continual reinforcement learning without interference ;https://ojs.aaai.org/index.php/AAAI/article/view/20674
1364;zeoZhH1XLGoJ;A review of uncertainty for deep reinforcement learning ;https://ojs.aaai.org/index.php/AIIDE/article/view/21959
1365;veb35vzrtBsJ;Drive: Deep reinforced accident anticipation with visual explanation ;http://openaccess.thecvf.com/content/ICCV2021/html/Bao_DRIVE_Deep_Reinforced_Accident_Anticipation_With_Visual_Explanation_ICCV_2021_paper.html
1366;mI_T5cjM6SYJ;Pi-ars: Accelerating evolution-learned visual-locomotion with predictive information representations ;https://ieeexplore.ieee.org/abstract/document/9981952/
1367;-JOzBZRzfooJ;Learning reward functions for robotic manipulation by observing humans ;https://ieeexplore.ieee.org/abstract/document/10161178/
1368;3aAOif1sEH8J;Relmogen: Integrating motion generation in reinforcement learning for mobile manipulation ;https://ieeexplore.ieee.org/abstract/document/9561315/
1369;lfhD9pY1-VgJ;PPO-CMA: Proximal policy optimization with covariance matrix adaptation ;https://ieeexplore.ieee.org/abstract/document/9231618/
1370;irJ6Vuv4m4cJ;Autonomous reinforcement learning: Formalism and benchmarking ;https://arxiv.org/abs/2112.09605
1371;2lI6UfT5dSkJ;Control-oriented model-based reinforcement learning with implicit differentiation ;https://ojs.aaai.org/index.php/AAAI/article/view/20758
1372;4rCiathnAxQJ;Emergent real-world robotic skills via unsupervised off-policy reinforcement learning ;https://arxiv.org/abs/2004.12974
1373;N1jzbh4VGj4J;Apple: Adaptive planner parameter learning from evaluative feedback ;https://ieeexplore.ieee.org/abstract/document/9502545/
1374;aRR_FJQVZf0J;Online implementation of a soft actor-critic agent to enhance indoor temperature control and energy efficiency in buildings ;https://www.mdpi.com/1996-1073/14/4/997
1375;i6r-Ve8jR-IJ;Deep reinforcement learning-based optimization for irs-assisted cognitive radio systems ;https://ieeexplore.ieee.org/abstract/document/9766179/
1376;R3QJHKSwmn0J;Reinforcement learning for automatic quadrilateral mesh generation: A soft actor–critic approach ;https://www.sciencedirect.com/science/article/pii/S089360802200418X
1377;2iERjsYHPUwJ;Imagined value gradients: Model-based policy optimization with tranferable latent dynamics models ;http://proceedings.mlr.press/v100/byravan20a.html
1378;nTHjQNX4tYIJ;Discrete and continuous action representation for practical rl in video games ;https://arxiv.org/abs/1912.11077
1379;80ZhDqKsGakJ;Caching transient content for IoT sensing: Multi-agent soft actor-critic ;https://ieeexplore.ieee.org/abstract/document/9446746/
1380;Z48j36hxQYcJ;Mat: Multi-fingered adaptive tactile grasping via deep reinforcement learning ;https://arxiv.org/abs/1909.04787
1381;8dRV9ReKFq4J;Pareto-optimal cycles for power, efficiency and fluctuations of quantum heat engines using reinforcement learning ;https://journals.aps.org/prresearch/abstract/10.1103/PhysRevResearch.5.L022017
1382;EADw4cHr_LcJ;Combining evolution and deep reinforcement learning for policy search: a survey ;https://dl.acm.org/doi/abs/10.1145/3569096
1383;GYOyQ6KJQDIJ;Finite sample analysis of two-time-scale natural actor-critic algorithm ;https://ieeexplore.ieee.org/abstract/document/9827586/
1384;Hazwug1k_woJ;Cross-domain imitation learning via optimal transport ;https://arxiv.org/abs/2110.03684
1385;1jcLa6btxHMJ;Skill generalization of tubular object manipulation with tactile sensing and Sim2Real learning ;https://www.sciencedirect.com/science/article/pii/S092188902200210X
1386;iavbOYamFf4J;Learning to navigate sidewalks in outdoor environments ;https://ieeexplore.ieee.org/abstract/document/9691818/
1387;kHfbVrKLGT4J;High-accuracy model-based reinforcement learning, a survey ;https://link.springer.com/article/10.1007/s10462-022-10335-w
1388;kpd2u6mFtiMJ;A proactive 2-stage indoor CO2-based demand-controlled ventilation method considering control performance and energy efficiency ;https://www.sciencedirect.com/science/article/pii/S0306261922015458
1389;brN2qkGfdjgJ;Efficientgrasp: A unified data-efficient learning to grasp method for multi-fingered robot hands ;https://ieeexplore.ieee.org/abstract/document/9813387/
1390;BqDeewUtce0J;Towards the next generation of machine learning models in additive manufacturing: A review of process dependent material evolution ;https://www.sciencedirect.com/science/article/pii/S0079642523000348
1391;kEfaFF0o2sQJ;A review of deep reinforcement learning approaches for smart manufacturing in industry 4.0 and 5.0 framework ;https://www.mdpi.com/2076-3417/12/23/12377
1392;cJRbhOjDE8UJ;Diversity policy gradient for sample efficient quality-diversity optimization ;https://dl.acm.org/doi/abs/10.1145/3512290.3528845
1393;845d9Ht6EiUJ;Flowsheet synthesis through hierarchical reinforcement learning and graph neural networks ;https://arxiv.org/abs/2207.12051
1394;zFsQPcehNfkJ;Exploring the potentialities of deep reinforcement learning for incentive-based demand response in a cluster of small commercial buildings ;https://www.mdpi.com/1996-1073/14/10/2933
1395;4GYncMbkmxkJ;A provably-efficient model-free algorithm for infinite-horizon average-reward constrained Markov decision processes ;https://ojs.aaai.org/index.php/AAAI/article/view/20302
1396;zbFdR5xV8nMJ;Dynamics-aware embeddings ;https://arxiv.org/abs/1908.09357
1397;6ZILYU2lSsMJ;Multi-agent reinforcement learning dealing with hybrid action spaces: A case study for off-grid oriented renewable building energy system ;https://www.sciencedirect.com/science/article/pii/S0306261922012788
1398;GOAWBFtRqu8J;Reinforcement learning with automated auxiliary loss search ;https://proceedings.neurips.cc/paper_files/paper/2022/hash/0be44cc1d459731928501cae5699f57a-Abstract-Conference.html
1399;9yYBy26NgFQJ;A general motion control architecture for an autonomous underwater vehicle with actuator faults and unknown disturbances through deep reinforcement … ;https://www.sciencedirect.com/science/article/pii/S0029801822017103
1400;QUa3nTbBYuwJ;Towards tractable optimism in model-based reinforcement learning ;https://proceedings.mlr.press/v161/pacchiano21a.html
1401;GqwwDAlOK70J;RIS-assisted UAV for fresh data collection in 3d urban environments: A deep reinforcement learning approach ;https://ieeexplore.ieee.org/abstract/document/9870566/
1402;tN7dQHuAjFIJ;Characterizing the gap between actor-critic and policy gradient ;https://proceedings.mlr.press/v139/wen21b.html
1403;9HKAFHT5x0UJ;Model-based multi-agent policy optimization with adaptive opponent-wise rollouts ;https://arxiv.org/abs/2105.03363
1404;x_1uG5wtedgJ;A reinforcement learning approach to home energy management for modulating heat pumps and photovoltaic systems ;https://www.sciencedirect.com/science/article/pii/S0306261922012776
1405;kl6QWaeRDkMJ;Policy information capacity: Information-theoretic measure for task complexity in deep reinforcement learning ;https://proceedings.mlr.press/v139/furuta21a.html
1406;IvsPZs8xE-kJ;Modeling human exploration through resource-rational reinforcement learning ;https://proceedings.neurips.cc/paper_files/paper/2022/hash/cde542f47c67907e170a1e1a7b32f6ad-Abstract-Conference.html
1407;3dLy9-A9ssIJ;Velocity control in car-following behavior with autonomous vehicles using reinforcement learning ;https://www.sciencedirect.com/science/article/pii/S0001457522001658
1408;x-HuZR8vo58J;Distributionally robust reinforcement learning ;https://arxiv.org/abs/1902.08708
1409;NHqbAD_YcLMJ;Direct behavior specification via constrained reinforcement learning ;https://arxiv.org/abs/2112.12228
1410;gIwMclL9yuAJ;A general motion controller based on deep reinforcement learning for an autonomous underwater vehicle with unknown disturbances ;https://www.sciencedirect.com/science/article/pii/S0952197622005796
1411;-pejHeOVAMwJ;Dynamic sparse training for deep reinforcement learning ;https://arxiv.org/abs/2106.04217
1412;wBqb5uieLzcJ;A hierarchical coordination framework for joint perception-action tasks in composite robot teams ;https://ieeexplore.ieee.org/abstract/document/9501958/
1413;E2X9T2W_VYkJ;Deep reinforcement learning based active pantograph control strategy in high-speed railway ;https://ieeexplore.ieee.org/abstract/document/9882390/
1414;mVcHU40728kJ;Tutorial on amortized optimization ;https://www.nowpublishers.com/article/Details/MAL-102
1415;qmUH_0kIOLoJ;Energy management strategy for fuel cell vehicles via soft actor-critic-based deep reinforcement learning considering powertrain thermal and durability … ;https://www.sciencedirect.com/science/article/pii/S0196890423002674
1416;Ak-cZ5b-_WEJ;Thinking while moving: Deep reinforcement learning with concurrent control ;https://arxiv.org/abs/2004.06089
1417;b4RRpr2eiI8J;Doorgym: A scalable door opening environment and baseline agent ;https://arxiv.org/abs/1908.01887
1418;jIctoSjQ1yAJ;Hallucinative topological memory for zero-shot visual planning ;http://proceedings.mlr.press/v119/liu20h.html
1419;LUvZA7gRcR0J;Fast lifelong adaptive inverse reinforcement learning from demonstrations ;https://proceedings.mlr.press/v205/chen23e.html
1420;7jZUi8K1uOYJ;How to spend your robot time: Bridging kickstarting and offline reinforcement learning for vision-based robotic manipulation ;https://ieeexplore.ieee.org/abstract/document/9981126/
1421;4oy8wR0BrzAJ;Compact Learning Model for Dynamic Off-Chain Routing in Blockchain-Based IoT ;https://ieeexplore.ieee.org/abstract/document/9918035/
1422;slxw3Cl5XCUJ;Evolving rewards to automate reinforcement learning ;https://arxiv.org/abs/1905.07628
1423;VOvGHXT7NIoJ;Multi-agent DRL-based lane change with right-of-way collaboration awareness ;https://ieeexplore.ieee.org/abstract/document/9932003/
1424;2ekPPpkA5kAJ;On multi-event co-calibration of dynamic model parameters using soft actor-critic ;https://ieeexplore.ieee.org/abstract/document/9220820/
1425;ks9PRvo1bk8J;Unsupervised visual attention and invariance for reinforcement learning ;http://openaccess.thecvf.com/content/CVPR2021/html/Wang_Unsupervised_Visual_Attention_and_Invariance_for_Reinforcement_Learning_CVPR_2021_paper.html
1426;pIY7ZCe_2T0J;A survey on quantum reinforcement learning ;https://arxiv.org/abs/2211.03464
1427;CGxQ9KMF2CUJ;Model-based reinforcement learning via latent-space collocation ;https://proceedings.mlr.press/v139/rybkin21b.html
1428;qY_UprgrC74J;Reinforcement learning with random delays ;https://openreview.net/forum?id=QFYnKlBJYR
1429;TbLa73c8mykJ;Actor–critic reinforcement learning and application in developing computer-vision-based interface tracking ;https://www.sciencedirect.com/science/article/pii/S209580992100326X
1430;nGNNPG0gNdUJ;Learning generalizable locomotion skills with hierarchical reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/9196642/
1431;suhjhRr8YzAJ;Leveraging fully observable policies for learning under partial observability ;https://arxiv.org/abs/2211.01991
1432;fxj32aDJy8sJ;Unsupervised visuomotor control through distributional planning networks ;https://arxiv.org/abs/1902.05542
1433;MdddYWEhN4IJ;Inverse reinforcement learning with natural language goals ;https://ojs.aaai.org/index.php/AAAI/article/view/17326
1434;MWpeCln5FGAJ;Scalable multi-task imitation learning with autonomous improvement ;https://ieeexplore.ieee.org/abstract/document/9197020/
1435;vdKihQ0M4CoJ;Learning to simulate and design for structural engineering ;http://proceedings.mlr.press/v119/chang20a.html
1436;zR4PK7fD4-UJ;Feasibility constrained online calculation for real-time optimal power flow: A convex constrained deep reinforcement learning approach ;https://ieeexplore.ieee.org/abstract/document/9944164/
1437;QnKXZJqKSE4J;Dexterous manipulation from images: Autonomous real-world rl via substep guidance ;https://ieeexplore.ieee.org/abstract/document/10161493/
1438;J4awubpm-5sJ;Dynamic task allocation and service migration in edge-cloud iot system based on deep reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/9748866/
1439;GIw88s4VeqsJ;Smart magnetic microrobots learn to swim with deep reinforcement learning ;https://onlinelibrary.wiley.com/doi/abs/10.1002/aisy.202200023
1440;C_PX55V9zRcJ;Fast population-based reinforcement learning on a single machine ;https://proceedings.mlr.press/v162/flajolet22a.html
1441;zkaDlBZFs5kJ;A reinforcement learning approach to long-horizon operations, health, and maintenance supervisory control of advanced energy systems ;https://www.sciencedirect.com/science/article/pii/S0952197622004444
1442;Fre1nvHUFJkJ;Mask-based latent reconstruction for reinforcement learning ;https://proceedings.neurips.cc/paper_files/paper/2022/hash/a0709efe5139939ab69902884ecad9c1-Abstract-Conference.html
1443;8U5eVP2X4YwJ;Online reinforcement learning for the shape morphing adaptive control of 4D printed shape memory polymer ;https://www.sciencedirect.com/science/article/pii/S096706612200123X
1444;5TXhgMktRL4J;Playvirtual: Augmenting cycle-consistent virtual trajectories for reinforcement learning ;https://proceedings.neurips.cc/paper_files/paper/2021/hash/2a38a4a9316c49e5a833517c45d31070-Abstract.html
1445;BCPjq4nvIJYJ;Using deep reinforcement learning with automatic curriculum learning for mapless navigation in intralogistics ;https://www.mdpi.com/2076-3417/12/6/3153
1446;L0pSj_gVyFQJ;A multiagent federated reinforcement learning approach for plug-in electric vehicle fleet charging coordination in a residential community ;https://ieeexplore.ieee.org/abstract/document/9889708/
1447;KOTMwA4x5pUJ;A hierarchical deep reinforcement learning-based community energy trading scheme for a neighborhood of smart households ;https://ieeexplore.ieee.org/abstract/document/9790854/
1448;aEtuJKsV78AJ;On transforming reinforcement learning by transformer: The development trajectory ;https://arxiv.org/abs/2212.14164
1449;sRQ1DPEC8gwJ;HOI4D: A 4D egocentric dataset for category-level human-object interaction ;http://openaccess.thecvf.com/content/CVPR2022/html/Liu_HOI4D_A_4D_Egocentric_Dataset_for_Category-Level_Human-Object_Interaction_CVPR_2022_paper.html
1450;Hufzc0Ss0loJ;Recurrent model-free rl is a strong baseline for many pomdps ;https://openreview.net/forum?id=E0zOKxQsZhN
1451;8sHZALPxCWUJ;Mastering arterial traffic signal control with multi-agent attention-based soft actor-critic model ;https://ieeexplore.ieee.org/abstract/document/9994639/
1452;r7nbVjoGW-EJ;Guidance and control of autonomous surface underwater vehicles for target tracking in ocean environment by deep reinforcement learning ;https://www.sciencedirect.com/science/article/pii/S002980182200378X
1453;VrR-gRA-akgJ;Dara: Dynamics-aware reward augmentation in offline reinforcement learning ;https://arxiv.org/abs/2203.06662
1454;VdLe1zbGm-gJ;Learn to navigate autonomously through deep reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/9430693/
1455;-62_9mJFyfcJ;A comparison of action spaces for learning manipulation tasks ;https://ieeexplore.ieee.org/abstract/document/8967946/
1456;46zc9J3kqnoJ;Deep-Reinforcement-Learning-Based Resource Allocation for Cloud Gaming via Edge Computing ;https://ieeexplore.ieee.org/abstract/document/9953046/
1457;vF79EAeHhdcJ;Bayesian controller fusion: Leveraging control priors in deep reinforcement learning for robotics ;https://journals.sagepub.com/doi/abs/10.1177/02783649231167210
1458;ccNzJBYOnFsJ;Dualafford: Learning collaborative visual affordance for dual-gripper object manipulation ;https://arxiv.org/abs/2207.01971
1459;u8sxECTVj08J;Reducing variance in temporal-difference value estimation via ensemble of deep networks ;https://proceedings.mlr.press/v162/liang22c.html
1460;K8DIojuBkFEJ;Iterative amortized policy optimization ;https://proceedings.neurips.cc/paper_files/paper/2021/hash/83fa5a432ae55c253d0e60dbfa716723-Abstract.html
1461;tDpeaItFUtwJ;Real-time model calibration with deep reinforcement learning ;https://www.sciencedirect.com/science/article/pii/S0888327021006506
1462;PkT8GOgfuyoJ;A decentralized policy gradient approach to multi-task reinforcement learning ;https://proceedings.mlr.press/v161/zeng21a.html
1463;Gqxl6RlWApAJ;Dynamic pricing based electric vehicle charging station location strategy using reinforcement learning ;https://www.sciencedirect.com/science/article/pii/S036054422301678X
1464;mYimKMNZwOsJ;Benchmarking structured policies and policy optimization for real-world dexterous object manipulation ;https://ieeexplore.ieee.org/abstract/document/9619924/
1465;umkTQ6R2GcQJ;Hyperparameter selection for imitation learning ;https://proceedings.mlr.press/v139/hussenot21a.html
1466;RTl271mZOwkJ;Modem: Accelerating visual model-based reinforcement learning with demonstrations ;https://arxiv.org/abs/2212.05698
1467;ZOFBoDUVjMUJ;Learning obstacle representations for neural motion planning ;https://proceedings.mlr.press/v155/strudel21a.html
1468;WcWrqcYvae0J;A learning method for AUV collision avoidance through deep reinforcement learning ;https://www.sciencedirect.com/science/article/pii/S0029801822013683
1469;Q9EuQmk6GkoJ;Learning insertion primitives with discrete-continuous hybrid action space for robotic assembly tasks ;https://ieeexplore.ieee.org/abstract/document/9811973/
1470;sibLaRpk9ksJ;Quantum imaginary time evolution steered by reinforcement learning ;https://www.nature.com/articles/s42005-022-00837-y
1471;6fKUrRuEk6cJ;Joint synthesis of safety certificate and safe control policy using constrained reinforcement learning ;https://proceedings.mlr.press/v168/ma22a.html
1472;FVBePNUrNhIJ;Planning for automatic product assembly using reinforcement learning ;https://www.sciencedirect.com/science/article/pii/S0166361521000786
1473;9SZwKGyShmIJ;Comparing deep reinforcement learning algorithms' ability to safely navigate challenging waters ;https://www.frontiersin.org/articles/10.3389/frobt.2021.738113/full
1474;c4KQqNc7hFMJ;Model-augmented prioritized experience replay ;https://openreview.net/forum?id=WuEiafqdy9H
1475;mQeHAxnrF8EJ;CO-PILOT: Collaborative planning and reinforcement learning on sub-task curriculum ;https://proceedings.neurips.cc/paper_files/paper/2021/hash/56577889b3c1cd083b6d7b32d32f99d5-Abstract.html
1476;yrdaxgXhN4AJ;Learning off-policy with online planning ;https://proceedings.mlr.press/v164/sikchi22a.html
1477;rI3MpxFM0XUJ;An autonomous control technology based on deep reinforcement learning for optimal active power dispatch ;https://www.sciencedirect.com/science/article/pii/S0142061522006822
1478;Gno58sAd_uUJ;A robust approach for continuous interactive actor-critic algorithms ;https://ieeexplore.ieee.org/abstract/document/9493212/
1479;qMlP42SVPIAJ;Spatiotemporal knowledge teacher-student reinforcement learning to detect liver tumors without contrast agents ;https://www.sciencedirect.com/science/article/pii/S1361841523002402
1480;UjnBz6Fryi8J;Adaptive optics control with multi-agent model-free reinforcement learning ;https://opg.optica.org/abstract.cfm?uri=oe-30-2-2991
1481;RHRlamdQ9uIJ;Energy-optimized trajectory planning for solar-powered aircraft in a wind field using reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/9857912/
1482;JkE4rvqwxpYJ;Boosting soft actor-critic: Emphasizing recent experience without forgetting the past ;https://arxiv.org/abs/1906.04009
1483;piXaL5ns6NUJ;Online meta-critic learning for off-policy actor-critic methods ;https://proceedings.neurips.cc/paper/2020/hash/cceff8faa855336ad53b3325914caea2-Abstract.html
1484;Ipi71MJkYiYJ;Nearly optimal policy optimization with stable at any time guarantee ;https://proceedings.mlr.press/v162/wu22n.html
1485;OvLTyWUJtmkJ;Edge intelligence for multi-dimensional resource management in aerial-assisted vehicular networks ;https://ieeexplore.ieee.org/abstract/document/9615107/
1486;wPnbCzvVYe0J;Self-imitation learning by planning ;https://ieeexplore.ieee.org/abstract/document/9561411/
1487;xMUnSzAg_YIJ;Soft actor-critic algorithm-based energy management strategy for plug-in hybrid electric vehicle ;https://www.mdpi.com/2032-6653/13/10/193
1488;g8NxPTRZjRsJ;An autonomous negotiating agent framework with reinforcement learning based strategies and adaptive strategy switching mechanism ;https://arxiv.org/abs/2102.03588
1489;FLyk7tCBJzcJ;Scaled autonomy: Enabling human operators to control robot fleets ;https://ieeexplore.ieee.org/abstract/document/9196792/
1490;aCgyB5EXhHkJ;PMSM Speed Control Based on Particle Swarm Optimization and Deep Deterministic Policy Gradient under Load Disturbance ;https://www.mdpi.com/2075-1702/9/12/343
1491;u88o47HRqAQJ;q-Learning in Continuous Time. ;https://www.jmlr.org/papers/volume24/22-0755/22-0755.pdf
1492;gL7nDDqtCRAJ;Actor prioritized experience replay ;https://arxiv.org/abs/2209.00532
1493;xfnRbBB3vSgJ;Improved soft actor-critic: Mixing prioritized off-policy samples with on-policy experiences ;https://ieeexplore.ieee.org/abstract/document/9778268/
1494;1HDmkV8pj3EJ;EMORL: Effective multi-objective reinforcement learning method for hyperparameter optimization ;https://www.sciencedirect.com/science/article/pii/S0952197621001639
1495;ecbEzAq-EC8J;Deep transformer Q-networks for partially observable reinforcement learning ;https://arxiv.org/abs/2206.01078
1496;bkpfpOBVCvgJ;A Survey on Deep Reinforcement Learning Algorithms for Robotic Manipulation ;https://www.mdpi.com/1424-8220/23/7/3762
1497;pQv59ssHNpQJ;Grac: Self-guided and self-regularized actor-critic ;https://proceedings.mlr.press/v164/shao22a.html
1498;AAX4hi12HrMJ;Lipschitz-constrained unsupervised skill discovery ;https://openreview.net/forum?id=BGvt0ghNgA
1499;Ww645YCCi2wJ;Hierarchically decoupled imitation for morphological transfer ;http://proceedings.mlr.press/v119/hejna20a.html
1500;G6ABlrFZVUsJ;State-dependent temperature control for Langevin diffusions ;https://epubs.siam.org/doi/abs/10.1137/21M1429424
1501;K1DV4GQueX4J;Arithmetic value representation for hierarchical behavior composition ;https://www.nature.com/articles/s41593-022-01211-5
1502;oYmf8x8suroJ;A comparison of deep reinforcement learning models for isolated traffic signal control ;https://ieeexplore.ieee.org/abstract/document/9712430/
1503;gAZ6MJmowtcJ;Adversarial soft advantage fitting: Imitation learning without policy optimization ;https://proceedings.neurips.cc/paper/2020/hash/9161ab7a1b61012c4c303f10b4c16b2c-Abstract.html
1504;qEcDhbO2ukEJ;Vision based drone obstacle avoidance by deep reinforcement learning ;https://www.mdpi.com/2673-2688/2/3/23
1505;si5HNDN1JooJ;Functional regularization for reinforcement learning via learned fourier features ;https://proceedings.neurips.cc/paper/2021/hash/9f0609b9d45dd55bed75f892cf095fcf-Abstract.html
1506;WZAYS_oavUwJ;Spectrum Random Masking for Generalization in Image-based Reinforcement Learning ;https://proceedings.neurips.cc/paper_files/paper/2022/hash/802a4350ca4fced76b13b8b320af1543-Abstract-Conference.html
1507;DzGCr8GUlqIJ;Evaluating vision transformer methods for deep reinforcement learning from pixels ;https://arxiv.org/abs/2204.04905
1508;hLPtq7vlsKoJ;ATAC-based car-following model for level 3 autonomous driving considering driver's acceptance ;https://ieeexplore.ieee.org/abstract/document/9468359/
1509;w-7zyEGPX5IJ;Revisiting discrete soft actor-critic ;https://arxiv.org/abs/2209.10081
1510;V2-GjOHrlgAJ;Reinforcement learning based underwater wireless optical communication alignment for autonomous underwater vehicles ;https://ieeexplore.ieee.org/abstract/document/9832941/
1511;XzbBmgBIe1EJ;Offline rl with realistic datasets: Heteroskedasticity and support constraints ;https://arxiv.org/abs/2211.01052
1512;4OxLuyMAmW4J;A safe reinforcement learning-based charging strategy for electric vehicles in residential microgrid ;https://www.sciencedirect.com/science/article/pii/S0306261923008541
1513;jTf-5ca0LMkJ;Asynchronous methods for model-based reinforcement learning ;https://arxiv.org/abs/1910.12453
1514;uSazIfEssOgJ;Bulletarm: An open-source robotic manipulation benchmark and learning framework ;https://link.springer.com/chapter/10.1007/978-3-031-25555-7_23
1515;4r6AYw2T4doJ;Variance aware reward smoothing for deep reinforcement learning ;https://www.sciencedirect.com/science/article/pii/S0925231221009139
1516;W4H7Sy7PCkgJ;Reinforcement learning of rare diffusive dynamics ;https://pubs.aip.org/aip/jcp/article/155/13/134105/353217
1517;N5wMHl2lyN8J;MyoSim: Fast and physiologically realistic MuJoCo models for musculoskeletal and exoskeletal studies ;https://ieeexplore.ieee.org/abstract/document/9811684/
1518;MP_MzO8hdxYJ;Cooperative Downloading for LEO Satellite Networks: A DRL-Based Approach ;https://www.mdpi.com/1424-8220/22/18/6853
1519;H4qkvntL4dkJ;Deep reinforcement learning towards real-world dynamic thermal management of data centers ;https://www.sciencedirect.com/science/article/pii/S0306261922018189
1520;co-8c2MP7JkJ;Deep reinforcement learning for predicting kinetic pathways to surface reconstruction in a ternary alloy ;https://iopscience.iop.org/article/10.1088/2632-2153/ac191c/meta
1521;mOa_Nma4K0gJ;CausalAF: causal autoregressive flow for safety-critical driving scenario generation ;https://proceedings.mlr.press/v205/ding23a.html
1522;UGsIbMrbsdYJ;Hybrid control for combining model-based and model-free reinforcement learning ;https://journals.sagepub.com/doi/abs/10.1177/02783649221083331
1523;hXtx3IEa990J;Ctrlformer: Learning transferable state representation for visual control via transformer ;https://arxiv.org/abs/2206.08883
1524;S9Xa22-z8ugJ;Learning-based multi-UAV flocking control with limited visual field and instinctive repulsion ;https://ieeexplore.ieee.org/abstract/document/10064126/
1525;aL0aKhkr4m4J;Maximum entropy optimal control of continuous-time dynamical systems ;https://ieeexplore.ieee.org/abstract/document/9760123/
1526;Atrk-bucCssJ;Learning robust policy against disturbance in transition dynamics via state-conservative policy optimization ;https://ojs.aaai.org/index.php/AAAI/article/view/20686
1527;vB1TLXgQwjUJ;Learning novel policies for tasks ;https://proceedings.mlr.press/v97/zhang19q.html
1528;LGH_W1R2Kd8J;Deep neural network-based surrogate model for optimal component sizing of power converters using deep reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/9841555/
1529;_z1m3c8eyBQJ;Model-free reinforcement learning with ensemble for a soft continuum robot arm ;https://ieeexplore.ieee.org/abstract/document/9479340/
1530;7yldeEyodh4J;Flowsheet generation through hierarchical reinforcement learning and graph neural networks ;https://aiche.onlinelibrary.wiley.com/doi/abs/10.1002/aic.17938
1531;7kQ8X8A2pJkJ;Complex interaction as emergent behaviour: Simulating mid-air virtual keyboard typing using reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/9523889/
1532;VCUW7D7NJvYJ;A theoretical analysis of optimistic proximal policy optimization in linear markov decision processes ;https://arxiv.org/abs/2305.08841
1533;6Bw9VjW6QCgJ;Skip training for multi-agent reinforcement learning controller for industrial wave energy converters ;https://ieeexplore.ieee.org/abstract/document/9926561/
1534;JS8xuZ_8WVAJ;Hierarchical multi‐agent reinforcement learning for multi‐aircraft close‐range air combat ;https://ietresearch.onlinelibrary.wiley.com/doi/abs/10.1049/cth2.12413
1535;y6R1_z6bnkcJ;Humanoid robot kick in motion ability for playing robotic soccer ;https://ieeexplore.ieee.org/abstract/document/9096073/
1536;y0zFBJIReosJ;Information Optimization and Transferable State Abstractions in Deep Reinforcement Learning ;https://ieeexplore.ieee.org/abstract/document/9864261/
1537;CVpuVgT84mgJ;Deep reinforcement learning for tactile robotics: Learning to type on a braille keyboard ;https://ieeexplore.ieee.org/abstract/document/9144378/
1538;HHs4DDNK_mMJ;Soft actor-critic deep reinforcement learning with hybrid mixed-integer actions for demand responsive scheduling of energy systems ;https://pubs.acs.org/doi/abs/10.1021/acs.iecr.1c04984
1539;P4zF3UdmEOYJ;Actor-critic-based learning for zero-touch joint resource and energy control in network slicing ;https://ieeexplore.ieee.org/abstract/document/9500265/
1540;lx_3ntTQ814J;Euclid: Towards efficient unsupervised reinforcement learning with multi-choice dynamics model ;https://arxiv.org/abs/2210.00498
1541;6kwEZASxU54J;Human-Robotic Prosthesis as Collaborating Agents for Symmetrical Walking ;https://proceedings.neurips.cc/paper_files/paper/2022/hash/aed42bb2e45857928418e4fe23d8cbcb-Abstract-Conference.html
1542;pwTYeZZXKhsJ;Deep reinforcement learning for computation offloading and resource allocation in unmanned-aerial-vehicle assisted edge computing ;https://www.mdpi.com/1424-8220/21/19/6499
1543;WIHcgmoqirwJ;Co-adaptation of algorithmic and implementational innovations in inference-based deep reinforcement learning ;https://proceedings.neurips.cc/paper/2021/hash/517f24c02e620d5a4dac1db388664a63-Abstract.html
1544;EpnnFxm_P-QJ;Graphopt: Learning optimization models of graph formation ;http://proceedings.mlr.press/v119/trivedi20a.html
1545;4W5-kWKCBQ0J;Data assimilation for urban stormwater and water quality simulations using deep reinforcement learning ;https://www.sciencedirect.com/science/article/pii/S0022169423009150
1546;_cgOUsDW2UkJ;Stabilizing Visual Reinforcement Learning via Asymmetric Interactive Cooperation ;http://openaccess.thecvf.com/content/ICCV2023/html/Zhai_Stabilizing_Visual_Reinforcement_Learning_via_Asymmetric_Interactive_Cooperation_ICCV_2023_paper.html
1547;7F5AX0TWLa0J;Mobility load management in cellular networks: A deep reinforcement learning approach ;https://ieeexplore.ieee.org/abstract/document/9525270/
1548;wcnWshpDiswJ;Multi-modal mutual information (mummi) training for robust self-supervised deep reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/9561187/
1549;EZiQla84etAJ;Forward and inverse reinforcement learning sharing network weights and hyperparameters ;https://www.sciencedirect.com/science/article/pii/S0893608021003221
1550;4cBUl08xyKcJ;Safe Reinforcement Learning for Model-Reference Trajectory Tracking of Uncertain Autonomous Vehicles With Model-Based Acceleration ;https://ieeexplore.ieee.org/abstract/document/10005026/
1551;gfKhPDwfst0J;Energy-optimal trajectory planning for solar-powered aircraft using soft actor-critic ;https://www.sciencedirect.com/science/article/pii/S1000936121003848
1552;LnTd5ajKZZsJ;Striving for simplicity and performance in off-policy DRL: Output normalization and non-uniform sampling ;http://proceedings.mlr.press/v119/wang20x.html
1553;cyERU9Xsh7EJ;Learning navigation skills for legged robots with learned robot embeddings ;https://ieeexplore.ieee.org/abstract/document/9635911/
1554;SqKIqhCHUgcJ;Guiding online reinforcement learning with action-free offline pretraining ;https://arxiv.org/abs/2301.12876
1555;06kdLWtYclEJ;The sufficiency of off-policyness and soft clipping: PPO is still insufficient according to an off-policy measure ;https://ojs.aaai.org/index.php/AAAI/article/view/25864
1556;6y8pMB8SUoEJ;Automated reinforcement learning: An overview ;https://arxiv.org/abs/2201.05000
1557;KmhL8660kH0J;Local-Guided Global: Paired Similarity Representation for Visual Reinforcement Learning ;http://openaccess.thecvf.com/content/CVPR2023/html/Choi_Local-Guided_Global_Paired_Similarity_Representation_for_Visual_Reinforcement_Learning_CVPR_2023_paper.html
1558;FSROyHDWSGAJ;Interpretable preference-based reinforcement learning with tree-structured reward functions ;https://arxiv.org/abs/2112.11230
1559;EnTrVTa096kJ;Inverse reinforcement learning intra-operative path planning for steerable needle ;https://ieeexplore.ieee.org/abstract/document/9645357/
1560;WiGCA6JcQJEJ;Off-policy reinforcement learning with delayed rewards ;https://proceedings.mlr.press/v162/han22e.html
1561;UtP39Wa4PS8J;Computation bits maximization in UAV-assisted MEC networks with fairness constraint ;https://ieeexplore.ieee.org/abstract/document/9780606/
1562;GWMY5-xXD8gJ;Latent state marginalization as a low-cost approach for improving exploration ;https://arxiv.org/abs/2210.00999
1563;ytUwiedE-gQJ;TASAC: A twin-actor reinforcement learning framework with a stochastic policy with an application to batch process control ;https://www.sciencedirect.com/science/article/pii/S096706612300031X
1564;o-MK8Opk8KsJ;Learning long-term reward redistribution via randomized return decomposition ;https://arxiv.org/abs/2111.13485
1565;Xl8HdDgsb_gJ;Constrained soft actor-critic for energy-aware trajectory design in UAV-Aided iot networks ;https://ieeexplore.ieee.org/abstract/document/9766421/
1566;CBy6-XignPQJ;RLogist: fast observation strategy on whole-slide images with deep reinforcement learning ;https://ojs.aaai.org/index.php/AAAI/article/view/25467
1567;uN09nywHhwEJ;Learning to seek: Autonomous source seeking with deep reinforcement learning onboard a nano drone microcontroller ;https://arxiv.org/abs/1909.11236
1568;3A0boc3CQBoJ;Diversity actor-critic: Sample-aware entropy regularization for sample-efficient exploration ;https://proceedings.mlr.press/v139/han21a.html
1569;mjS29ctFuU4J;PI-QT-Opt: Predictive Information Improves Multi-Task Robotic Reinforcement Learning at Scale ;https://proceedings.mlr.press/v205/lee23a.html
1570;yHJcu2n7RHEJ;Taps: Task-agnostic policy sequencing ;https://arxiv.org/abs/2210.12250
1571;XUN-dZDilbYJ;Characterising the robustness of reinforcement learning for continuous control using disturbance injection ;https://arxiv.org/abs/2210.15199
1572;YJnpcFbRXs8J;Molecule generation for drug design: a graph learning perspective ;https://arxiv.org/abs/2202.09212
1573;h3zQgMuxqsoJ;igrow: A smart agriculture solution to autonomous greenhouse control ;https://ojs.aaai.org/index.php/AAAI/article/view/21440
1574;EIIO2n8qY1MJ;Extending the capabilities of reinforcement learning through curriculum: A review of methods and applications ;https://link.springer.com/article/10.1007/s42979-021-00934-9
1575;vlCdHS2Cr2MJ;A max-min entropy framework for reinforcement learning ;https://proceedings.neurips.cc/paper/2021/hash/d7b76edf790923bf7177f7ebba5978df-Abstract.html
1576;xRjyxYUb7tQJ;Cclf: A contrastive-curiosity-driven learning framework for sample-efficient reinforcement learning ;https://arxiv.org/abs/2205.00943
1577;3JVnGoPx-WsJ;Simulated and Real Robotic Reach, Grasp, and Pick-and-Place Using Combined Reinforcement Learning and Traditional Controls ;https://www.mdpi.com/2218-6581/12/1/12
1578;3yu1FVaARxEJ;Saac: Safe reinforcement learning as an adversarial game of actor-critics ;https://arxiv.org/abs/2204.09424
1579;rvEzSkr5YJEJ;Meta-reinforcement learning via language instructions ;https://ieeexplore.ieee.org/abstract/document/10160626/
1580;YwLJVj2Hp0cJ;Learning purely tactile in-hand manipulation with a torque-controlled hand ;https://ieeexplore.ieee.org/abstract/document/9812093/
1581;6QdY35xWCe0J;Coordinated carbon capture systems and power-to-gas dynamic economic energy dispatch strategy for electricity–gas coupled systems considering system … ;https://www.sciencedirect.com/science/article/pii/S0360544223003596
1582;zDcG7AXnHz8J;Transfer reinforcement learning method with multi-label learning for compound fault recognition ;https://www.sciencedirect.com/science/article/pii/S1474034622002762
1583;JDVv8Awq71oJ;Many-to-Many Task Offloading in Vehicular Fog Computing: A Multi-Agent Deep Reinforcement Learning Approach ;https://ieeexplore.ieee.org/abstract/document/10056271/
1584;63aBO1usGGwJ;A regularized approach to sparse optimal policy in reinforcement learning ;https://proceedings.neurips.cc/paper_files/paper/2019/hash/3f4366aeb9c157cf9a30c90693eafc55-Abstract.html
1585;Lsdq5o-m8twJ;State deviation correction for offline reinforcement learning ;https://ojs.aaai.org/index.php/AAAI/article/view/20886
1586;1und7ibhsjIJ;Off-policy policy gradient with stationary distribution correction ;http://proceedings.mlr.press/v115/liu20a.html
1587;L3eSwZisLkkJ;PECAN: Leveraging Policy Ensemble for Context-Aware Zero-Shot Human-AI Coordination ;https://arxiv.org/abs/2301.06387
1588;C8eoeKtHYowJ;Distributed optimization for distribution grids with stochastic der using multi-agent deep reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/9411856/
1589;QHFvUg5BAZ8J;Simsr: Simple distance-based state representations for deep reinforcement learning ;https://ojs.aaai.org/index.php/AAAI/article/view/20883
1590;zIrb3giXDFAJ;Deep reinforcement learning for cryptocurrency trading: Practical approach to address backtest overfitting ;https://arxiv.org/abs/2209.05559
1591;FXuXfJNxgq4J;Powergym: A reinforcement learning environment for volt-var control in power distribution systems ;https://proceedings.mlr.press/v168/fan22a.html
1592;jjuHMlWemmMJ;Augmenting reinforcement learning with transformer-based scene representation learning for decision-making of autonomous driving ;https://arxiv.org/abs/2208.12263
1593;ze4RNaKSBM8J;DHRL: A Graph-Based Approach for Long-Horizon and Sparse Hierarchical Reinforcement Learning ;https://proceedings.neurips.cc/paper_files/paper/2022/hash/58b286aea34a91a3d33e58af0586fa40-Abstract-Conference.html
1594;Q9CtLagVPWoJ;PALMER: Perception-Action Loop with Memory for Long-Horizon Planning ;https://proceedings.neurips.cc/paper_files/paper/2022/hash/dd7a48c862b800f0537fe1d506e641b5-Abstract-Conference.html
1595;46g09WnIH-8J;Langevin Thompson sampling with logarithmic communication: bandits and reinforcement learning ;https://proceedings.mlr.press/v202/karbasi23a.html
1596;BMkFRhstVoYJ;REBOOT: Reuse Data for Bootstrapping Efficient Real-World Dexterous Manipulation ;https://arxiv.org/abs/2309.03322
1597;Wg3-j1ZSTrgJ;Off-policy meta-reinforcement learning with belief-based task inference ;https://ieeexplore.ieee.org/abstract/document/9763505/
1598;-PBs4DZfhLgJ;Autonomous skill learning of water polo ball heading for a robotic fish: Curriculum and verification ;https://ieeexplore.ieee.org/abstract/document/9817452/
1599;g38GtU5sSFsJ;Risk-conditioned distributional soft actor-critic for risk-sensitive navigation ;https://ieeexplore.ieee.org/abstract/document/9560962/
1600;iP3X_6jjPGgJ;A few lessons learned in reinforcement learning for quadcopter attitude control ;https://dl.acm.org/doi/abs/10.1145/3447928.3456707
1601;NYEpp5uxUnoJ;Dexterous manipulation for multi-fingered robotic hands with reinforcement learning: a review ;https://www.frontiersin.org/articles/10.3389/fnbot.2022.861825/full
1602;creEwAGp-78J;Cooperative control for multi-intersection traffic signal based on deep reinforcement learning and imitation learning ;https://ieeexplore.ieee.org/abstract/document/9241814/
1603;PBt1Tm90U7YJ;Nonlinear control of an expander-bleed rocket engine using reinforcement learning ;https://elib.dlr.de/141739/
1604;hz6Yo88KMRYJ;Learning to drive at unsignalized intersections using attention-based deep reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/9564720/
1605;7Z_-XM0mszEJ;Simultaneous control and guidance of an auv based on soft actor–critic ;https://www.mdpi.com/1424-8220/22/16/6072
1606;j0i1cqkIyQwJ;SPD: Synergy Pattern Diversifying Oriented Unsupervised Multi-agent Reinforcement Learning ;https://proceedings.neurips.cc/paper_files/paper/2022/hash/825341ab91db01bf063add41ac022702-Abstract-Conference.html
1607;mnncJpl6xbQJ;Deep reinforcement learning-based V2V partial computation offloading in vehicular fog computing ;https://ieeexplore.ieee.org/abstract/document/9417450/
1608;vD8AbaAzLg4J;Real-time Sequential Security-Constrained Optimal Power Flow: A Hybrid Knowledge-Data-Driven Reinforcement Learning Approach ;https://ieeexplore.ieee.org/abstract/document/10086621/
1609;gZkHR-Nq8m8J;Colonoscopy navigation using end-to-end deep visuomotor control: A user study ;https://ieeexplore.ieee.org/abstract/document/9981480/
1610;7aMw99O04rMJ;Establishment of line-of-sight optical links between autonomous underwater vehicles: Field experiment and performance validation ;https://www.sciencedirect.com/science/article/pii/S0141118722003169
1611;YODRHgvtCMgJ;Study on TLS point cloud registration algorithm for large-scale outdoor weak geometric features ;https://www.mdpi.com/1424-8220/22/14/5072
1612;kYNUyQbBDSQJ;Recurrent off-policy baselines for memory-based continuous control ;https://arxiv.org/abs/2110.12628
1613;i83rTnuJFq0J;Learning to calibrate battery models in real-time with deep reinforcement learning ;https://www.mdpi.com/1996-1073/14/5/1361
1614;h3Jnxs547gAJ;A Bayesian Approach to Robust Inverse Reinforcement Learning ;https://arxiv.org/abs/2309.08571
1615;3bk-MBII1Q8J;Prioritized Hindsight with Dual Buffer for Meta-Reinforcement Learning ;https://www.mdpi.com/2079-9292/11/24/4192
1616;2xy-HpjJGpsJ;Self-learned suppression of roll oscillations based on model-free reinforcement learning ;https://www.sciencedirect.com/science/article/pii/S1270963821003606
1617;CzdOKT4f8qgJ;Search and tracking strategy of autonomous surface underwater vehicle in oceanic eddies based on deep reinforcement learning ;https://www.sciencedirect.com/science/article/pii/S1568494622009516
1618;-h1vLNMS1fIJ;Visual-tactile multimodality for following deformable linear objects using reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/9982218/
1619;bJ63lC1-mR8J;Reinforcement Learning based cooperative longitudinal control for reducing traffic oscillations and improving platoon stability ;https://www.sciencedirect.com/science/article/pii/S0968090X22001772
1620;WKVbwkswGM0J;An improved transformer model with multi-head attention and attention to attention for low-carbon multi-depot vehicle routing problem ;https://link.springer.com/article/10.1007/s10479-022-04788-z
1621;mnVwp1X-IHgJ;Hierarchical Combination of Deep Reinforcement Learning and Quadratic Programming for Distribution System Restoration ;https://ieeexplore.ieee.org/abstract/document/10051723/
1622;Y588MgFCwiQJ;Discrete soft actor-critic with auto-encoder on vascular robotic system ;https://www.cambridge.org/core/journals/robotica/article/discrete-soft-actorcritic-with-autoencoder-on-vascular-robotic-system/B4B948DF75E9B30445923603C5CD2BC5
1623;e8g_RJNIohQJ;Bingham policy parameterization for 3d rotations in reinforcement learning ;https://arxiv.org/abs/2202.03957
1624;qL1msRtkDKQJ;Deep reinforcement learning for gearshift controllers in automatic transmissions ;https://www.sciencedirect.com/science/article/pii/S2590005622000728
1625;GibOxonWTh0J;Multiagent deep reinforcement learning-aided output current sharing control for input-series output-parallel dual active bridge converter ;https://ieeexplore.ieee.org/abstract/document/9793712/
1626;96o8N80bMswJ;Simultaneously learning vision and feature-based control policies for real-world ball-in-a-cup ;https://arxiv.org/abs/1902.04706
1627;mdT5zFuN9OUJ;Beyond Target Networks: Improving Deep -learning with Functional Regularization ;https://arxiv.org/abs/2106.02613
1628;U38QZc1Y9SAJ;Learning object-conditioned exploration using distributed soft actor critic ;https://proceedings.mlr.press/v155/wahid21a.html
1629;ZQzMPrkXhj8J;Motor synergy development in high-performing deep reinforcement learning algorithms ;https://ieeexplore.ieee.org/abstract/document/8966298/
1630;vQbfVVmfCk8J;Evaluations of the gap between supervised and reinforcement lifelong learning on robotic manipulation tasks ;https://proceedings.mlr.press/v164/yang22a.html
1631;i4Dgr5uMyaAJ;Traceable group-wise self-optimizing feature transformation learning: A dual optimization perspective ;https://arxiv.org/abs/2306.16893
1632;XVYQZb7SZ-oJ;Noah: Reinforcement-Learning-Based Rate Limiter for Microservices in Large-Scale E-Commerce Services ;https://ieeexplore.ieee.org/abstract/document/10098822/
1633;T3oLbgwSEGgJ;Distributed multi-agent deep reinforcement learning framework for whole-building hvac control ;https://arxiv.org/abs/2110.13450
1634;i0_vjW0nWLcJ;Deep reinforcement learning-based operation of fast charging stations coupled with energy storage system ;https://www.sciencedirect.com/science/article/pii/S037877962200311X
1635;_FQttxs15IIJ;Learning pessimism for reinforcement learning ;https://ojs.aaai.org/index.php/AAAI/article/view/25852
1636;cALSfpGgU2AJ;Hierarchical Reinforcement Learning for Air Combat At DARPA's AlphaDogfight Trials ;https://ieeexplore.ieee.org/abstract/document/9950612/
1637;PIgTrWVQlCoJ;Adaptive control of a mechatronic system using constrained residual reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/9693307/
1638;f7wNGwAaHFcJ;Cross-domain transfer via semantic skill imitation ;https://arxiv.org/abs/2212.07407
1639;_-b5gfsB8EMJ;Decoupled exploration and exploitation policies for sample-efficient reinforcement learning ;https://arxiv.org/abs/2101.09458
1640;zr8yOq0hCUYJ;Autoregressive policies for continuous control deep reinforcement learning ;https://arxiv.org/abs/1903.11524
1641;lhYWn6SUFxgJ;Guided reinforcement learning with efficient exploration for task automation of surgical robot ;https://arxiv.org/abs/2302.09772
1642;AKDYLaBfto4J;From deterministic to stochastic: an interpretable stochastic model-free reinforcement learning framework for portfolio optimization ;https://link.springer.com/article/10.1007/s10489-022-04217-5
1643;vzXEC9d6oiIJ;Learning to centralize dual-arm assembly ;https://www.frontiersin.org/articles/10.3389/frobt.2022.830007/full
1644;Xr52gEoBGhkJ;Air learning: a deep reinforcement learning gym for autonomous aerial robot visual navigation ;https://link.springer.com/article/10.1007/s10994-021-06006-6
1645;J41E56bOkW0J;A multi-critic reinforcement learning method: An application to multi-tank water systems ;https://ieeexplore.ieee.org/abstract/document/9200594/
1646;IjYMQHUvD4AJ;Monte carlo tree search based hybrid optimization of variational quantum circuits ;https://proceedings.mlr.press/v190/yao22a.html
1647;MmwN4jiHQ28J;Path planning for multiple agents in an unknown environment using soft actor critic and curriculum learning ;https://onlinelibrary.wiley.com/doi/abs/10.1002/cav.2113
1648;4yK1jJCfta0J;Collective reinforcement learning based resource allocation for digital twin service in 6G networks ;https://www.sciencedirect.com/science/article/pii/S1084804523001169
1649;ba6d8cWZm1EJ;ACUTE: Attentional Communication Framework for Multi-Agent Reinforcement Learning in Partially Communicable Scenarios ;https://www.mdpi.com/2079-9292/11/24/4204
1650;4d9sR5SR-CMJ;Independent skill transfer for deep reinforcement learning ;https://www.ijcai.org/proceedings/2020/0401.pdf
1651;v1IhSXeZkVwJ;Effective pre-training of a deep reinforcement learning agent by means of long short-term memory models for thermal energy management in buildings ;https://www.sciencedirect.com/science/article/pii/S0196890423006490
1652;3jI2Tf34UzMJ;Modern machine learning tools for monitoring and control of industrial processes: A survey ;https://www.sciencedirect.com/science/article/pii/S2405896320303827
1653;Rm0y3OX8cjIJ;Task-induced representation learning ;https://arxiv.org/abs/2204.11827
1654;r_Io4bkSpn0J;Learning active spine behaviors for dynamic and efficient locomotion in quadruped robots ;https://ieeexplore.ieee.org/abstract/document/8956332/
1655;hqtIxzE6KHkJ;Safe reinforcement learning from pixels using a stochastic latent representation ;https://arxiv.org/abs/2210.01801
1656;D-EXpRk6_y0J;Learning-based Initialization of Trajectory Optimization for Path-following Problems of Redundant Manipulators ;https://ieeexplore.ieee.org/abstract/document/10161426/
1657;V3Oy0qISm8gJ;Dyna-PPO reinforcement learning with Gaussian process for the continuous action decision-making in autonomous driving ;https://link.springer.com/article/10.1007/s10489-022-04354-x
1658;OcA3QLKXqL0J;Metric Residual Network for Sample Efficient Goal-Conditioned Reinforcement Learning ;https://ojs.aaai.org/index.php/AAAI/article/view/26058
1659;B0gUooYGWc0J;Contrastive Inductive Bias Controlling Networks for Reinforcement Learning ;https://proceedings.mlr.press/v189/li23a.html
1660;C3uiyjBt-VcJ;Dexterous robotic manipulation using deep reinforcement learning and knowledge transfer for complex sparse reward‐based tasks ;https://onlinelibrary.wiley.com/doi/abs/10.1111/exsy.13205
1661;Rk96gM3w1mkJ;Learning to walk a tripod mobile robot using nonlinear soft vibration actuators with entropy adaptive reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/8978537/
1662;Xneg7Dq9DCsJ;Efficient Sim-to-real Transfer of Contact-Rich Manipulation Skills with Online Admittance Residual Learning ;https://arxiv.org/abs/2310.10509
1663;lSVzflNzjWsJ;A Game of Bundle Adjustment-Learning Efficient Convergence ;https://openaccess.thecvf.com/content/ICCV2023/html/Belder_A_Game_of_Bundle_Adjustment_-_Learning_Efficient_Convergence_ICCV_2023_paper.html
1664;iO7EYmYrSGEJ;Human-in-the-loop methods for data-driven and reinforcement learning systems ;https://arxiv.org/abs/2008.13221
1665;xXwxM7smSyQJ;Just round: Quantized observation spaces enable memory efficient learning of dynamic locomotion ;https://ieeexplore.ieee.org/abstract/document/10160293/
1666;ocv7xRssHOAJ;End-to-end Reinforcement Learning for Online Coverage Path Planning in Unknown Environments ;https://arxiv.org/abs/2306.16978
1667;f7bKo4c58bQJ;Multi-agent reinforcement learning accelerated mcmc on multiscale inversion problem ;https://arxiv.org/abs/2011.08954
1668;X7Xck3DgzasJ;Guided policy search model-based reinforcement learning for urban autonomous driving ;https://arxiv.org/abs/2005.03076
1669;pmtJ_io_JJYJ;Deep Reinforcement Learning for Intelligent Penetration Testing Path Design ;https://www.mdpi.com/2076-3417/13/16/9467
1670;JlZIpb-WWzoJ;A hierarchical framework for quadruped locomotion based on reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/9636757/
1671;R_8TU4l6sC8J;6D localization and kicking for humanoid robotic soccer ;https://link.springer.com/article/10.1007/s10846-021-01385-3
1672;mWDtQBOTPhgJ;Variational quantum soft actor-critic ;https://arxiv.org/abs/2112.11921
1673;Tj_lYyJAc8kJ;Stochastic cubic-regularized policy gradient method ;https://www.sciencedirect.com/science/article/pii/S095070512200853X
1674;uQTlSH3NzyYJ;Comparison of deep reinforcement learning and PID controllers for automatic cold shutdown operation ;https://www.mdpi.com/1996-1073/15/8/2834
1675;te1poV7mgIAJ;Control of chaos with time-delayed feedback based on deep reinforcement learning ;https://www.sciencedirect.com/science/article/pii/S0167278923001215
1676;TuAmnooi83QJ;Assessing Quality-Diversity Neuro-Evolution Algorithms Performance in Hard Exploration Problems ;https://arxiv.org/abs/2211.13742
1677;ESjmNG-TLYsJ;Deep Reinforcement Learning-Based End-to-End Control for UAV Dynamic Target Tracking ;https://www.mdpi.com/2313-7673/7/4/197
1678;de4rpCzLIhoJ;Value-consistent representation learning for data-efficient reinforcement learning ;https://ojs.aaai.org/index.php/AAAI/article/view/26311
1679;v5CbmYkaYucJ;MERLIN: Multi-agent offline and transfer learning for occupant-centric energy flexible operation of grid-interactive communities using smart meter data and CityLearn ;https://arxiv.org/abs/2301.01148
1680;b493ZLeTc5EJ;Improved policy optimization for online imitation learning ;https://proceedings.mlr.press/v199/lavington22a.html
1681;glxoeClqEvoJ;F2a2: Flexible fully-decentralized approximate actor-critic for cooperative multi-agent reinforcement learning ;https://arxiv.org/abs/2004.11145
1682;BohfHJ42KLMJ;MERLIN: Multi-agent offline and transfer learning for occupant-centric operation of grid-interactive communities ;https://www.sciencedirect.com/science/article/pii/S0306261923006876
1683;1FuRuVMZxEQJ;Learning High Speed Precision Table Tennis on a Physical Robot ;https://ieeexplore.ieee.org/abstract/document/9982205/
1684;N_zcp0CWQH0J;Automated reinforcement learning (autorl): A survey and open problems ;https://www.jair.org/index.php/jair/article/view/13596
1685;CgNI17oseNwJ;Cherry-picking with reinforcement learning ;https://www.roboticsproceedings.org/rss19/p021.pdf
1686;y9R2svAttVoJ;Adaptive Traffic Signal Control Based on Neural Network Prediction of Weighted Traffic Flow ;https://link.springer.com/article/10.3103/S8756699022050016
1687;9X0lFqPOAAIJ;Battery thermal-and cabin comfort-aware collaborative energy management for plug-in fuel cell electric vehicles based on the soft actor-critic algorithm ;https://www.sciencedirect.com/science/article/pii/S0196890423002352
1688;3IdIVuhSjOgJ;Reinforcement learning: theory and applications in hems ;https://www.mdpi.com/1996-1073/15/17/6392
1689;zvQOSnXZI_oJ;Blending mpc & value function approximation for efficient reinforcement learning ;https://arxiv.org/abs/2012.05909
1690;E0zZNP5iKWMJ;From psychological curiosity to artificial curiosity: Curiosity-driven learning in artificial intelligence tasks ;https://arxiv.org/abs/2201.08300
1691;ze4Jf2bpuf4J;Continuous control with action quantization from demonstrations ;https://arxiv.org/abs/2110.10149
1692;zjN2jjc9Bq8J;Soft actor-critic deep reinforcement learning for fault tolerant flight control ;https://arc.aiaa.org/doi/abs/10.2514/6.2022-2078
1693;CmLIvFq895oJ;Learning to place objects onto flat surfaces in upright orientations ;https://ieeexplore.ieee.org/abstract/document/9384169/
1694;xQ-6EsUu8HYJ;Predictable MDP Abstraction for Unsupervised Model-Based RL ;https://arxiv.org/abs/2302.03921
1695;NgUhcBS7WkMJ;Delay-aware Edge-Terminal Collaboration in Green Internet of Vehicles: A Multi-Agent Soft Actor-Critic Approach ;https://ieeexplore.ieee.org/abstract/document/9810544/
1696;FhOWzY-wnesJ;Research on PID Parameter Tuning and Optimization Based on SAC-Auto for USV Path Following ;https://www.mdpi.com/2077-1312/10/12/1847
1697;bsXVZKgpLNkJ;Ten questions concerning reinforcement learning for building energy management ;https://www.sciencedirect.com/science/article/pii/S0360132323004626
1698;HCVwm8_tZAUJ;Dream to generalize: zero-shot model-based reinforcement learning for unseen visual distractions ;https://ojs.aaai.org/index.php/AAAI/article/view/25945
1699;VTsxphS6pRsJ;Neural Collage Transfer: Artistic Reconstruction via Material Manipulation ;https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Neural_Collage_Transfer_Artistic_Reconstruction_via_Material_Manipulation_ICCV_2023_paper.html
1700;I8IzIV196G4J;Chaining behaviors from data with model-free reinforcement learning ;https://proceedings.mlr.press/v155/singh21a.html
1701;cnG2Obr8iGgJ;Graph Decision Transformer ;https://arxiv.org/abs/2303.03747
1702;XFSSl6oI4b0J;Bayesian bellman operators ;https://proceedings.neurips.cc/paper_files/paper/2021/hash/7180cffd6a8e829dacfc2a31b3f72ece-Abstract.html
1703;ecqo_QlndOUJ;Stabilizing voltage in power distribution networks via multi-agent reinforcement learning with transformer ;https://dl.acm.org/doi/abs/10.1145/3534678.3539480
1704;1uqAuDvYS7AJ;Geometric reinforcement learning for robotic manipulation ;https://ieeexplore.ieee.org/abstract/document/10273391/
1705;-nNYyJIGf4YJ;Off-policy maximum entropy reinforcement learning: Soft actor-critic with advantage weighted mixture policy (sac-awmp) ;https://arxiv.org/abs/2002.02829
1706;mTW2CkdCkvMJ;Autonomous air combat decision‐making of UAV based on parallel self‐play reinforcement learning ;https://ietresearch.onlinelibrary.wiley.com/doi/abs/10.1049/cit2.12109
1707;nAqf7Nl6qSIJ;A comparative study of deep reinforcement learning based energy management strategy for hybrid electric vehicle ;https://www.sciencedirect.com/science/article/pii/S0196890423007884
1708;B9Fhbtw8BeUJ;Solving continuous control with episodic memory ;https://arxiv.org/abs/2106.08832
1709;3oVzXR-3xbAJ;Enhanced off-policy reinforcement learning with focused experience replay ;https://ieeexplore.ieee.org/abstract/document/9444458/
1710;YiW0_dgKZuMJ;Learn zero-constraint-violation policy in model-free constrained reinforcement learning ;https://arxiv.org/abs/2111.12953
1711;Y8UICuO_iOwJ;Leveraging granularity: Hierarchical reinforcement learning for pedagogical policy induction ;https://link.springer.com/article/10.1007/s40593-021-00269-9
1712;pJpUiMCmIkIJ;Distributional generative adversarial imitation learning with reproducing kernel generalization ;https://www.sciencedirect.com/science/article/pii/S0893608023002721
1713;lX08PvOUr_0J;Deep reinforcement learning-based two-timescale Volt-VAR control with degradation-aware smart inverters in power distribution systems ;https://www.sciencedirect.com/science/article/pii/S0306261922018864
1714;_-Vl1kVP4aMJ;Attention-Based Communication and Control for Multi-UAV Path Planning ;https://ieeexplore.ieee.org/abstract/document/9766100/
1715;nIN0zF4H0rsJ;An analytical update rule for general policy optimization ;https://proceedings.mlr.press/v162/li22d.html
1716;z7FzmZge__QJ;Driving black-box quantum thermal machines with optimal power/efficiency trade-offs using reinforcement learning ;https://arxiv.org/abs/2204.04785
1717;3Yo2Dhtbr4kJ;An Efficient Self-Evolution Method of Autonomous Driving for Any Given Algorithm ;https://ieeexplore.ieee.org/abstract/document/10239250/
1718;A7aikqkHR5MJ;Reinforcement learning experiments and benchmark for solving robotic reaching tasks ;https://link.springer.com/chapter/10.1007/978-3-030-62579-5_22
1719;zy6b1Je67tgJ;Model-free optimization of power/efficiency tradeoffs in quantum thermal machines using reinforcement learning ;https://academic.oup.com/pnasnexus/article/doi/10.1093/pnasnexus/pgad248/7235395
1720;vAZMybsHqMwJ;Exploratory state representation learning ;https://www.frontiersin.org/articles/10.3389/frobt.2022.762051/full
1721;yU3wZR8jdnoJ;A DRL-Based Task Offloading Scheme for Server Decision-Making in Multi-Access Edge Computing ;https://www.mdpi.com/2079-9292/12/18/3882
1722;ocr9HdHHMDQJ;CACTO: Continuous Actor-Critic with Trajectory Optimization—Towards global optimality ;https://ieeexplore.ieee.org/abstract/document/10101856/
1723;FRYnd65HafgJ;Generalizing reinforcement learning through fusing self-supervised learning into intrinsic motivation ;https://ojs.aaai.org/index.php/AAAI/article/view/20847
1724;GVia3mtsg5IJ;Adaptive Nonlinear Model Predictive Horizon Using Deep Reinforcement Learning for Optimal Trajectory Planning ;https://www.mdpi.com/2504-446X/6/11/323
1725;MRG0EfVQ-qkJ;Balancing policy constraint and ensemble size in uncertainty-based offline reinforcement learning ;https://arxiv.org/abs/2303.14716
1726;5-4p68b6Ke8J;A survey on reinforcement learning for combinatorial optimization ;https://ieeexplore.ieee.org/abstract/document/10263956/
1727;B8lLgHj7rFUJ;Suspension control strategies using switched soft actor-critic models for real roads ;https://ieeexplore.ieee.org/abstract/document/9724132/
1728;YKdaWmhR5J0J;Decentralized multi-agent control of a manipulator in continuous task learning ;https://www.mdpi.com/2076-3417/11/21/10227
1729;7cxCu81rq_kJ;Policy Gradient With Serial Markov Chain Reasoning ;https://proceedings.neurips.cc/paper_files/paper/2022/hash/39fac857b4467e3ef4f358186bb07d81-Abstract-Conference.html
1730;qZ106XqkAHIJ;Exploiting Unlabeled Data for Feedback Efficient Human Preference based Reinforcement Learning ;https://arxiv.org/abs/2302.08738
1731;EDJXLatb5WcJ;Increasing the safety of adaptive cruise control using physics-guided reinforcement learning ;https://www.mdpi.com/1996-1073/14/22/7572
1732;KOoMHEXZduYJ;Learning Generalizable Pivoting Skills ;https://arxiv.org/abs/2305.02554
1733;ow4cdQuJ2ToJ;RLlib Flow: Distributed Reinforcement Learning is a Dataflow Problem ;https://proceedings.neurips.cc/paper_files/paper/2021/hash/2bce32ed409f5ebcee2a7b417ad9beed-Abstract.html
1734;gtb21BeDAEoJ;Action noise in off-policy deep reinforcement learning: Impact on exploration and performance ;https://arxiv.org/abs/2206.03787
1735;4GKw7g_TXckJ;Decentralized global connectivity maintenance for multi-robot navigation: A reinforcement learning approach ;https://ieeexplore.ieee.org/abstract/document/9812163/
1736;jqh6miTe6_4J;Task and motion planning methods: applications and limitations ;https://hal.science/hal-03744923/
1737;kUdKODCyW_8J;Towards learning to play piano with dexterous hands and touch ;https://ieeexplore.ieee.org/abstract/document/9981221/
1738;hpMai8k46AgJ;Generalization and computation for policy classes of generative adversarial imitation learning ;https://link.springer.com/chapter/10.1007/978-3-031-14714-2_27
1739;zdzLohQLdksJ;A surrogate-assisted controller for expensive evolutionary reinforcement learning ;https://www.sciencedirect.com/science/article/pii/S0020025522012658
1740;HRUAizKNEgcJ;Asynchronous reinforcement learning for real-time control of physical robots ;https://ieeexplore.ieee.org/abstract/document/9811771/
1741;k-MDfwnm0x0J;Framework for TCAD augmented machine learning on multi-I–V characteristics using convolutional neural network and multiprocessing ;https://iopscience.iop.org/article/10.1088/1674-4926/42/12/124101/meta
1742;5Mgf7LokaRkJ;Ariadne: A reinforcement learning approach using attention-based deep networks for exploration ;https://arxiv.org/abs/2301.11575
1743;O_Mjo6-1qmEJ;Imitation learning for high precision peg-in-hole tasks ;https://ieeexplore.ieee.org/abstract/document/9108072/
1744;Y5UhzFNMuuoJ;Distributed conflict resolution at high traffic densities with reinforcement learning ;https://www.mdpi.com/2226-4310/9/9/472
1745;Kr3kXHaR8GAJ;Adaptive behavior cloning regularization for stable offline-to-online reinforcement learning ;https://arxiv.org/abs/2210.13846
1746;iCwErVNnTOYJ;Improving Algorithm Conflict Resolution Manoeuvres with Reinforcement Learning ;https://www.mdpi.com/2226-4310/9/12/847
1747;tVms47UsOzsJ;Conditional automated channel pruning for deep neural networks ;https://ieeexplore.ieee.org/abstract/document/9453104/
1748;5p9cHbLxJUgJ;A study of causal confusion in preference-based reward learning ;https://openreview.net/forum?id=WaZZ0Sw9fWf
1749;npop1s_P4UAJ;Energy efficient AP selection for cell-free massive MIMO systems: Deep reinforcement learning approach ;https://ieeexplore.ieee.org/abstract/document/9849036/
1750;kLEZtxPCIlcJ;Contextual latent-movements off-policy optimization for robotic manipulation skills ;https://ieeexplore.ieee.org/abstract/document/9561870/
1751;38kdndPdzAMJ;Optimization of demand response-oriented electrolytic and fuel cell cogeneration system for community residents: uncovering flexibility and gaps ;https://www.sciencedirect.com/science/article/pii/S0196890423004454
1752;xAwOy2vv4GcJ;Real-world human-robot collaborative reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/9341473/
1753;o4h8nbJSJikJ;Trajectory planning and vibration control of translation flexible hinged plate based on optimization and reinforcement learning algorithm ;https://www.sciencedirect.com/science/article/pii/S0888327022004940
1754;myVngHzKuEAJ;Learning pessimism for robust and efficient off-policy reinforcement learning ;https://arxiv.org/abs/2110.03375
1755;lKo6KW1pz6cJ;Synergy emergence in deep reinforcement learning for full-dimensional arm manipulation ;https://ieeexplore.ieee.org/abstract/document/9345796/
1756;11ZF3DDg8sYJ;Traffic engineering based on reinforcement learning for service function chaining with delay guarantee ;https://ieeexplore.ieee.org/abstract/document/9526552/
1757;JEsCr0rKE1AJ;Variational meta reinforcement learning for social robotics ;https://link.springer.com/article/10.1007/s10489-023-04691-5
1758;TNTJEEbUDgsJ;Utilizing reinforcement learning to continuously improve a primitive-based motion planner ;https://arc.aiaa.org/doi/abs/10.2514/1.I011044
1759;xnx5AhFIOM4J;Inertia-Constrained Reinforcement Learning to Enhance Human Motor Control Modeling ;https://www.mdpi.com/1424-8220/23/5/2698
1760;oTjFFSFwbAEJ;To follow or not to follow: Selective imitation learning from observations ;https://arxiv.org/abs/1912.07670
1761;QON2_DHGX4QJ;Empowering the diversity and individuality of option: Residual soft option critic framework ;https://ieeexplore.ieee.org/abstract/document/9632279/
1762;mwTSij6d3rYJ;Neuro-planner: A 3d visual navigation method for mav with depth camera based on neuromorphic reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/10262227/
1763;f8JVI6VewicJ;A novel data-driven energy management strategy for fuel cell hybrid electric bus based on improved twin delayed deep deterministic policy gradient algorithm ;https://www.sciencedirect.com/science/article/pii/S0360319923022103
1764;3PN-XMRHonkJ;Value Summation: A novel scoring function for MPC-based model-based reinforcement learning ;https://arxiv.org/abs/2209.08169
1765;5LxwBdHuQf4J;DRL-based Path Planner and its Application in Real Quadrotor with LIDAR ;https://link.springer.com/article/10.1007/s10846-023-01819-0
1766;1HLvlq_q_i8J;Reinforcement Learning Algorithms: A brief survey ;https://www.sciencedirect.com/science/article/pii/S0957417423009971
1767;qc-vIYgEdFwJ;Distributional Shift-Aware Off-Policy Interval Estimation: A Unified Error Quantification Framework ;https://arxiv.org/abs/2309.13278
1768;tgNHJnrviEUJ;Variational policy search using sparse Gaussian process priors for learning multimodal optimal actions ;https://www.sciencedirect.com/science/article/pii/S0893608021002422
1769;XDxqB1z8BGwJ;Sample efficient social navigation using inverse reinforcement learning ;https://arxiv.org/abs/2106.10318
1770;MBnCSO0JZ-sJ;Active hierarchical exploration with stable subgoal representation learning ;https://arxiv.org/abs/2105.14750
1771;2oDGX73wxlEJ;Model-free dynamic control of robotic joints with integrated elastic ligaments ;https://www.sciencedirect.com/science/article/pii/S0921889022000860
1772;MPZ-EGGwGmsJ;A simulator-based planning framework for optimizing autonomous greenhouse control strategy ;https://ojs.aaai.org/index.php/ICAPS/article/view/15989
1773;P2xZd6MoOuEJ;Target-based Surrogates for Stochastic Optimization ;https://arxiv.org/abs/2302.02607
1774;TybqCkxdzm8J;Guided soft actor critic: A guided deep reinforcement learning approach for partially observable markov decision processes ;https://ieeexplore.ieee.org/abstract/document/9631278/
1775;oIM8I0oBXz8J;Timing is everything: Learning to act selectively with costly actions and budgetary constraints ;https://arxiv.org/abs/2205.15953
1776;v1d-1nTmU7kJ;A collaborative statistical actor-critic learning approach for 6G network slicing control ;https://ieeexplore.ieee.org/abstract/document/9685218/
1777;BAJ2njta7hcJ;Graph augmented deep reinforcement learning in the GameRLand3D environment ;https://arxiv.org/abs/2112.11731
1778;o6HJCUH-Xx0J;Learning to sample with local and global contexts in experience replay buffer ;https://arxiv.org/abs/2007.07358
1779;Mg5hKOodva4J;Longevity-aware energy management for fuel cell hybrid electric bus based on a novel proximal policy optimization deep reinforcement learning framework ;https://www.sciencedirect.com/science/article/pii/S0378775323000927
1780;2s2Bv0rYIlgJ;Meta-sac: Auto-tune the entropy temperature of soft actor-critic via metagradient ;https://arxiv.org/abs/2007.01932
1781;Tqv6K9qkUSEJ;Building a subspace of policies for scalable continual learning ;https://arxiv.org/abs/2211.10445
1782;9HXPrzNmZkwJ;Boosting Exploration in Actor-Critic Algorithms by Incentivizing Plausible Novel States ;https://arxiv.org/abs/2210.00211
1783;Ewmf_HUPjDUJ;Reinforcement learning for multi-aircraft autonomous air combat in multi-sensor UCAV platform ;https://ieeexplore.ieee.org/abstract/document/9947042/
1784;zVCBpIDogcMJ;Efficient quality-diversity optimization through diverse quality species ;https://dl.acm.org/doi/abs/10.1145/3583133.3590581
1785;jMcuIzGRmuwJ;Encoding distributional soft actor-critic for autonomous driving in multi-lane scenarios ;https://arxiv.org/abs/2109.05540
1786;CzMPuf90UKEJ;A 3d simulation environment and navigation approach for robot navigation via deep reinforcement learning in dense pedestrian environment ;https://ieeexplore.ieee.org/abstract/document/9217023/
1787;3PCDLqPrdXYJ;Explicable Policy Search ;https://proceedings.neurips.cc/paper_files/paper/2022/hash/fdff3c4130c24c40c88aa41eb52d2a27-Abstract-Conference.html
1788;2lj13JTNrNsJ;Implicit distributional reinforcement learning ;https://proceedings.neurips.cc/paper/2020/hash/4f20f7f5d2e7a1b640ebc8244428558c-Abstract.html
1789;SR3BHRd6ysMJ;Safe reinforcement learning of dynamic high-dimensional robotic tasks: navigation, manipulation, interaction ;https://ieeexplore.ieee.org/abstract/document/10161548/
1790;4GVUgzu0KGMJ;Transfer reinforcement learning via meta-knowledge extraction using auto-pruned decision trees ;https://www.sciencedirect.com/science/article/pii/S0950705122000624
1791;bNFaFZAydzUJ;Learning to view: Decision transformers for active object detection ;https://arxiv.org/abs/2301.09544
1792;AFukQeyhMLQJ;Optimizing service function chaining migration with explicit dynamic path ;https://ieeexplore.ieee.org/abstract/document/9709333/
1793;W9vYRpjkYx0J;Device selection for the coexistence of URLLC and distributed learning services ;https://arxiv.org/abs/2212.11805
1794;B5bUllXB89QJ;Boosting Supervised Dehazing Methods via Bi-level Patch Reweighting ;https://link.springer.com/chapter/10.1007/978-3-031-19797-0_4
1795;jSBhpU5cjFwJ;Intrinsically motivated reinforcement learning based recommendation with counterfactual data augmentation ;https://link.springer.com/article/10.1007/s11280-023-01187-7
1796;mbvQl-F0UJoJ;Goal-guided transformer-enabled reinforcement learning for efficient autonomous navigation ;https://arxiv.org/abs/2301.00362
1797;QJtRd8_j-cYJ;A Joint Modeling of Vision-Language-Action for Target-oriented Grasping in Clutter ;https://arxiv.org/abs/2302.12610
1798;odd7L9aahGAJ;Autonomous car racing in simulation environment using deep reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/8946332/
1799;JMyBZJLonMwJ;LifeGuard: An Improvement of Actor-Critic Model with Collision Predictor in Autonomous UAV Navigation ;https://www.tandfonline.com/doi/abs/10.1080/08839514.2022.2137632
1800;JH90zyUX7TAJ;Learning to Grasp on the Moon from 3D Octree Observations with Deep Reinforcement Learning ;https://ieeexplore.ieee.org/abstract/document/9981661/
1801;0F3OMfFGKvAJ;Large-scale Lifelong Learning of In-context Instructions and How to Tackle It ;https://aclanthology.org/2023.acl-long.703/
1802;QootEEkriUQJ;A deep reinforcement learning approach for power management of battery-assisted fast-charging EV hubs participating in day-ahead and real-time electricity … ;https://www.sciencedirect.com/science/article/pii/S036054422302491X
1803;UMbkeBtcJZ8J;Deep Reinforcement Learning-based UAV Navigation and Control: A Soft Actor-Critic with Hindsight Experience Replay Approach ;https://arxiv.org/abs/2106.01016
1804;WacyA7Rlb5UJ;Lyceum: An efficient and scalable ecosystem for robot learning ;http://proceedings.mlr.press/v120/summers20a.html
1805;dBsmzbPLRyYJ;Covy: An ai-powered robot for detection of breaches in social distancing ;https://arxiv.org/abs/2207.06847
1806;ZmGbCkTjoZUJ;Trajectory planning with deep reinforcement learning in high-level action spaces ;https://ieeexplore.ieee.org/abstract/document/9940484/
1807;f2nfJTfRhYgJ;Action candidate based clipped double q-learning for discrete and continuous action tasks ;https://ojs.aaai.org/index.php/AAAI/article/view/16973
1808;udCW5KyUcnwJ;Grimgep: learning progress for robust goal sampling in visual deep reinforcement learning ;https://ieeexplore.ieee.org/iel7/7274989/7422051/09928363.pdf
1809;SIzRZTRkVssJ;Adaptively calibrated critic estimates for deep reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/9984837/
1810;rJoNk2jaV-0J;Goal-directed planning by reinforcement learning and active inference ;https://arxiv.org/abs/2106.09938
1811;5b6P4q_pcc8J;Aggressive q-learning with ensembles: Achieving both high sample efficiency and high asymptotic performance ;https://arxiv.org/abs/2111.09159
1812;C20jNraxY5kJ;Soft Actor–Critic Algorithm Featured Residential Demand Response Strategic Bidding for Load Aggregators ;https://ieeexplore.ieee.org/abstract/document/9767551/
1813;sdjwVT6DGMAJ;Soft actor-critic DRL algorithm for interval optimal dispatch of integrated energy systems with uncertainty in demand response and renewable energy ;https://www.sciencedirect.com/science/article/pii/S0952197623014148
1814;1PIieNZlZbcJ;Traffic signal control using a cooperative EWMA-based multi-agent reinforcement learning ;https://link.springer.com/article/10.1007/s10489-022-03643-9
1815;t6FHn4COtaYJ;Deep Reinforcement Learning Based Explainable Pricing Policy for Virtual Storage Rental Service ;https://ieeexplore.ieee.org/abstract/document/10068282/
1816;TukhyZO2j4sJ;Federated Deep Reinforcement Learning for Recommendation-Enabled Edge Caching in Mobile Edge-Cloud Computing Networks ;https://ieeexplore.ieee.org/abstract/document/10015857/
1817;40JW5s0TYEIJ;Deep reinforcement learning for dynamic control of fuel injection timing in multi-pulse compression ignition engines ;https://journals.sagepub.com/doi/abs/10.1177/14680874211019345
1818;_xaxufFPGh4J;Local demand management of charging stations using vehicle-to-vehicle service: A welfare maximization-based soft actor-critic model ;https://www.sciencedirect.com/science/article/pii/S2590116823000553
1819;WeOxhn5ubJcJ;Multi-objective longitudinal decision-making for autonomous electric vehicle: a entropy-constrained reinforcement learning approach ;https://ieeexplore.ieee.org/abstract/document/9294736/
1820;HTFIFJ5GUYsJ;Laxity differentiated pricing and deadline differentiated threshold scheduling for a public electric vehicle charging station ;https://ieeexplore.ieee.org/abstract/document/9735345/
1821;P3Tz0kpC5HgJ;Combining a gradient-based method and an evolution strategy for multi-objective reinforcement learning ;https://link.springer.com/article/10.1007/s10489-020-01702-7
1822;8N7tPbJ39UkJ;Using soft actor-critic for low-level uav control ;https://arxiv.org/abs/2010.02293
1823;izzol8E2oJYJ;EAT-C: environment-adversarial sub-task curriculum for efficient reinforcement learning ;https://proceedings.mlr.press/v162/ao22a.html
1824;4DS4rWZdc7gJ;Evolving Populations of Diverse RL Agents with MAP-Elites ;https://arxiv.org/abs/2303.12803
1825;dhbNmsn6IXsJ;Sampling efficient deep reinforcement learning through preference-guided stochastic exploration ;https://ieeexplore.ieee.org/abstract/document/10269149/
1826;ysuC1PxqOQQJ;DualAfford: Learning Collaborative Visual Affordance for Dual-gripper Manipulation ;https://openreview.net/forum?id=I_YZANaz5X
1827;We7VL-x2vBMJ;Physics-informed deep reinforcement learning-based integrated two-dimensional car-following control strategy for connected automated vehicles ;https://www.sciencedirect.com/science/article/pii/S0950705123002356
1828;yRgluGq1Zx8J;SESNO: Sample Efficient Social Navigation from Observation ;https://ieeexplore.ieee.org/abstract/document/9981645/
1829;arCPgLEAt9oJ;Reference Model-Based Deterministic Policy for Pitch and Depth Control of Autonomous Underwater Vehicle ;https://www.mdpi.com/2077-1312/11/3/588
1830;YEPMJm6XwmQJ;rsoccer: A framework for studying reinforcement learning in small and very small size robot soccer ;https://link.springer.com/chapter/10.1007/978-3-030-98682-7_14
1831;n9RvLJtD6kIJ;Real-time model for wave attenuation using active plate breakwater based on deep reinforcement learning ;https://www.sciencedirect.com/science/article/pii/S0029801823007047
1832;cZXlKFrB87YJ;Learning temporally-consistent representations for data-efficient reinforcement learning ;https://arxiv.org/abs/2110.04935
1833;5X-YaTtW7rEJ;Stochastic Planner-Actor-Critic for Unsupervised Deformable Image Registration ;https://ojs.aaai.org/index.php/AAAI/article/view/20086
1834;iVQUyp8MzD8J;Causal confusion and reward misidentification in preference-based reward learning ;https://arxiv.org/abs/2204.06601
1835;osv_lcFsWB0J;Deep Reinforcement Learning Based Decision Making for Complex Jamming Waveforms ;https://www.mdpi.com/1099-4300/24/10/1441
1836;bWBnvYKXYzUJ;Optimization of autonomous vehicle speed control mechanisms using hybrid DDPG-SHAP-DRL-stochastic algorithm ;https://www.sciencedirect.com/science/article/pii/S096599782200148X
1837;D5aoFI1csJkJ;Deep reinforcement learning for long term hydropower production scheduling ;https://ieeexplore.ieee.org/abstract/document/9203208/
1838;1aKZdOG1TvwJ;Learning context-aware task reasoning for efficient meta-reinforcement learning ;https://arxiv.org/abs/2003.01373
1839;1YFQ7L7NdBIJ;Reinforcement learning-based black-box evasion attacks to link prediction in dynamic graphs ;https://ieeexplore.ieee.org/abstract/document/9780921/
1840;ZZPZb6MvXe0J;A reinforcement learning approach for scheduling in mmwave networks ;https://ieeexplore.ieee.org/abstract/document/9653135/
1841;_Zv9NONFlXwJ;Intelligent control system for droplet volume in inkjet printing based on stochastic state transition soft actor–critic DRL algorithm ;https://www.sciencedirect.com/science/article/pii/S0278612523000742
1842;eAwk0wymhrIJ;Towards AI-controlled FES-restoration of arm movements: neuromechanics-based reinforcement learning for 3-D reaching ;https://ieeexplore.ieee.org/abstract/document/10123831/
1843;xt81hycaOogJ;Multi-UAV trajectory design and power control based on deep reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/9815202/
1844;XFRiLVnWq44J;Collaborative optimization of multi-microgrids system with shared energy storage based on multi-agent stochastic game and reinforcement learning ;https://www.sciencedirect.com/science/article/pii/S0360544223015761
1845;Z6M3XQudPokJ;Priors, hierarchy, and information asymmetry for skill transfer in reinforcement learning ;https://arxiv.org/abs/2201.08115
1846;8ACBaYFDH64J;DSAC-configured Differential Evolution for Cloud-Edge-Device Collaborative Task Scheduling ;https://ieeexplore.ieee.org/abstract/document/10138879/
1847;kC2s0B-2sYsJ;A Soft Actor-Critic Reinforcement Learning Algorithm for Network Intrusion Detection ;https://www.sciencedirect.com/science/article/pii/S0167404823004121
1848;ux39uRYF75cJ;Offline Model-Based Adaptable Policy Learning for Decision-Making in Out-of-Support Regions ;https://ieeexplore.ieee.org/abstract/document/10255284/
1849;jEJtGAhXkdAJ;DROP: Deep relocating option policy for optimal ride-hailing vehicle repositioning ;https://www.sciencedirect.com/science/article/pii/S0968090X22003369
1850;iAx0Y5Q_ZLEJ;Distributional and hierarchical reinforcement learning for physical systems with noisy state observations and exogenous perturbations ;https://www.sciencedirect.com/science/article/pii/S0952197623006498
1851;Xc397ezb8AMJ;Improved Reinforcement Learning Using Stability Augmentation With Application to Quadrotor Attitude Control ;https://ieeexplore.ieee.org/abstract/document/9803038/
1852;u597YXneaUgJ;Autonomous docking of mobile robots by reinforcement learning tackling the sparse reward problem ;https://link.springer.com/chapter/10.1007/978-3-030-85099-9_32
1853;Us_KmKZzSJkJ;Adaptive phase shift control of thermoacoustic combustion instabilities using model-free reinforcement learning ;https://www.sciencedirect.com/science/article/pii/S0010218023004157
1854;rwOhpIrPFc4J;Constrained reinforcement learning and formal verification for safe colonoscopy navigation ;https://arxiv.org/abs/2303.03207
1855;GuuIrsD7NxUJ;Model-Free Economic Dispatch for Virtual Power Plants: An Adversarial Safe Reinforcement Learning Approach ;https://ieeexplore.ieee.org/abstract/document/10163055/
1856;UGxSk9CnZssJ;Balancing exploration and exploitation in episodic reinforcement learning ;https://www.sciencedirect.com/science/article/pii/S0957417423013039
1857;7Isc7jyqKRcJ;Physics informed intrinsic rewards in reinforcement learning ;https://ieeexplore.ieee.org/abstract/document/9966956/
1858;4mHnGmSBGxsJ;On the Efficacy of 3D Point Cloud Reinforcement Learning ;https://arxiv.org/abs/2306.06799
1859;Eo3GZOZbq6cJ;Load frequency active disturbance rejection control for multi-source power system based on soft actor-critic ;https://www.mdpi.com/1996-1073/14/16/4804
1860;deioOJPpZC8J;Automated design of search algorithms based on reinforcement learning ;https://www.sciencedirect.com/science/article/pii/S0020025523012240
1861;9gSRgFZGnZYJ;Optimal strategy of the simultaneous dice game Pig for multiplayers: when reinforcement learning meets game theory ;https://www.nature.com/articles/s41598-023-35237-x
1862;Hr0MHYMoim8J;Towards AI-controlled FES-restoration of arm movements: Controlling for progressive muscular fatigue with Gaussian state-space models ;https://ieeexplore.ieee.org/abstract/document/10123874/
1863;-kiO7pA_PEAJ;A general motion control framework for an autonomous underwater vehicle through deep reinforcement learning and disturbance observers ;https://www.sciencedirect.com/science/article/pii/S001600322300217X
1864;XYqNYXf-a40J;Averaged soft actor-critic for deep reinforcement learning ;https://www.hindawi.com/journals/complexity/2021/6658724/
1865;Q6rSfozCRegJ;Target entropy annealing for discrete soft actor-critic ;https://arxiv.org/abs/2112.02852
1866;vlMd_egZ-lYJ;Data Driven Reward Initialization for Preference based Reinforcement Learning ;https://arxiv.org/abs/2302.08733
1867;4NxVetQEuicJ;An adaptable approach to learn realistic legged locomotion without examples ;https://ieeexplore.ieee.org/abstract/document/9812441/
1868;ogtIDGW3fbsJ;Deep Reinforcement Learning Based Active Network Management and Emergency Load-Shedding Control for Power Systems ;https://ieeexplore.ieee.org/abstract/document/10210687/
1869;keKaXaVMg0QJ;Training and transferring safe policies in reinforcement learning ;https://repository.ubn.ru.nl/bitstream/handle/2066/287359/287359.pdf?sequence=1
1870;vZvqgi7fQh8J;Optimal Goal-Reaching Reinforcement Learning via Quasimetric Learning ;https://arxiv.org/abs/2304.01203
1871;1A4Edbx9-VQJ;Revisiting pgd attacks for stability analysis of large-scale nonlinear systems and perception-based control ;https://arxiv.org/abs/2201.00801
1872;Dp31EWKDlxAJ;Joint Computing, Pushing, and Caching Optimization for Mobile Edge Computing Networks Via Soft Actor-Critic Learning ;https://ieeexplore.ieee.org/abstract/document/10275097/
1873;nopwlLdDv1MJ;Contrastive State Augmentations for Reinforcement Learning-Based Recommender Systems ;https://dl.acm.org/doi/abs/10.1145/3539618.3591656
1874;Ug-0v9jB_VQJ;On entropy regularized path integral control for trajectory optimization ;https://www.mdpi.com/1099-4300/22/10/1120
1875;KqtKcAmZhVsJ;A hybrid approach for learning to shift and grasp with elaborate motion primitives ;https://ieeexplore.ieee.org/abstract/document/9811735/
1876;FxR8kWkRr68J;Learning unsupervised disentangled skill latents to adapt unseen task and morphological modifications ;https://www.sciencedirect.com/science/article/pii/S0952197622003815
1877;I9IdaeAMUlgJ;Deep reinforcement learning for process synthesis ;https://arxiv.org/abs/2009.13265
1878;mCRpgmNAfzUJ;Minimax-Bayes Reinforcement Learning ;https://proceedings.mlr.press/v206/buening23a.html
1879;xc_QQav14MoJ;Noise-robust end-to-end quantum control using deep autoregressive policy networks ;https://proceedings.mlr.press/v145/yao22a.html
1880;ylkwZX3ZyywJ;On optimizing interventions in shared autonomy ;https://ojs.aaai.org/index.php/AAAI/article/view/20471
1881;-FAa6YLovEMJ;Some Supervision Required: Incorporating Oracle Policies in Reinforcement Learning via Epistemic Uncertainty Metrics ;https://arxiv.org/abs/2208.10533
1882;vAaNw0eiQjYJ;Reducing conservativeness oriented offline reinforcement learning ;https://arxiv.org/abs/2103.00098
1883;zzqnzePxXV4J;Digital-twin deep dynamic camera position optimisation for the V-STARS photogrammetry system based on 3D reconstruction ;https://www.tandfonline.com/doi/abs/10.1080/00207543.2023.2252108
1884;slA0gpdNZRgJ;Fishgym: A high-performance physics-based simulation framework for underwater robot learning ;https://ieeexplore.ieee.org/abstract/document/9812066/
1885;fV7zSxwQgC0J;Online Operational Decision-making for Integrated Electric-Gas Systems with Safe Reinforcement Learning ;https://ieeexplore.ieee.org/abstract/document/10266735/
1886;-ZstjjSgcCcJ;Probabilistic machine learning for healthcare ;https://www.annualreviews.org/doi/abs/10.1146/annurev-biodatasci-092820-033938
1887;ulaWTj7XJL0J;The effects of reward misspecification: Mapping and mitigating misaligned models ;https://arxiv.org/abs/2201.03544
1888;3l17UAfu4z0J;Online reinforcement learning for a continuous space system with experimental validation ;https://www.sciencedirect.com/science/article/pii/S0959152421000950
1889;wkM_8_FZwxEJ;Subcutaneous insulin administration by deep reinforcement learning for blood glucose level control of type-2 diabetic patients ;https://www.sciencedirect.com/science/article/pii/S001048252200614X
1890;wdwakkC8O8IJ;A blood glucose control framework based on reinforcement learning with safety and interpretability: In silico validation ;https://ieeexplore.ieee.org/abstract/document/9496615/
1891;oabkTLWIeX0J;Offline reinforcement learning for safer blood glucose control in people with type 1 diabetes ;https://www.sciencedirect.com/science/article/pii/S1532046423000977
1892;D1uvGzRVJoYJ;Blood glucose level forecasting on type-1-diabetes subjects during physical activity: a comparative analysis of different learning techniques ;https://www.mdpi.com/2306-5354/8/6/72
1893;SO_8kiviRJMJ;Reinforcement learning for patient-specific optimal stenting of intracranial aneurysms ;https://www.nature.com/articles/s41598-023-34007-z
1894;b3hcI4n2qbsJ;Evaluation of blood glucose level control in type 1 diabetic patients using deep reinforcement learning ;https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0274608
1895;Bwmjznxeyl4J;Escada: Efficient safety and context aware dose allocation for precision medicine ;https://proceedings.neurips.cc/paper_files/paper/2022/hash/afddff15817993412489a7df483da7d9-Abstract-Conference.html
